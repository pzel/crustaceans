<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8" />
  <title>Planet Crustaceans</title>
  <link media="screen" href="/static/styles/screen-switcher-default.css"
     type="text/css" id="screen-switcher-stylesheet" rel="stylesheet" />
  <link rel="stylesheet" type="text/css" media="sc&#82;een" href="/static/styles/netscape4.css" />
  <link rel="stylesheet" type="text/css" media="print" href="/static/styles/print.css" />
  <link rel="alternate stylesheet" type="text/css" media="screen" href="/static/styles/largestyles.css" title="large text" />
  <link media="screen" href="/static/styles/defaultfonts.css" type="text/css"
      rel="alternate stylesheet" title="default fonts" />
  <script src="/js/iotbs2-key-directors-load.js" type="text/javascript"></script>
  <script src="/js/iotbs2-directors.js" type="text/javascript"></script>
  <script src="/js/iotbs2-core.js" type="text/javascript"></script>
  <meta name="generator" content="Planet/2.0 +http://www.planetplanet.org">
  <meta name="keywords"
     content="Python weblog blog blogger weblogger aggregator rss">
  <meta name="description" content="Recent postings from Python-related weblogs.">
  <link rel="alternate" type="application/rss+xml" title="RSS" href="rss20.xml">
</head>

<body>
  <!-- Logo -->
  <h1 id="logoheader">
    <a href="/" id="logolink" accesskey="1"><img id="logo"
src="/static/images/python-logo.gif" alt="homepage" border="0" /></a>
  </h1>
  <!-- Skip to Navigation -->
  <div class="skiptonav"><a href="#left-hand-navigation" accesskey="2"><img src="/static/images/trans.gif" id="skiptonav" alt="skip to navigation" border="0" /></a></div>
  <div class="skiptonav"><a href="#content-body" accesskey="3"><img src="/static/images/trans.gif" id="skiptocontent" alt="skip to content" border="0" /></a></div>

  <div id="content-body">
    <div id="body-main">

<h1 class="pageheading">Planet Crustaceans</h1>

<p>Last update: April 25, 2020 10:03 PM





<h2>April 22, 2020</h2>




<hr><h3 class="post"><a href="https://caiustheory.com/" title="Caius Theory">Caius Durling (caius)</a></h3>


<h4><a href="https://caiustheory.com/rspec-given/when/then-with-symbols/">RSpec Given/When/Then with symbols</a></h4>
<p>
<p>Having a need to write some BDD-esque tests without the need of putting them in front of non-technical people, I was recently playing around with <a href="https://relishapp.com/rspec/rspec-rails/docs/feature-specs/feature-spec">rspec feature specs</a>. Where I&rsquo;ve used these previously we&rsquo;ve eventually run into curation issues where the specs are outdated, brittle and require so much maintenance we&rsquo;ve generally ended up lobbing cucumber into the project as a stopgap.</p>
<p>This is due to ending up with feature specs like the following, which lead you to having to parse the code mentally to work out what it&rsquo;s testing:</p>
<div class="highlight"><pre class="chroma"><code class="language-ruby"><span class="no">RSpec</span><span class="o">.</span><span class="n">feature</span> <span class="s2">"Admin: Posts"</span> <span class="k">do</span>
<span class="n">scenario</span> <span class="s2">"Authoring a post"</span> <span class="k">do</span>
<span class="vi">@user</span> <span class="o">=</span> <span class="n">create</span> <span class="ss">:user</span><span class="p">,</span> <span class="ss">:admin</span>
<span class="n">login_as</span> <span class="vi">@user</span>
<span class="n">visit</span> <span class="n">new_admin_post_path</span>
<span class="n">fill_in</span> <span class="s2">"Title"</span><span class="p">,</span> <span class="ss">with</span><span class="p">:</span> <span class="s2">"RSpec feature specs"</span>
<span class="n">fill_in</span> <span class="s2">"Body"</span><span class="p">,</span> <span class="ss">with</span><span class="p">:</span> <span class="s2">"Some piffle about feature specs"</span>
<span class="n">click_on</span> <span class="s2">"Publish!"</span>
<span class="n">visit</span> <span class="n">root_url</span>
<span class="n">expect</span><span class="p">(</span><span class="n">page</span><span class="p">)</span><span class="o">.</span><span class="n">to</span> <span class="n">have_content</span><span class="p">(</span><span class="s2">"RSpec feature specs"</span><span class="p">)</span>
<span class="k">end</span>
<span class="k">end</span>
</code></pre></div><p>After some reading around, I eventually stumbled back across <a href="https://www.futurelearn.com/info/blog/how-we-write-readable-feature-tests-with-rspec">this idea from Future Learn</a> where they lay out the above test by splitting it into private methods within the feature block, but leaving it more readable to future readers. I then found <a href="https://www.madetech.com/blog/feature-testing-with-rspec">Made Tech&rsquo;s take on this same idea</a>, and riffing off the both of them ended up with the following instead:</p>
<div class="highlight"><pre class="chroma"><code class="language-ruby"><span class="no">RSpec</span><span class="o">.</span><span class="n">feature</span> <span class="s2">"Admin: Posts"</span> <span class="k">do</span>
<span class="n">scenario</span> <span class="s2">"Authoring a post"</span> <span class="k">do</span>
<span class="n">given_i_am_logged_in_as_an_admin</span>
<span class="n">when_i_publish_a_new_post</span>
<span class="n">then_i_see_the_post_on_the_homepage</span>
<span class="k">end</span>
<span class="kp">protected</span>
<span class="k">def</span> <span class="nf">given_i_am_logged_in_as_an_admin</span>
<span class="vi">@user</span> <span class="o">=</span> <span class="n">create</span> <span class="ss">:user</span><span class="p">,</span> <span class="ss">:admin</span>
<span class="n">login_as</span> <span class="vi">@user</span>
<span class="k">end</span>
<span class="k">def</span> <span class="nf">when_i_publish_a_new_post</span>
<span class="n">visit</span> <span class="n">new_admin_post_path</span>
<span class="n">fill_in</span> <span class="s2">"Title"</span><span class="p">,</span> <span class="ss">with</span><span class="p">:</span> <span class="s2">"RSpec feature specs"</span>
<span class="n">fill_in</span> <span class="s2">"Body"</span><span class="p">,</span> <span class="ss">with</span><span class="p">:</span> <span class="s2">"Some piffle about feature specs"</span>
<span class="n">click_on</span> <span class="s2">"Publish!"</span>
<span class="k">end</span>
<span class="k">def</span> <span class="nf">then_i_see_the_post_on_the_homepage</span>
<span class="n">visit</span> <span class="n">root_url</span>
<span class="n">expect</span><span class="p">(</span><span class="n">page</span><span class="p">)</span><span class="o">.</span><span class="n">to</span> <span class="n">have_content</span><span class="p">(</span><span class="s2">"RSpec feature specs"</span><span class="p">)</span>
<span class="k">end</span>
<span class="k">end</span>
</code></pre></div><p>Now this is fine, but writing lots_of_names_with_underscores_in_is_a_trifle <strong>irritating</strong>. Now I remember <a href="https://weirichinstitute.com/about">Jim Weirich</a><sup id="fnref:1"><a href="https://caiustheory.com/feed.xml#fn:1" class="footnote-ref">1</a></sup> showing off <a href="https://github.com/rspec-given/rspec-given">rspec-given</a> at a conference a few years ago, and wondered if that would solve my problem here of wanting to have runtime warn me when my methods are misspelled or missing, without having_to_underscore_them.</p>
<p>Now rspec-given would let me do that, but I&rsquo;d have to switch from calling them all in turn inside a scenario block to calling them inside context blocks and passing blocks to each of the <code>Given</code>, <code>When</code>, etc methods. I think it would be something like (warning, untested)</p>
<div class="highlight"><pre class="chroma"><code class="language-ruby"><span class="no">Rspec</span><span class="o">.</span><span class="n">feature</span> <span class="s2">"Admin: Posts"</span> <span class="k">do</span>
<span class="no">Given</span> <span class="p">{</span> <span class="vi">@user</span> <span class="o">=</span> <span class="n">create</span> <span class="ss">:user</span><span class="p">,</span> <span class="ss">:admin</span> <span class="p">}</span>
<span class="no">Given</span> <span class="p">{</span> <span class="n">login_as</span> <span class="vi">@user</span> <span class="p">}</span>
<span class="n">context</span> <span class="s2">"authoring a post"</span> <span class="k">do</span>
<span class="no">When</span> <span class="p">{</span> <span class="n">visit</span> <span class="n">new_admin_post_path</span> <span class="p">}</span>
<span class="no">When</span> <span class="p">{</span> <span class="n">fill_in</span> <span class="p">:</span><span class="err">…</span> <span class="p">}</span>
<span class="no">Then</span> <span class="p">{</span> <span class="n">visit</span> <span class="n">root_url</span> <span class="p">}</span>
<span class="no">And</span> <span class="p">{</span> <span class="n">expect</span><span class="p">(</span><span class="n">page</span><span class="p">)</span><span class="o">.</span><span class="n">to</span> <span class="n">have_content</span><span class="p">(</span><span class="s2">"RSpec feature specs"</span><span class="p">)</span> <span class="p">}</span>
<span class="k">end</span>
<span class="k">end</span>
</code></pre></div><p>Now this didn&rsquo;t <em>quite</em> fit with what I wanted. However, I did wonder if it was possible to go down the route of having a <code>Given</code> method that takes a token to identify the code it should call. (A method if you will.) It&rsquo;s possible in ruby to call a method starting with a Capital letter, but convention dictates those are usually class/module names (constants) rather than methods.</p>
<p>A little bit of hacking later and this is what I ended up getting working:</p>
<div class="highlight"><pre class="chroma"><code class="language-ruby"><span class="no">RSpec</span><span class="o">.</span><span class="n">feature</span> <span class="s2">"Admin: Posts"</span> <span class="k">do</span>
<span class="n">scenario</span> <span class="s2">"Authoring a post"</span> <span class="k">do</span>
<span class="no">Given</span> <span class="ss">:"I am logged in as an admin"</span>
<span class="no">When</span> <span class="ss">:"I publish a new post"</span>
<span class="no">Then</span> <span class="ss">:"I see the post on the homepage"</span>
<span class="k">end</span>
<span class="kp">protected</span>
<span class="n">def_Given</span> <span class="ss">:"I am logged in as an admin"</span> <span class="k">do</span>
<span class="vi">@user</span> <span class="o">=</span> <span class="n">create</span> <span class="ss">:user</span><span class="p">,</span> <span class="ss">:admin</span>
<span class="n">login_as</span> <span class="vi">@user</span>
<span class="k">end</span>
<span class="n">def_When</span> <span class="ss">:"I publish a new post"</span> <span class="k">do</span>
<span class="n">visit</span> <span class="n">new_admin_post_path</span>
<span class="n">fill_in</span> <span class="s2">"Title"</span><span class="p">,</span> <span class="ss">with</span><span class="p">:</span> <span class="s2">"RSpec feature specs"</span>
<span class="n">fill_in</span> <span class="s2">"Body"</span><span class="p">,</span> <span class="ss">with</span><span class="p">:</span> <span class="s2">"Some piffle about feature specs"</span>
<span class="n">click_on</span> <span class="s2">"Publish!"</span>
<span class="k">end</span>
<span class="n">def_Then</span> <span class="ss">:"I see the post on the homepage"</span> <span class="k">do</span>
<span class="n">visit</span> <span class="n">root_url</span>
<span class="n">expect</span><span class="p">(</span><span class="n">page</span><span class="p">)</span><span class="o">.</span><span class="n">to</span> <span class="n">have_content</span><span class="p">(</span><span class="s2">"RSpec feature specs"</span><span class="p">)</span>
<span class="k">end</span>
<span class="k">end</span>
</code></pre></div><p>Now there&rsquo;s two extra things that makes this easier for me to write than underscored methods. Ruby doesn&rsquo;t only allow <code>:foo</code> as a symbol, it also allows <code>:&quot;foo bar&quot;</code> for writing a symbol. You can then define a method based on that even though it has spaces in the method name.</p>
<p>My text editor<sup id="fnref:2"><a href="https://caiustheory.com/feed.xml#fn:2" class="footnote-ref">2</a></sup> also autocompletes ruby symbols from partial matches, which makes it easy to write out what I want in the scenario, run the spec and find out what methods need defining, then define the methods using autocomplete to save copy/pasting everything.</p>
<p>By using actual methods for these, we get a couple of other happy accidents along the way. Most ruby installs now include <a href="https://github.com/ruby/did_you_mean">did_you_mean</a> out the box, which suggests methods like the one you called if your method results in a <code>NoMethodError</code>. This works quite nicely, you end up with something like</p>
<pre><code>undefined method `When I pblish a new post' for #&lt;RSpec::ExampleGroups::AdminPosts:0x00007faf1f9fc4c0&gt;
Did you mean? When I publish a new post
</code></pre><p>And then if you just run it without implementing any of the helper methods at all, you get a nice <code>NoMethodError</code> telling you exactly what you need to implement:</p>
<pre><code>NoMethodError:
undefined method `Given I am logged in as an admin' for #&lt;RSpec::ExampleGroups::AdminPosts:0x00007fbd06598498&gt;
</code></pre><p>The magic behind that makes all this work is in <a href="https://gist.github.com/caius/606b80252b176e353fe0893f8888dbbf"><code>spec/support/given_when_then.rb</code></a>, which is not terrible, but also probably not a great idea. 🙃</p>

<hr />
<ol>
<li id="fn:1">
<p>😿 <a href="https://caiustheory.com/feed.xml#fnref:1" class="footnote-backref">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p><a href="https://macromates.com">TextMate 2</a> <a href="https://caiustheory.com/feed.xml#fnref:2" class="footnote-backref">&#x21a9;&#xfe0e;</a></p>
</li>
</ol></p>
<p>
<em><a href="https://caiustheory.com/rspec-given/when/then-with-symbols/">April 22, 2020 05:30 PM</a></em>
</p>





<h2>April 21, 2020</h2>




<hr><h3 class="post"><a href="http://www.petecorey.com/" title="Pete Corey">Pete Corey (petecorey)</a></h3>


<h4><a href="http://www.petecorey.com/blog/2020/04/21/guitar-chord-voicings-with-prolog/">Guitar Chord Voicings with Prolog</a></h4>
<p>
Prolog is a language that excels at defining and exploring relationships. Let's take advantage of that and use Prolog to explore a few of the myriad of relationships that exist between chords and the guitar's fretboard.</p>
<p>
<em><a href="http://www.petecorey.com/blog/2020/04/21/guitar-chord-voicings-with-prolog/">April 21, 2020 12:00 AM</a></em>
</p>









<hr><h3 class="post"><a href="https://sulami.github.io" title="sulami's blog">Robin Schroer (sulami)</a></h3>


<h4><a href="https://sulami.github.io/posts/engineers-meeting-guide/index.html">The Grumpy Developer's Guide to Meetings</a></h4>
<p>
<p>While everyone is writing about remote meetings these days, I do not believe that successful remote meetings are actually meaningfully different from successful in-person meetings.<span><label for="sn-1" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-1" class="margin-toggle" /><span class="sidenote">I’m glossing over videoconferencing because I don’t believe it is a meaningful hurdle to clear.<br />
<br />
</span></span></p>
<p><a href="http://twitchard.github.io/posts/2020-03-28-against-process.html">Like many other developers</a>, I loathe meetings, especially when they seem like a waste of valuable time. My philosophy is “if you have to set up a meeting, at least do it right”. Consequently, here are some rules for successful meetings, both remote and in-person:</p>
<h2 id="the-best-meeting-is-no-meeting">The Best Meeting Is No Meeting</h2>
<p>It is important to understand the tradeoffs involved when deciding to schedule a meeting. Meetings are synchronous discussions, which makes them useful for knowledge exchanges and decision making processes, but they are also time-intensive and disruptive for everyone involved.</p>
<p>The alternative to organising a meeting is an asynchronous conversation, for example on a shared document.<span><label for="sn-2" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-2" class="margin-toggle" /><span class="sidenote">I find that doing all the same work as for a meeting on a shared document, but just leaving out the actual meeting, is a very effective way of using asynchronous process.<br />
<br />
</span></span> This can be faster than a meeting overall, as it allows participants to participate in their own time, instead of trying to find a slot that fits everyone. In addition to that, it is much less disruptive compared scheduling a meeting, especially for <a href="https://www.oreilly.com/library/view/changing-software-development/9780470515044/9780470515044_software_developers_are_knowledge_worker.html">knowledge workers</a>.</p>
<p>The only good reason for a synchronous meeting is making decisions requiring knowledge exchange and/or consensus. A good example would be planning a complicated feature, or cleaning up a backlog.</p>
<h2 id="the-most-important-work-happens-before-the-meeting">The Most Important Work Happens Before the Meeting</h2>
<p>Every meeting needs an organiser. The organiser needs to define the expected outcome of the meeting, as well as gather all required information, and share all of these in the meeting agenda. The outcome should be tangible, like a decision or a set of tasks to be done.</p>
<p>The agenda is crucial, because the participants will likely have to do some preparation in advance to the meeting. If any specific work needs to be done before the meeting, like research or data retrieval, make sure to clearly assign tasks.</p>
<p>I recommend writing out the full agenda before scheduling the meeting, and then sharing the agenda with the calendar invitation. This allows everyone to schedule their preparation in their own time.</p>
<h2 id="the-actual-meeting">The Actual Meeting</h2>
<p>During the meeting it is important to keep notes, usually in a shared document. You can designate a scribe, or just agree to all contribute some bullet points whenever possible.<span><label for="sn-3" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-3" class="margin-toggle" /><span class="sidenote">Both approaches have pros and cons. A dedicated scribe leads to more detailed and coherent notes, but requires a person who will not be able to take part in the conversation, at least not effectively.<br />
<br />
</span></span> You want to write down any conclusions reached, important points made, and further questions and future work to be done. Do not care too much about form, the meeting organiser should rewrite the notes after the meeting anyway.</p>
<p>The meeting is prime talking time, and you should treat it as such. Do not spend time watching someone carry out a task.<span><label for="sn-4" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-4" class="margin-toggle" /><span class="sidenote">There is really no point in everyone watching a single person manipulate a JIRA board during a meeting.<br />
<br />
</span></span> If you find during the meeting that you require more information, write this down as a future task instead of derailing the meeting.</p>
<p>The organiser should always work towards the defined outcome, but it often happens that some other discussion emerges as a precondition to reaching the outcome. There is a balance to be struck between discussion necessary to get to a meaningful outcome and veering too far off-topic.</p>
<p>Keep in mind that the time slot scheduled is more a rough guideline than a rule. If you can finish early, do so. If you need more time, and everyone involved has more time, take it.<span><label for="sn-5" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-5" class="margin-toggle" /><span class="sidenote">Though maybe take a 5 minute break.<br />
<br />
</span></span> Do not try to force an outcome if you did not get there in time. If you find at the start of the meeting that some necessary precondition has not been met do not be afraid to reschedule or cancel altogether.</p>
<h2 id="the-alternative-the-ad-hoc-huddle">The Alternative: The Ad Hoc Huddle</h2>
<p>The rules above do not mean that you cannot talk to one another without ritual. Especially for small discussions between 2-4 people, ad hoc huddles can be useful.</p>
<p>As a rule of thumb, these should usually be happening within the next 24 hours, so usually “later today” or “tomorrow morning”.</p>
<p>You still need to define a goal, and you will want to write down any outcomes in some form, even if less formal than meeting notes. Even a Slack message with some findings in a relevant channel counts.</p></p>
<p>
<em><a href="https://sulami.github.io/posts/engineers-meeting-guide/index.html">April 21, 2020 12:00 AM</a></em>
</p>





<h2>April 19, 2020</h2>




<hr><h3 class="post"><a href="http://shape-of-code.coding-guidelines.com" title="The Shape of Code">Derek Jones (derek-jones)</a></h3>


<h4><a href="http://shape-of-code.coding-guidelines.com/2020/04/19/predicting-the-future-with-datalogistic-regression/">Predicting the future with data+logistic regression</a></h4>
<p>
Predicting the peak of data fitted by a logistic equation is attracting a lot of attention at the moment. Let&#8217;s see how well we can predict the final size of a software system, in lines of code, using logistic regression (code+data). First up is the size of the GNU C library. This is not really [&#8230;]</p>
<p>
<em><a href="http://shape-of-code.coding-guidelines.com/2020/04/19/predicting-the-future-with-datalogistic-regression/">April 19, 2020 10:35 PM</a></em>
</p>









<hr><h3 class="post"><a href="https://blog.asrpo.com" title="Asrp Blog">asrpo (asrp)</a></h3>


<h4><a href="https://blog.asrpo.com/flpc_is_now_self_hosted">Flpc is now self-hosted</a></h4>
<p>
<p>The Forth Lisp Python Continuum (Flpc) can now compile its own source code! Get it from <a href="https://github.com/asrp/flpc">Github</a>.</p>

<p>So instead of</p>
<pre><code>$ python compiler.py file1.flpc file2.flpc file3.flpc &gt; output.f
</code></pre>
<p>you can now run</p>
<pre><code>$ ./flpc precompiled/compiler.f
&gt; push: output.f init_g
&gt; push: file1.flpc compile_file
&gt; push: file2.flpc compile_file
&gt; push: file3.flpc compile_file
</code></pre></p>
<p>
<em><a href="https://blog.asrpo.com/flpc_is_now_self_hosted">April 19, 2020 03:27 PM</a></em>
</p>









<hr><h3 class="post"><a href="https://www.the-paper-trail.org/" title="The Paper Trail">Henry Robinson (henryr)</a></h3>


<h4><a href="https://www.the-paper-trail.org/post/2020-04-19-gray-failures/">Gray Failures</a></h4>
<p>
<p><em>Huang et. al., HotOS 2017</em> <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/06/paper-1.pdf">&ldquo;Gray Failure: The Achilles Heel of Cloud-Scale Systems&rdquo;</a></p>

<p>Detecting faults in a large system is a surprisingly hard problem. First you have to decide what kind of thing you want to measure, or &lsquo;observe&rsquo;. Then you have to decide what pattern in that observation constitutes a sufficiently worrying situation (or &lsquo;failure&rsquo;) to require mitigation. Then you have to decide how to mitigate it!</p>

<p>Complicating this already difficult issue is the fact that the health of your system is in part a matter of perspective. Your service might be working wonderfully from inside your datacenter, where your probes are run, but all of that means nothing to your users who have been trying to get their RPCs through an overwhelmed firewall for the last hour.</p>

<p>That gap, between what your failure detectors observe, and what clients observe, is the subject of this paper on &lsquo;Gray Failures&rsquo;, which are the failure modes that happen when clients perceive an issue that is not yet detected by your internal systems. This is a good name for an old phenomenon (every failure detector I have built includes client-side mitigations to work around this exact issue).</p>

<p></p></p>
<p>
<em><a href="https://www.the-paper-trail.org/post/2020-04-19-gray-failures/">April 19, 2020 05:04 AM</a></em>
</p>





<h2>April 18, 2020</h2>




<hr><h3 class="post"><a href="http://bluishcoder.co.nz/&quot;" title="Bluishcoder">Chris Double (doublec)</a></h3>


<h4><a href="http://bluishcoder.co.nz/2020/04/18/fun-factor-libraries.html">Fun Factor Libraries</a></h4>
<p>
<p><a href="https://factorcode.org/">Factor</a> is a programming language I've <a href="http://bluishcoder.co.nz/tags/factor/">written about before</a> and in the early days of Factor development I wrote a number of libraries and contributed to development. It's been a while since I've contributed but I still use Factor. The development environment has a very Smalltalk-like feel to it and it includes full documentation and browseable source code of libraries.</p>

<p>This post isn't about Factor the language, but is about some of the neat fun libraries that people have written that shows off the graphical development system a bit.</p>

<h2>Minesweeper</h2>

<p>The first example is an implementation of the game Minesweeper in Factor. A <a href="https://re-factor.blogspot.com/2018/02/minesweeper.html">blog post by the author</a> explains the implementation. To run it inside Factor, do the following:</p>

<pre><code>"minesweeper" run
</code></pre>

<p>A new window will open showing the game. Help can be shown with:</p>

<pre><code>"minesweeper" help
</code></pre>

<p><img src="http://bluishcoder.co.nz/factor/factor_minesweeper.gif" /></p>

<h2>XKCD</h2>

<p>Another fun example is displaying XKCD comics inside the Factor REPL. The <a href="http://re-factor.blogspot.com/2011/04/xkcd.html">implementation is explained by the author here</a>.</p>

<pre><code>USE: xkcd
latest-xkcd.
...comic displayed here...
random-xkcd.
...comic displayed here...
</code></pre>

<p><img src="http://bluishcoder.co.nz/factor/factor_xkcd.gif" /></p>

<h2>Wikipedia</h2>

<p>If it seems like all the examples I'm using are from the excellent re-factor blog - well, most of them are. This blog post from re-factor <a href="https://re-factor.blogspot.com/2012/12/today-in-history.html">shows pulling historical facts from Wikipedia</a>:</p>

<pre><code>USE: wikipedia
USE: calendar

today historical-events.
...a list of historical events from wikipedia for today...

yesterday historical-births.
...a list of historical births from wikipedia for yesterday...

5 weeks ago historical-deaths.
...a list of historical deaths from wikipedia for five weeks ago...
</code></pre>

<p>The items in the list are graphical elements that can be manipulated. Left clicking on the coloured words will open a URL in the default web browser. Right clicking allows you to push the element on the Factor stack and manipulate it.</p>

<p>The <a href="https://docs.factorcode.org/content/article-calendar.html">calendar vocab</a> has a lot of interesting words that allow doing calculations like "5 weeks ago".</p>

<p><img src="http://bluishcoder.co.nz/factor/factor_wikipedia.gif" /></p>

<h2>Hacker News</h2>

<p>There's a <a href="https://docs.factorcode.org/content/vocab-hacker-news.html">hacker-news</a> vocabulary that provides words to list current articles on the <a href="https://news.ycombinator.com/">Hacker News</a> website. Like the previous Wikipedia example, the graphical elements are clickable objects:</p>

<pre><code>USE: hacker-news

hacker-news-top.
...list of top articles...

hacker-news-show.
...list articles related to showing projects...
</code></pre>

<p><img src="http://bluishcoder.co.nz/factor/factor_hackernews.gif" /></p>

<h2>CPU 8080 Emulator</h2>

<p>A number of years ago I wrote a CPU 8080 emulator in Factor and used this to implement a <a href="http://bluishcoder.co.nz/2007/05/12/factor-space-invaders-updated.html">Space Invaders Emulator</a> and then emulators for a couple of other 8080 arcade games, Balloon Bomber and Lunar Rescue. These examples require the original arcade ROMs and instructions for using them are in the online help:</p>

<pre><code>"rom.space-invaders" run
...opens in a new window...
"rom.balloon-bomber" run
...opens in a new window...
"rom.lunar-rescue" run
...opens in a new window...

"rom.space-invaders" help
...displays help...
</code></pre>

<p><img src="http://bluishcoder.co.nz/factor/factor_cpu8080.gif" /></p>

<h2>Gopher Implementation</h2>

<p>Another magical implementation from the re-factor blog, a <a href="https://re-factor.blogspot.com/2016/10/gopher-server.html">Gopher server</a> and a <a href="http://re-factor.blogspot.com/2014/12/gopher.html">graphical Gopher Client</a>. This is a video I made of the gopher client on YouTube:</p>




<p>I also did a video that shows some Factor development tools on the running Gopher client to show how everything is live in Factor:</p>




<h2>And More</h2>

<p>There's much more buried inside Factor. The <a href="https://docs.factorcode.org/content/article-handbook-library-reference.html">list of articles</a> and <a href="https://docs.factorcode.org/content/article-vocab-index.html">list of vocabularies</a> from the online help is a good way to explore. This help system is also available offline in a Factor install. By default many libraries aren't loaded when Factor starts but you can force loading everything using <code>load-all</code>:</p>

<pre><code>load-all
...all vocabs are loaded - prepare to wait for a while...
save
...saves the image so when factor is restarted the vocabs remain loaded...
</code></pre>

<p>The benefit of doing this while developing is all the online help, source and words are available via the inbuilt tools like "apropos", "usage", etc.</p></p>
<p>
<em><a href="http://bluishcoder.co.nz/2020/04/18/fun-factor-libraries.html">April 18, 2020 11:00 AM</a></em>
</p>





<h2>April 17, 2020</h2>




<hr><h3 class="post"><a href="https://blog.ovalerio.net" title="Gonçalo Valério">Gonçalo Valério (dethos)</a></h3>


<h4><a href="https://blog.ovalerio.net/archives/1861">Django Friday Tips: Feature Flags</a></h4>
<p>
This time, as you can deduce from the title, I will address the topic of how to use feature flags on Django websites and applications. This is an incredible functionality to have, specially if you need to continuously roll new code to production environments that might not be ready to be released. But first what [&#8230;]</p>
<p>
<em><a href="https://blog.ovalerio.net/archives/1861">April 17, 2020 07:49 PM</a></em>
</p>





<h2>April 16, 2020</h2>




<hr><h3 class="post"><a href="https://www.jeremymorgan.com/tags/programming/" title="programming on Jeremy Morgan :: Tech Blog">Jeremy Morgan (JeremyMorgan)</a></h3>


<h4><a href="http://feedproxy.google.com/~r/JeremyMorganProgramming/~3/GyfbG1qRiHg/">I Took a COBOL Course and I Liked It</a></h4>
<p>
COBOL is in the news again. Millions of people are filing unemployment claims nearly all at once, and the systems to process them are failing. Why? They need to scale to unprecedented levels, they&rsquo;re written in COBOL, and&hellip; we don&rsquo;t have enough COBOL programmers.
Here&rsquo;s a look at the increase in searches for &ldquo;COBOL programmers&rdquo;:
Most COBOL programmers are retired. The pipeline of new COBOL programmers is nearly nonexistent. Many are coming out of retirement just to help.</p>
<p>
<em><a href="http://feedproxy.google.com/~r/JeremyMorganProgramming/~3/GyfbG1qRiHg/">April 16, 2020 02:02 AM</a></em>
</p>









<hr><h3 class="post"><a href="http://www.petecorey.com/" title="Pete Corey">Pete Corey (petecorey)</a></h3>


<h4><a href="http://www.petecorey.com/blog/2020/04/16/clapping-music-with-tidalcycles/">Clapping Music with TidalCycles</a></h4>
<p>
Let's use TidalCycles to recreate Steve Reich's "Clapping Music", and hopefully learn a thing or two along the way.</p>
<p>
<em><a href="http://www.petecorey.com/blog/2020/04/16/clapping-music-with-tidalcycles/">April 16, 2020 12:00 AM</a></em>
</p>





<h2>April 15, 2020</h2>




<hr><h3 class="post"><a href="https://j11g.com" title="Jan van den Berg">Jan van den Berg (j11g)</a></h3>


<h4><a href="https://j11g.com/2020/04/15/ten-pieces-of-software-that-removed-roadblocks/">Ten pieces of software that removed roadblocks</a></h4>
<p>
<p>Successful software is not defined by the number of lines of code or number of clever algorithms. More often than not, successful software is defined by how many roadblocks it removes for the user. Sounds obvious, right? But it usually takes a few iterations before software gains critical mass. And for a (critical) mass number [&#8230;]</p>
<p>The post <a rel="nofollow" href="https://j11g.com/2020/04/15/ten-pieces-of-software-that-removed-roadblocks/">Ten pieces of software that removed roadblocks</a> appeared first on <a rel="nofollow" href="https://j11g.com">Jan van den Berg</a>.</p></p>
<p>
<em><a href="https://j11g.com/2020/04/15/ten-pieces-of-software-that-removed-roadblocks/">April 15, 2020 02:40 PM</a></em>
</p>





<h2>April 14, 2020</h2>




<hr><h3 class="post"><a href="https://www.ponylang.io/blog/" title="Blog on Pony">Ponylang (SeanTAllen)</a></h3>


<h4><a href="https://www.ponylang.io/blog/2020/04/last-week-in-pony---april-14-2020/">Last Week in Pony - April 14, 2020</a></h4>
<p>
<p>We return after a long absence with some very sad news.</p>

<p></p></p>
<p>
<em><a href="https://www.ponylang.io/blog/2020/04/last-week-in-pony---april-14-2020/">April 14, 2020 09:38 PM</a></em>
</p>









<hr><h3 class="post"><a href="https://www.cambus.net/" title="Atom Feed - Cambus.net">Frederic Cambus (fcambus)</a></h3>


<h4><a href="https://www.cambus.net/chinese-bbses-and-unicode-ansi-art/">Chinese BBSes and Unicode ANSi Art</a></h4>
<p>
ANSI screens from Chinese BBSes</p>
<p>
<em><a href="https://www.cambus.net/chinese-bbses-and-unicode-ansi-art/">April 14, 2020 08:50 PM</a></em>
</p>





<h2>April 13, 2020</h2>




<hr><h3 class="post"><a href="https://j11g.com" title="Jan van den Berg">Jan van den Berg (j11g)</a></h3>


<h4><a href="https://j11g.com/2020/04/13/string-theory-david-foster-wallace/">String Theory – David Foster Wallace</a></h4>
<p>
<p>If you read this blog, you know DFW is one of my favorite writers. I even named my book app, in part, after him. So I could be short about String Theory &#8212; it&#8217;s a absolute pure delight to read &#8212; but, of course, I won&#8217;t. String Theory is a collection of 5 DFW essays [&#8230;]</p>
<p>The post <a rel="nofollow" href="https://j11g.com/2020/04/13/string-theory-david-foster-wallace/">String Theory &#8211; David Foster Wallace</a> appeared first on <a rel="nofollow" href="https://j11g.com">Jan van den Berg</a>.</p></p>
<p>
<em><a href="https://j11g.com/2020/04/13/string-theory-david-foster-wallace/">April 13, 2020 08:56 PM</a></em>
</p>





<h2>April 12, 2020</h2>




<hr><h3 class="post"><a href="http://shape-of-code.coding-guidelines.com" title="The Shape of Code">Derek Jones (derek-jones)</a></h3>


<h4><a href="http://shape-of-code.coding-guidelines.com/2020/04/12/motzkin-paths-and-source-code-silhouettes/">Motzkin paths and source code silhouettes</a></h4>
<p>
Consider a language that just contains assignments and if-statements (no else arm). Nesting level could be used to visualize programs written in such a language; an if represented by an Up step, an assignment by a Level step, and the if-terminator (e.g., the } token) by a Down step. Silhouettes for the nine possible four [&#8230;]</p>
<p>
<em><a href="http://shape-of-code.coding-guidelines.com/2020/04/12/motzkin-paths-and-source-code-silhouettes/">April 12, 2020 10:25 PM</a></em>
</p>





<h2>April 11, 2020</h2>




<hr><h3 class="post"><a href="https://blog.separateconcerns.com" title="Separate Concerns">Pierre Chapuis (catwell)</a></h3>


<h4><a href="https://blog.separateconcerns.com/2020-04-11-quora-class-concept.html">[Quora] Explaining classes to a 10 year old</a></h4>
<p>
</p>
<p>
<em><a href="https://blog.separateconcerns.com/2020-04-11-quora-class-concept.html">April 11, 2020 01:00 PM</a></em>
</p>





<h2>April 10, 2020</h2>




<hr><h3 class="post"><a href="https://j11g.com" title="Jan van den Berg">Jan van den Berg (j11g)</a></h3>


<h4><a href="https://j11g.com/2020/04/10/the-trial-franz-kafka/">The Trial – Franz Kafka</a></h4>
<p>
<p>Max Brod is probably the worlds&#8217; greatest publicist. He famously refused his writer friends&#8217; dying wish to destroy all his work after his passing. This friend was of course, Franz Kafka. And against Kafka&#8217;s wishes Max Brod did publish his works and subsequently Kafka became known to the world as an absolute literary genius. The [&#8230;]</p>
<p>The post <a rel="nofollow" href="https://j11g.com/2020/04/10/the-trial-franz-kafka/">The Trial &#8211; Franz Kafka</a> appeared first on <a rel="nofollow" href="https://j11g.com">Jan van den Berg</a>.</p></p>
<p>
<em><a href="https://j11g.com/2020/04/10/the-trial-franz-kafka/">April 10, 2020 11:13 AM</a></em>
</p>





<h2>April 09, 2020</h2>




<hr><h3 class="post"><a href="https://j11g.com" title="Jan van den Berg">Jan van den Berg (j11g)</a></h3>


<h4><a href="https://j11g.com/2020/04/09/cruddiy-a-no-code-bootstrap-crud-generator/">Cruddiy: a no-code Bootstrap CRUD generator</a></h4>
<p>
<p>Sometimes you need to give people access to a MySQL database to do some basic tasks. They should be able to Create, Read, Update or Delete database records. And you probably know the user (preferred use-case), but you don&#8217;t want to give them access to phpMyAdmin, which is often too difficult (or let alone give [&#8230;]</p>
<p>The post <a rel="nofollow" href="https://j11g.com/2020/04/09/cruddiy-a-no-code-bootstrap-crud-generator/">Cruddiy: a no-code Bootstrap CRUD generator</a> appeared first on <a rel="nofollow" href="https://j11g.com">Jan van den Berg</a>.</p></p>
<p>
<em><a href="https://j11g.com/2020/04/09/cruddiy-a-no-code-bootstrap-crud-generator/">April 09, 2020 07:18 PM</a></em>
</p>











<h4><a href="https://j11g.com/2020/04/09/use-find-1-as-a-quick-and-dirty-duplicate-file-finder/">Use find (1) as a quick and dirty duplicate file finder</a></h4>
<p>
<p>Run the following two commands in bash to get a listing of all duplicate files (from a directory or location). This can help you clean out duplicate files that sometimes accumulate over time. The first command uses find to print all files (and specific attributes) from a specific location to a file, prefixing the size [&#8230;]</p>
<p>The post <a rel="nofollow" href="https://j11g.com/2020/04/09/use-find-1-as-a-quick-and-dirty-duplicate-file-finder/">Use find (1) as a quick and dirty duplicate file finder</a> appeared first on <a rel="nofollow" href="https://j11g.com">Jan van den Berg</a>.</p></p>
<p>
<em><a href="https://j11g.com/2020/04/09/use-find-1-as-a-quick-and-dirty-duplicate-file-finder/">April 09, 2020 01:24 PM</a></em>
</p>









<hr><h3 class="post"><a href="https://blog.separateconcerns.com" title="Separate Concerns">Pierre Chapuis (catwell)</a></h3>


<h4><a href="https://blog.separateconcerns.com/2020-04-09-quora-lua-call.html">[Quora] What is the call metamethod in Lua?</a></h4>
<p>
</p>
<p>
<em><a href="https://blog.separateconcerns.com/2020-04-09-quora-lua-call.html">April 09, 2020 08:40 AM</a></em>
</p>





<h2>April 07, 2020</h2>




<hr><h3 class="post"><a href="https://blog.separateconcerns.com" title="Separate Concerns">Pierre Chapuis (catwell)</a></h3>


<h4><a href="https://blog.separateconcerns.com/2019-05-04-ssh-port.html">Changing the SSH port on Arch Linux</a></h4>
<p>
</p>
<p>
<em><a href="https://blog.separateconcerns.com/2019-05-04-ssh-port.html">April 07, 2020 10:40 AM</a></em>
</p>









<hr><h3 class="post"><a href="https://www.the-paper-trail.org/" title="The Paper Trail">Henry Robinson (henryr)</a></h3>


<h4><a href="https://www.the-paper-trail.org/post/2020-04-06-physalia/">Availability in AWS' Physalia</a></h4>
<p>
<p><em>Brooker et. al., NSDI 2020</em> <a href="https://www.usenix.org/conference/nsdi20/presentation/brooker">&ldquo;Physalia: Millions of Tiny Databases&rdquo;</a></p>

<p>Some notes on AWS&rsquo; latest systems publication, which continues and expands their thinking about reducing the effect of failures in very large distributed systems (see <a href="https://aws.amazon.com/blogs/architecture/shuffle-sharding-massive-and-magical-fault-isolation/">shuffle sharding</a> as an earlier and complementary technique for the same kind of problem).</p>

<p>Physalia is a configuration store for AWS&rsquo; Elastic-Block Storage (i.e. network-attached disks). EBS disks are replicated using chain replication, but the configuration of the replication chain needs to be stored somewhere - enter Physalia.</p>

<p></p></p>
<p>
<em><a href="https://www.the-paper-trail.org/post/2020-04-06-physalia/">April 07, 2020 05:04 AM</a></em>
</p>





<h2>April 05, 2020</h2>




<hr><h3 class="post"><a href="http://shape-of-code.coding-guidelines.com" title="The Shape of Code">Derek Jones (derek-jones)</a></h3>


<h4><a href="http://shape-of-code.coding-guidelines.com/2020/04/05/comments-on-the-covid-19-model-source-code-from-imperial/">Comments on the COVID-19 model source code from Imperial</a></h4>
<p>
At the end of March a paper modelling the impact of various scenarios on the spread of COVID-19 infections, by the MRC Centre for Global Infectious Disease Analysis at Imperial College, appears to have influenced the policy of the powers that be. This group recently started publishing their modelling code on Github (good for them). [&#8230;]</p>
<p>
<em><a href="http://shape-of-code.coding-guidelines.com/2020/04/05/comments-on-the-covid-19-model-source-code-from-imperial/">April 05, 2020 08:50 PM</a></em>
</p>









<hr><h3 class="post"><a href="https://defn.io/" title="defn.io">Bogdan Popa (bogdan)</a></h3>


<h4><a href="https://defn.io/2020/04/05/postgres-bytea-to-uuid/">Converting byte arrays to UUIDs in Postgres</a></h4>
<p>
For a project that I&rsquo;m working on, I have a custom flake id spec that allows me to generate unique, sortable identifiers across computers without any sort of synchronization. The ids themselves can be encoded down to 16 bytes and I wanted to store them in Postgres. A good way to do that is to leverage Postgres&rsquo; UUID data type, which lets you efficiently store any 16 byte quantity in a way that can be indexed reasonably well.</p>
<p>
<em><a href="https://defn.io/2020/04/05/postgres-bytea-to-uuid/">April 05, 2020 04:00 PM</a></em>
</p>









<hr><h3 class="post"><a href="https://www.rkallos.com/index.html" title="Richard Kallos: Richard Kallos">Richard Kallos (rkallos)</a></h3>


<h4><a href="https://www.rkallos.com/blog/2020/04/04/what-my-choices-told-me-about-my-priorities/?utm_source=all&amp;utm_medium=RSS">What my choices told me about my priorities</a></h4>
<p>
<p>This was a useful exercise for me. I think I&rsquo;ll try and check in again sometime soon. Here were my thoughts from today.</p>

<h1 id="i-was-prioritizing-long-term-storage">I was prioritizing long-term storage</h1>

<ul>
 <li>When I started using plain text files to store my notes as Org mode files (which I am trying to replace)</li>
 <li>When I started using <a href="https://tiddlywiki.com">TiddlyWiki</a>, which can be opened/reused wherever I have access to a browser that executes Javascript. It doesn&rsquo;t necessarily have the longevity of plain text, but it&rsquo;s close.</li></ul>

<h1 id="i-was-prioritizing-re-reading-and-reflection">I was prioritizing (re-)reading and reflection</h1>

<ul>
 <li>When I stopped transcribing my notes into Org mode file, where I would never happen across them unless I specifically went looking for them.</li>
 <li>When I started transcribing my handwritten notes into TiddlyWiki, breaking my notes into smaller, more reusable chunks (tiddlers), organizing them all, and making small changes to TiddlyWiki&rsquo;s interface to encourage exploration.</li></ul>

<h1 id="i-am-prioritizing-focus">I am prioritizing focus</h1>

<ul>
 <li>When I step away from the computer to think with pen and paper.</li>
 <li>When I write notes by hand while reading papers or watching talks.</li>
 <li>When I close Slack after realizing I&rsquo;ve wasted too much time clicking on unread channels and not enough time working.</li></ul></p>
<p>
<em><a href="https://www.rkallos.com/blog/2020/04/04/what-my-choices-told-me-about-my-priorities/?utm_source=all&amp;utm_medium=RSS">April 05, 2020 02:57 AM</a></em>
</p>





<h2>April 03, 2020</h2>




<hr><h3 class="post"><a href="https://blog.separateconcerns.com" title="Separate Concerns">Pierre Chapuis (catwell)</a></h3>


<h4><a href="https://blog.separateconcerns.com/2020-04-03-2fa-pass-oathtool.html">Two-factor authentication with pass and oathtool</a></h4>
<p>
</p>
<p>
<em><a href="https://blog.separateconcerns.com/2020-04-03-2fa-pass-oathtool.html">April 03, 2020 04:20 PM</a></em>
</p>









<hr><h3 class="post"><a href="http://www.petecorey.com/" title="Pete Corey">Pete Corey (petecorey)</a></h3>


<h4><a href="http://www.petecorey.com/blog/2020/04/03/wolfram-style-cellular-automata-with-vim-macros/">Wolfram Style Cellular Automata with Vim Macros</a></h4>
<p>
Let's use substitutions and recursive macros to generate Wolfram-style cellular automata entirely within Vim. Why? Because it's Friday.</p>
<p>
<em><a href="http://www.petecorey.com/blog/2020/04/03/wolfram-style-cellular-automata-with-vim-macros/">April 03, 2020 12:00 AM</a></em>
</p>





<h2>April 02, 2020</h2>




<hr><h3 class="post"><a href="https://www.jeffcarp.com/" title="jeffcarp">Jeff Carpenter (jeffcarp)</a></h3>


<h4><a href="https://www.jeffcarp.com/posts/2020/vanguard-fund-vs-etf/">Vanguard Funds vs ETFs</a></h4>
<p>
After researching Vanguard funds vs. ETFs I still haven&rsquo;t found a good resource that lists in detail the benefits and downsides of each.
 A Vanguard mutual fund is provided and managed by Vanguard. You can only buy Vanguard funds on vanguard.com or over the phone. A Vanguard Exchange Traded Fund is packaged up like a stock and its shares can be traded on any market with any brokerage account.  This is my attempt to compile a comprehensive list of tradeoffs.</p>
<p>
<em><a href="https://www.jeffcarp.com/posts/2020/vanguard-fund-vs-etf/">April 02, 2020 08:23 PM</a></em>
</p>









<hr><h3 class="post"><a href="https://www.jeremymorgan.com/tags/programming/" title="programming on Jeremy Morgan :: Tech Blog">Jeremy Morgan (JeremyMorgan)</a></h3>


<h4><a href="http://feedproxy.google.com/~r/JeremyMorganProgramming/~3/9JksUeGLAK4/">All Pluralsight Content is Free in April</a></h4>
<p>
Times are tough right now. The world is struggling with this pandemic, and folks are staying inside to help stop the spread. Pluralsight has just announced that they&rsquo;re opening up the entire platform for the month of April. They&rsquo;re making all 7,000 courses and other content completely free for the month, no credit card needed.
We are all in this together. This is a great time to leverage the platform to build up skills.</p>
<p>
<em><a href="http://feedproxy.google.com/~r/JeremyMorganProgramming/~3/9JksUeGLAK4/">April 02, 2020 05:17 PM</a></em>
</p>





<h2>April 01, 2020</h2>




<hr><h3 class="post"><a href="http://www.kmjn.org/notes/" title="Mark's Notes">Mark J. Nelson (mjn)</a></h3>


<h4><a href="http://www.kmjn.org/notes/funded_masters_call.html">Opening for a funded Masters student</a></h4>
<p>
</p>
<p>
<em><a href="http://www.kmjn.org/notes/funded_masters_call.html">April 01, 2020 12:00 PM</a></em>
</p>









<hr><h3 class="post"><a href="https://sulami.github.io" title="sulami's blog">Robin Schroer (sulami)</a></h3>


<h4><a href="https://sulami.github.io/posts/common-lisp-restarts/index.html">Restarts in Common Lisp</a></h4>
<p>
<p><em><strong>Errata:</strong> An earlier version of this post was misrepresenting conditions as exceptions, which has been addressed.</em></p>
<hr />
<p>I have been reading <em><a href="http://www.gigamonkeys.com/book/">Practical Common Lisp</a></em> by Peter Seibel over the weekend, which is an excellent introduction to Common Lisp, showcasing its power by writing real programs. If you are interested in Lisp or programming languages at all, I recommend at least skimming it, it is free to read online.</p>
<p>Writing a Lisp-descended language professionally, and also living inside Emacs, I had dabbled in Common Lisp before, but I still found something I was not aware of, restarts. I do not think that this is a particularly well known feature outside the Lisp world, so I would like to spread awareness, as I think it is a particularly interesting take on error handling.</p>
<p>The book explains restarts using a mocked parser, which I will slightly modify for my example. Imagine you are writing an interpreter/compiler for a language. On the lowest level you are parsing lines to some internal representation:</p>
<div class="sourceCode"><pre class="sourceCode commonlisp"><code class="sourceCode commonlisp">(<span class="kw">define-condition</span><span class="fu"> invalid-line-error </span>(<span class="kw">error</span>)
  ((line :initarg :line :reader line)))

(<span class="kw">defun</span><span class="fu"> parse-line </span>(line)
  (<span class="kw">if</span> (valid-line-p line)
      (to-ir line)
    (<span class="kw">error</span> 'invalid-line-error :line line)))</code></pre></div>
<p>We define a condition, which is similar to an exception object with metadata in other languages<span><label for="sn-1" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-1" class="margin-toggle" /><span class="sidenote">A “condition” in Common Lisp, as has been explained to me by <a href="https://phoe.github.io">Michał “phoe” Herda</a>, is a way of signalling arbitrary events up the stack to allow running of additional code, not just signalling errors. They’re comparable to hooks in Emacs, but dynamically scoped to the current call stack.<br />
<br />
</span></span>, and a function which attempts to parse a single line.<span><label for="sn-2" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-2" class="margin-toggle" /><span class="sidenote">This is assuming of course that a line always represents a complete parsable entity, but this is only an example after all.<br />
<br />
</span></span> If it turns out that the line is invalid, it signals a condition up the stack. We attach the line encountered, in case we want to use it for error reporting.</p>
<p>Now imagine your parser is used in two situations: there is a compiler, and a REPL. For the compiler, you would like to abort at the first invalid line you encounter, which is what we are currently set up to do. But for the REPL, you would like to ignore the line and just continue with the next line.<span><label for="sn-3" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-3" class="margin-toggle" /><span class="sidenote">I’m not saying that is necessarily a good idea, but it is something some REPLs do, for example some Clojure REPLs.<br />
<br />
</span></span></p>
<p>To ignore a line, we would have to either do it on a low-level, return <code>nil</code> instead of signalling and filter out <code>nil</code> values up the stack. Handling the condition will not help us a lot, because at that point we have lost our position in the file already, or have we?</p>
<p>The next layer up is parsing a collection of lines:</p>
<div class="sourceCode"><pre class="sourceCode commonlisp"><code class="sourceCode commonlisp">(<span class="kw">defun</span><span class="fu"> parse-lines </span>(lines)
  (<span class="kw">loop</span> for line in lines
        for entry <span class="op">=</span> (<span class="kw">restart-case</span>
                     (parse-line line)
                     (skip-line () <span class="kw">nil</span>))
        <span class="kw">when</span> entry collect it))</code></pre></div>
<p>This is where the magic begins. The <code>loop</code> construct just loops over the lines, applies <code>parse-line</code> to every element of the list, and returns a list containing all results which are not <code>nil</code>. The feature I am showcasing in this post is <code>restart-case</code>. Think of it this way: it does <strong>not</strong> handle a condition, but when the stack starts unwinding <span><label for="sn-4" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-4" class="margin-toggle" /><span class="sidenote">Technically not unwinding yet, at least not in Common Lisp.<br />
<br />
</span></span> because we signalled a condition in <code>parse-line</code>, it registers a possible restart-position. If the condition is handled at some point,<span><label for="sn-5" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-5" class="margin-toggle" /><span class="sidenote">If it isn’t caught, you will get dropped into the debugger, which also gives you the option to restart.<br />
<br />
</span></span> the signal handler can choose to restart at any restart-point that has been registered down the stack.</p>
<p>Now let us have a look at the callers:</p>
<div class="sourceCode"><pre class="sourceCode commonlisp"><code class="sourceCode commonlisp">(<span class="kw">defun</span><span class="fu"> parse-compile </span>(lines)
  (<span class="kw">handler-case</span>
      (parse-lines lines)
    (invalid-line-error (e)
                        (print-error e))))

(<span class="kw">defun</span><span class="fu"> parse-repl </span>(lines)
  (<span class="kw">handler-bind</span> ((invalid-line-error
                  #'(<span class="kw">lambda</span> (e)
                      (<span class="kw">invoke-restart</span> 'skip-line))))
    (parse-lines lines)))</code></pre></div>
<p>There is a lot to unpack here. The compiler code is using <code>handler-case</code>, which is comparable to <code>catch</code> in other languages. It unwinds the stack to the current point and runs the signal handling code, in this case <code>print-error</code>.</p>
<p>Because we do not actually want to unwind the stack all the way, but resume execution inside the <code>loop</code> in <code>parse-lines</code>, we use a different construct, <code>handler-bind</code>, which automatically handles <code>invalid-line-error</code> and invokes the <code>skip-line</code> restart. If you scroll up to <code>parse-lines</code> now, you will see that the restart clause says, if we restart here, just return <code>nil</code>, and <code>nil</code> will be filtered on the very next line by <code>when entry</code>.</p>
<p>The elegance here is the split of signal handling code, and decisions about which signal handling approach to take. You can register a lot of different <code>restart-case</code> statements throughout the stack, and let the caller decide if some signals are okay to ignore, without the caller having to have intricate knowledge of the lower-level code.<span><label for="sn-6" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-6" class="margin-toggle" /><span class="sidenote">It does need to know about the registered <code>restart-case</code> statements though, at least by name.<br />
<br />
</span></span></p>
<p>If you want to learn more about this, make sure to have a look at the book, it goes into much more detail than I did here.</p></p>
<p>
<em><a href="https://sulami.github.io/posts/common-lisp-restarts/index.html">April 01, 2020 12:00 AM</a></em>
</p>





<h2>March 29, 2020</h2>




<hr><h3 class="post"><a href="http://shape-of-code.coding-guidelines.com" title="The Shape of Code">Derek Jones (derek-jones)</a></h3>


<h4><a href="http://shape-of-code.coding-guidelines.com/2020/03/29/influential-programming-languages-some-of-the-considerations/">Influential programming languages: some of the considerations</a></h4>
<p>
Which programming languages have been the most influential? Let&#8217;s define an influential language as one that has had an impact on lots of developers. What impact might a programming language have on developers? To have an impact a language needs to be used by lots of people, or at least have a big impact on [&#8230;]</p>
<p>
<em><a href="http://shape-of-code.coding-guidelines.com/2020/03/29/influential-programming-languages-some-of-the-considerations/">March 29, 2020 10:38 PM</a></em>
</p>





<h2>March 28, 2020</h2>




<hr><h3 class="post"><a href="https://venam.nixers.net/blog/" title="Venam's Blog">Patrick Louis (venam)</a></h3>


<h4><a href="https://venam.nixers.net/blog/unix/2020/03/29/distro-pkgs.html">Software Distributions And Their Roles Today</a></h4>
<p>
<p><img src="https://venam.nixers.net/blog/assets/mailroom.jpg" alt="Mailroom" /></p>

<p><em>NB</em>: This is a repost on this blog of a post made on <a href="https://nixers.net/showthread.php?tid=2192">nixers.net</a></p>

<h2 id="what-is-a-distribution">What is a distribution</h2>

<p>What are software distributions? You may think you know everything there
is to know about the term software distribution, but take a moment to
think about it, take a step back and try to see the big picture.</p>

<p>We often have in mind the thousands of Linux distributions when we hear
it, however, this is far from limited to Linux, BSD, Berkeley Software
Distribution, has software distribution right in the name. Android,
and iOS are software distributions too.</p>

<p>Actually, it’s so prevalent, we may have stopped paying attention to
the concept. We find it hard to put a definition together.<br />
There’s definitely the part about distributing software in it. Software
that may be commercial or not, open source or not.<br />
To understand it better maybe investigating what problems software
distributions address would clear things up.</p>

<p>Let’s imagine a world before software distributions, does that world
exist? A world where software stays within boundaries, not shared with anyone
outside of it.<br />
Once we break these boundaries and we want to share it, we’ll find that we
have to package all the software together in a meaningful way, configure
them so that they work well together, adding some glue in between when
necessary, find the appropriate medium to distribute the bundle, get
it all from one end to another safely, make sure it installs properly,
and follow up on it.</p>

<p>Thus, software distribution is about the mechanism and the community
that takes the burden and decisions to build an assemblage of coherent
software that can be shipped.</p>

<p>The operating system, or kernel if you like, could be, and is often,
part of the collage offered, a software just like others.</p>

<p>The people behind it are called distribution maintainers, or package
maintainers. Their role vary widely, they could write the software that
stores all the packages called the repository, maintain a package manager
with its format, maintain a full operating system installer, package and
upload software they built or that someone else built on a specific time
frame/life cycle, make sure there aren’t any malicious code uploaded on
the repository, follow up on the latest security issues and bug reports,
fix third party software to fit the distribution philosophical choices
and configurations, and most importantly test, plan, and make sure
everything holds up together.<br />
These maintainers are the source of trust of the distribution, they
take responsibility for it. In fact, I think it’s more accurate to call
them distributors.</p>

<h2 id="different-ways-to-approach-it">Different ways to approach it</h2>

<p>There’s so many distributions it can make your head spin. The software
world is booming, especially the open source one. For instance, we can
find bifurcations of distributions that get copied by new maintainers
and divert. This creates a tree like aspect, a genealogy of both common
ancestors and/or influences in technical and philosophical choices.<br />
Overall, we now have a vibrant ecosystem where a thing learned on a
branch can help a completely unrelated leaf on another tree. There’s
something for everyone.</p>

<h3 id="target-and-speciality">Target and speciality</h3>

<p>So what could be so different between all those software distributions,
why not have a single platform that everyone can build on.</p>

<p>One thing is specialization and differentiation. Each distro caters to
a different audience and is built by a community with its philosophy.</p>

<p>Let’s go over some of them:</p>

<ul>
  <li>A distribution can support specific sets and combinations of hardware:
from CPU ISA to peripherals drivers</li>
  <li>A distribution may be specifically optimized for a type of environment:
Be it desktop, portable mobile device, servers, warehouse size computers,
embedded devices, virtualised environment, etc..</li>
  <li>A distribution can be commercially backed or not</li>
  <li>A distribution can be designed for different levels of knowledge in a
domain, professional or not. For instance, security research, scientific
computing, music production, multimedia box, HUD in cars, mobile device
interface, etc..</li>
  <li>A distribution might have been certified to follow certain standards
that need to be adhere to in professional settings, for example security
standards and hardening</li>
  <li>A distribution may have a single purpose in a commodity machine,
specific machine functionalities such as firewall, a computer cluster,
a router, etc..</li>
</ul>

<p>That all comes to the raison d’être, the philosophy of the distribution,
it guides every decision the maintainers have to make. It guides how they
configure every software, how they think about security, portability,
comprehensiveness.</p>

<p>For example, if a distribution cares about free software, it’s going to
be strict about what software it includes and what licenses it allows
in its repository, having software to check the consistency of licenses
in the core.<br />
Another example is if their goal is to target a desktop audience then
internationalization, ease of use, user friendliness, having a large
number of packages, is going to be prioritized. While, again, if the
target is a real time embedded device, the size of the kernel is going
to be small, configured and optimized for this purpose, and limiting and
choosing the appropriate packages that work in this environment. Or if
it’s targeted at advanced users that love having control of their machine,
the maintainers will choose to let the users make most of the decisions,
providing as many packages as possible with the latest version possible,
with a loosely way to install the distribution, having a lot of libraries
and software development tools.</p>

<p>What this means is that a distribution does anything it can to provide
sane defaults that fit its mindset. It composes and configures a layer
of components, a stack of software.</p>

<h3 id="the-layering">The layering</h3>

<p>Distribution maintainers often have at their disposition different blocks
and the ability to choose them, stacking them to create a unit we call a
software distribution. There’s a range of approaches to this, they could
choose to have more, or less, included in what they consider the <em>core</em> of
the distribution and what is externally less important to it.<br />
Moreover, sometimes they might even leave the core very small and loose,
instead providing the glue software that makes it easy for the users
to choose and swap the blocks at specific stages in time: installation,
run time, maintenance mode, etc..</p>

<p>So what are those blocks of interdependent components.</p>

<p>The first part is the method of installation, this is what everything
hinges on, the starting point.</p>

<p>The second part is the kernel, the real core of all operating systems
today. But that doesn’t mean that the distribution has to enforce
it. Some distributions may go as far as to provide multiple kernels
specialised in different things or none at all.</p>

<p>The third part is the filesystem and file hierarchy, the component that
manages where and how files are spread out on the physical or virtual
hardware. This could be a mix and match where sections of the file system
tree are stored on separate filesystems.</p>

<p>The fourth part is the init system, PID 1. This choice has generated
a lot of contention these days. PID 1 being the mother process of all
other processes on the system. What role it has and what functionalities
it should include is a subject of debate.</p>

<p>The fifth part is composed of the shell utilities, what we sometimes
refer to as the userland or user space, as its the first layer the user
can directly interface with to have control of the operating system, the
place where processes run. The userland implementations on Unix-based
systems usually tries to follow the POSIX standard. There are many such
implementations, also subject of contention.</p>

<p>The sixth part is made up of services and their management. The daemons,
long running processes that keep the system in order. Many argue if the
management functionality should be part of the init system or not.</p>

<p>The seventh part is documentation. Often it is forgotten but it is still
very important.</p>

<p>The last part is about everything else, all the user interfaces and
utilities a user can have and ways to manage them on the system.</p>

<h3 id="stable-releases-vs-rolling">Stable releases vs Rolling</h3>

<p>There exists a spectrum on which distributions place themselves when
it comes to keeping up to date with the versions of the software they
provide. This most often applies to external third party open source
software.<br />
The spectrum is the following: Do we allow the users to always have the
latest version of every software while running the risk of accidentally
breaking their system, what we call bleeding edge or rolling distro, or
do we take a more conservative approach and take the time to test every
software properly before allowing it in the repository, while not having
all the latest updates, features, and optimizations of those software,
what we call release based distro.</p>

<p>The extreme of the first scenario would be to let users directly download
from the software vendor/creator source code repository, or the opposite,
let the software vendor/creator push directly to the distribution
repository. Which could easily break or conflict with the user’s system
or lead to security vulnerability. We’ll come back to this later, as
this could be avoided if the software runs in a containerized environment.</p>

<p>When it comes to release distributions, it usually involves having a long
term support stable version that keeps receiving and syncing with the
necessary security updates and bug fixes on the long run while having
another version running a bit ahead testing the future changes. On
specific time frames, users can jump to the latest release of the
distribution, which may involve a lot of changes in both configuration
and software.<br />
Some distributions decide they may want to break ABI or API of the kernel
upon major releases, that means that everything in the system needs to
be rebuilt and reinstalled.</p>

<p>The release cycle, and the rate of updates is really a spectrum.</p>

<p>When it comes to updates, in both cases, the distribution maintainers
have to decide how to communicate and handle them. How to let the users
know what changes. If a user configuration was swapped for a new one or
merged with the new one, or copied aside.<br />
Communication is essential, be it through official channels, logging,
mails, etc.. Communication needs to be bi-directional, users report bugs
and maintainers posts what their decisions are and if users need to be
involved in them. This creates the community around the distribution.</p>

<p>Rolling releases require intensive efforts from package maintainers as
they constantly have to keep up with software developers. Especially
when it comes to the thousands of newest libraries that are part of
recent programming languages and that keep on increasing.</p>

<p>Various users will want precise things out of a system. Enterprise
environments and mission critical tasks will prefer stable releases,
and software developers or normal end users may prefer to have the
ability to use the latest current software.</p>

<h3 id="interdistribution-standard">Interdistribution standard</h3>

<p>With all this, can’t there be an interdistribution standard that creates
order, and would we want such standard.</p>

<p>At the user level, the differences are not always noticeable, most
of the time everything seems to work as Unix systems are expected to
work.<br />
There’s no real standard between distributions other than that they are
more or less following the POSIX standards.</p>

<p>Within the Linux ecosystem, the Free Standards Group tries to improve
interoperability of software by fixing a common Linux ABI, file system
hierarchy, naming conventions, and more. But that’s just the tip of the
iceberg when it comes to having something that works interdistributions.</p>

<p>Furthermore, each part of the layering we’ve seen before could be said
to have its own standards: There are desktop interoperability standards,
filesystem standards, networking standards, security standards, etc..</p>

<p>The biggest player right now when it comes to this is systemd in
association with the free desktop group, it tries to create (force)
an interdistribution standard for Linux distribution.</p>

<p>But again, the big Question: Do we actually want such inter-distribution
standards, can’t we be happy with the mix and match we currently
have. Would we profit from such thing?</p>

<h2 id="the-package-manager-and-packaging">The package manager and packaging</h2>

<p>Let’s now pay attention to the package themselves, how we store them, how
we give secure access to them, how we are able to search amongst them,
download them, install them, remove them, and anything related to their
local management, versioning, and configuration.</p>

<h3 id="method-of-distribution">Method of distribution</h3>

<p>How do we distribute software, share them, what’s the front-end to
this process.</p>

<p>First of all, where do we store this software.</p>

<p>Historically and still today, software can be shared via physical
medium such as CD-ROM, DVD, USBs, etc.. This is common when it comes
to proprietary vendors to have the distribution come with a piece of
hardware they are selling, it’s also common for the procurement of the
initial installation image.<br />
However, with today’s hectic software growth, using a physical medium
isn’t flexible. Sharing over the internet is more convenient, be it via
FTP, HTTP, HTTPS, a publicly available svn or git repo, via central
website hubs such as Github or appliation stores such the ones Apple
and Google provide.</p>

<p>A requirement is that the storage and the communication to it should be
secure, reliable against failures, and accessible from anywhere. Thus,
replication is often done to avoid failures but also to have a sort of
edge network speeding effect across the world, load balancing. Replication
could be done in multiple ways, it could be a P2P distributed system
for instance.</p>

<p>How we store it and in what format is up to the repository
maintainers. Usually, this is a file system with a software API users
can interact with over the wire. Two main format strategies exist:
source based repositories and binary repositories.</p>

<p>Second of all, who can upload and manage the host of packages. Who has
the right to replicate the repository.</p>

<p>As a source of truth for the users, it is important to make sure the
packages have been verified and secured before being accepted on the
repository.</p>

<p>Many distribution have the maintainers be the only ones that are able
to do this. Giving them cryptographic keys to sign packages and validate
them.</p>

<p>Others have their own users build the packages, send them to a central
hub for automatic or manual verification and then uploaded to the
repository. Each user having their own cryptographic key for signature
verification.</p>

<p>This comes down to an issue of trust and stability. Having the users
upload packages isn’t always feasible when using binary packages if the
individual packages are not containerized properly.</p>

<p>There’s a third option, the road in between, having the two types, the
core managed by the official distribution maintainers and the rest by
its user community.</p>

<p>Finally, the packages reach the user.</p>

<p>How the user interact with the repository locally and remotely depends on
the package management choices. Do users cache a version of the remote
repository, like is common with the BSD port tree system.<br />
How flexible can it be to track updates, locking versions of software,
allowing downgrades. Can users download from different sources. Can
users have multiple version of the same software on the their machine.</p>

<h3 id="format">Format</h3>

<p>As we’ve said there are two main philosophy of software sharing format:
source code port-style and pre-built binary packages.</p>

<p>The software that manages those on the user side is called the package
manager, it’s the link with the repository. Though, in source based repo
I’m not sure we can call them this way, but regardless I’ll still refer
to them as such.<br />
Many distributions create their own or reuse a popular one. It does the
search, download, install, update, and removal of local software. It’s
not a small task.</p>

<p>The rule of the book is that if it isn’t installed by the package manager
then it won’t be aware of its existence. Noting that distributions don’t
have to be limited to a single package manager, there could be many.</p>

<p>Each package manager relies on a specific format and metadata to be able
to manage software, be it source or binary formatted. This format can
be composed of a group of files or a single binary file with specific
information segments that together create recipes that help throughout
its lifecycle. Some are easier to put together than others, incidentally
allowing more user contributions.</p>

<p>Here’s a list of common information that the package manager needs:</p>

<ul>
  <li>The package name</li>
  <li>The version</li>
  <li>The description</li>
  <li>The dependencies on other packages, along with their versions</li>
  <li>The directory layout that needs to be created for the package</li>
  <li>Along with the configuration files that it needs and if they should
be overwritten or not</li>
  <li>An integrity, or ECC, on all files, such as SHA256</li>
  <li>Authenticity, to know that it comes from the trusted source, such as
cryptographic signatures checked against a trusted store on the user’s
machine</li>
  <li>If this is a group of package, meta package, or a direct one</li>
  <li>The actions to take on certain events: pre-installation,
post-installation, pre-removal, and post removal</li>
  <li>If there are specific configuration flags or parameter to pass to the
package manager upon installation</li>
</ul>

<p>So what’s the advantage of having pre-compiled binary packages instead
of cloning the source code and compiling ourselves. Won’t that remove
a burden from package maintainers.</p>

<p>One advantage is that pre-compiled packages are convenient, it’s easier to
download them and run them instantly. It’s also hard, if not impossible,
these days, and energy intensive, to compile huge software such as
web browsers.<br />
Another point, is that proprietary software are often already distributed
as binary packages, which would creates a mix of source and binary
packages.</p>

<p>Binary formats are also space efficient as the code is stored in a
compressed archived format. For example: APK, Deb, Nix, ORB, PKG, RPM,
Snap, pkg.tar.gz/xz, etc..<br />
Some package managers may also choose to leave the choice of compression
up to the user and dynamically discern from its configuration file how
to decompress packages.</p>

<p>Let’s add that there exists tools, such as “Alien”, that facilitate the
job of package maintainers by converting from one binary package format
to another.</p>

<h2 id="conflict-resolution--dependencies-management">Conflict resolution &amp; Dependencies management</h2>

<h3 id="resolving-dependencies">Resolving dependencies</h3>

<p>One of the hardest job of the package manager is to resolve dependencies.</p>

<p>A package manager has to keep a list of all the packages and their
versions that are currently installed on the system and their
dependencies.<br />
When the user wants to install a package, it has to take as input the
list of dependencies of that package, compare it against the one it
already has and output a list of what needs to be installed in an order
that satisfies all dependencies.</p>

<p>This is a problem that is commonly encountered in the software development
world with build automation utilities such as make. The tool creates a
directed acyclic graph (DAG), and using the power of graph theory and the
acyclic dependencies principle (ADP) tries to find the right order. If
no solution is found, or if there are conflicts or cycles in the graph,
the action should be aborted.</p>

<p>The same applies in reverse, upon removal of the package. We have to make
a decision, do we remove all the other packages that were installed as
a dependency of that single one. What if newer packages depend on those
dependencies, should we only allow the removal of the unused dependencies.</p>

<p>This is a hard problem, indeed.</p>

<h3 id="versioning">Versioning</h3>

<p>This problem increases when we add the factor of versioning to the mix,
if we allow multiple versions of the same software to be installed on
the system.</p>

<p>If we don’t, but allow switching from one version to another, do we also
switch all other packages that depend on it too.</p>

<p>Versioning applies everywhere, not only to packages but to release
versions of the distribution too. A lot of them attach certain version
of packages to specific releases, and consequentially releases may have
different repositories.</p>

<p>The choice of naming conventions also plays a role, it should convey to
users what they are about and if any changes happened.</p>

<p>Should the package maintainer follow the naming convention of the software
developer or should they use their own. What if the name of two software
conflict with one another, this makes it impossible to have it in the
repo, some extra information needs to be added.</p>

<p>Do we rely on semantic versioning, major, minor, patch, or do we rely
on names like so many distributions releases do (toy story, deserts,
etc..), or do we rely on the date it was released, or maybe simply an
incremental number.</p>

<p>All those convey meaning to the user when they search and update packages
from the repository.</p>

<h3 id="static-vs-dynamic-linking">Static vs dynamic linking</h3>

<p>One thing that may not apply to source based distro, is the decision
between building packages as statically linked to libraries or dynamically
linked.</p>

<p>Dynamic linking is the process in which a program chooses not to include
a library it depends upon in its executable but only a reference to it,
which is then resolved at run-time by a dynamic linker that will load
the shared object in memory upon usage. On the opposite, static linking
means storing the libraries right inside the compiled executable program.</p>

<p>Dynamic linking is useful when many software rely on the same library,
thus only a single instance of the library has to be in memory at a time.
Executables sizes are also smaller, and when it is updated all programs
relying on it get the benefit (as long as the interfaces are the same).</p>

<p>So what does this have to do with distributions and package management.</p>

<p>Package managers in dynamic linking environment have to take care of
the versions of the libraries that are installed and which packages
depend on them. This can create issues if different packages rely on
different versions.</p>

<p>For this reason, some distro communities have chosen to get rid of dynamic
linking altogether and rely on static linking, at least for things that
are not related to the core system.</p>

<p>Another incidental advantage of static linking is that it doesn’t have
to resolve dependencies with the dynamic linker, which makes it gain a
small boost in speed.</p>

<p>So static builds simplify the package management process. There
doesn’t need to be a complex DAG because everything is self
contained. Additionally, this can allow to have multiple versions of the
same software installed alongside one another without conflicts. Updates
and rollbacks are not messy with static linking.</p>

<p>This gives rise to more containerised software, and continuing on this
path leads to market platforms such as Android and iOS where distribution
can be done by the individual software developers themselves, skipping the
middle-man altogether and giving the ability for increasingly impatient
users to always have the latest version that works for their current
OS. Everything is self-packaged.<br />
However, this relies heavily on the trust of the
repository/marketplace. There needs to be many security mechanisms in
place to not allow rogue software to be uploaded. We’ll talk more about
this when we come back to containers</p>

<p>This is great for users and, from a certain perspective, software
developers too as they can directly distribute pre-built packages,
especially when there’s a stable ABI for the base system.</p>

<p>All this breaks the classic distribution scheme we’re accustomed to on
the desktop.</p>

<p>Is it all roses and butterflies, though.</p>

<p>As we’ve said, packages take much more space with static linking, thus
wasting resources (storage, memory, power).<br />
Moreover, because it’s a model where software developers push directly
to users, this removes the filtering that distribution maintainers have
over the distro, and encourages licenses uncertainties. There’s no more
overall philosophies that surrounds the distribution.<br />
There’s also the issue of library updates, the weight is on the software
developers to make sure they have no vulnerabilities or bugs in their
code. This adds a veil on which software uses what, all we see is the
end products.</p>

<p>From a software developer using this type of distribution perspective,
this adds extra steps to download the source code of each libraries their
software depends on, and build each one individually. Turning the system
into a source based distro.</p>

<h3 id="reproducibility">Reproducibility</h3>

<p>Because package management is increasingly becoming messier the past few
years, a new trend has emerged to put back a sense of order in all this,
reproducibility.</p>

<p>It has been inspired by the world of functional programming and the world
of containers. Package managers that respect reproducibility have each
of their builds asserted to always produce the same output (functionality wise, though there could be differences, see footnote for info).<br />
They allow for packages of different versions to be installed alongside
one another, each living in its own tree, and it allows normal users
to install packages only them can access. Thus, many users can have
different packages.</p>

<p>They can be used as universal package managers, installed alongside any
other package managers without conflict.</p>

<p>The most prominent example is Nix and Guix, that use a purely functional
deployment model where software is installed into unique directories
generated through cryptographic hashes. Dependencies from each software
are included within each hash, solving the problem of dependency
hell. This approach to package management promises to generate more
reliable, reproducible, and portable packages.</p>

<h3 id="stateless-and-verifiable-systems">Stateless and verifiable systems</h3>

<p>The discussion about trust, portability, and reproducibility can also
be applied to the whole system itself.</p>

<p>When we talked about repositories as marketplaces, where software
developers push directly to it and the users have instant access to the
latest version, we said it was mandatory to have additional measures
for security.</p>

<p>One of them is to containerised, to sandbox every software. Having each
software run in their own space not affecting the rest of the system
resources. This removes the heavy burden of auditing and verifying each
and every software. Many solutions exist to achieve this sandboxing, from
docker, chroot, jails, firejail, selinux, cgroups, etc..</p>

<p>We could also distance the home directory of the users, making them
self-contained, never installing or modifying the globally accessible
places.</p>

<p>This could let us have the core of the system verifiable as it is not
changed, as it stays pristine. Making sure it’s secure would be really
easy.</p>

<p>The idea of having the user part of the distro as atomic, movable,
containerized, and the rest reproducible is game changing. But again,
do we want to move to a world where every distro is interchangeable?</p>

<h2 id="do-distros-matter-with-containers-virtualisation-and-specific-and-universal-package-managers">Do Distros matter with containers, virtualisation, and specific and universal package managers</h2>

<p>It remains to be asked if distributions still have a role today with
all the containers, virtualisation, and specific and universal package
managers.</p>

<p>When it comes to containers, they are still very important as they most
often are the base of the stack the other components build upon.</p>

<p>The distribution is made up of people that work together to build and
distribute the software and make sure it works fine. It isn’t the role
of the person managing the container and much more convenient for them
to rely on a distribution.</p>

<p>Another point, is that containers hide vulnerabilities, they aren’t
checked after they are put together, while on the other hand, distribution
maintainers, have as a role to communicate and follow up on security
vulnerabilities and other bugs. Community is what solves daunting problems
that everyone shares.<br />
A system administrator building containers can’t possibly have the
knowledge to manage and builds hundreds of software and libraries and
ensure they work well together.</p>

<h3 id="if-packages-are-self-contained">If packages are self-contained</h3>

<p>Do distributions matter if packages are self-contained?</p>

<p>To an extent they do as they could be in this ecosystem the
providers/distributors of such universal self-contained packages. And
as we’ve said it is important to keep the philosophy of the distro and
offer a tested toolbox that fits the use case.</p>

<p>What’s more probable is that we’ll move to a world with multiple package
managers, each trusted for its specific space and purpose. Each with a
different source of philosophical and technical truth.</p>

<h3 id="programming-language-package-management-specific">Programming language package management specific</h3>

<p>This phenomena is already exploding in the world of programming language
package management.</p>

<p>The speed and granularity at which software is built today is almost
impossible to follow using the old method of packaging. The old software
release life cycle has been thrown out the window. Thus language-specific
tools were developed, not limited to installing libraries but also
software. We can now refer to the distribution offered package manager as
system-level and others as application-level or specific package managers.</p>

<p>Consequentially, the complexity and conflicts within a system has
exploded, and distribution package managers are finding it pointless
to manage and maintain anything that can already be installed via those
tools. Vice-versa, the specific tool makers are also not interested in
having what they provide included in distribution system-level package
managers.</p>

<p>Package managers that respect reproducibility, such as Nix, that we’ve
mentioned, handle such cases more cleanly as they respect the idea
of locality, everything residing withing a directory tree that isn’t
maintained by the system-level package manager.</p>

<p>Again, same conclusion here, we’re stuck with multiple package managers
that have different roles.</p>

<h3 id="going-distro-less">Going distro-less</h3>

<p>A popular topic in the container world is “distro-less”.</p>

<p>It’s about replacing everything provided in a distribution, removing
it’s customization, or building an image from scratch and maybe relying
on universal package managers or none.</p>

<p>The advantage of such containers is that they are really small and
targeted for a single purpose. This let the sysadmin have full control
of what happens on that box.</p>

<p>However, remember that there’s a huge cost to controlling everything,
just like we mentioned earlier. This moves the burden upon the sysadmin
to manage and be responsible to keep up with bugs and security updates
instead of the distribution maintainers</p>

<h2 id="conclusion">Conclusion</h2>

<p>With everything we’ve presented about distributions, I hope we now have
a clearer picture of what they are providing and their place in our
current times.</p>

<p>What’s your opinion on this topic? Do you like the diversity? Which stack
would you use to build a distribution? What’s your take on static builds,
having users upload their own software to the repo? Do you have a solution
to the trust issue? How do you see this evolve?</p>

<p>More discussion here: <a href="https://nixers.net/showthread.php?tid=2192">https://nixers.net/showthread.php?tid=2192</a></p>

<p><em>EDIT</em>: It has come to my understanding that I’ve conflated the meaning
of “reproducible”, as in reproducing bit-for-bit identical software, and
“reproducible”, as in recreate the functionality of an operating system
in this article. I’ve instead taken it to mean anything that we’re sure
we could recreate functionality without breaking it, and used verifiable
as anything that is identical. Guix and nixos are currently accomplishing
the functionality part.</p>

<hr />

<p>What is a distribution</p>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Linux_distribution">https://en.wikipedia.org/wiki/Linux_distribution</a></li>
</ul>

<p>Different ways to approach it</p>

<ul>
  <li><a href="https://distrowatch.com/">https://distrowatch.com/</a></li>
  <li><a href="https://www.howtogeek.com/132624/htg-explains-whats-a-linux-distro-and-how-are-they-different/">https://www.howtogeek.com/132624/htg-explains-whats-a-linux-distro-and-how-are-they-different/</a></li>
  <li><a href="https://fossbytes.com/difference-linux-bsd-open-source/">https://fossbytes.com/difference-linux-bsd-open-source/</a></li>
  <li><a href="https://unix.stackexchange.com/questions/24755/what-are-the-main-differences-between-bsd-and-linux-based-operating-systems">https://unix.stackexchange.com/questions/24755/what-are-the-main-differences-between-bsd-and-linux-based-operating-systems</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Comparison_of_Linux_distributions">https://en.wikipedia.org/wiki/Comparison_of_Linux_distributions</a></li>
  <li><a href="https://changelog.complete.org/archives/9317-has-linux-lost-its-way-comments-prompt-a-debian-developer-to-revisit-freebsd-after-20-years">https://changelog.complete.org/archives/9317-has-linux-lost-its-way-comments-prompt-a-debian-developer-to-revisit-freebsd-after-20-years</a></li>
  <li><a href="https://michael.stapelberg.ch/posts/2019-03-10-debian-winding-down/">https://michael.stapelberg.ch/posts/2019-03-10-debian-winding-down/</a></li>
  <li><a href="http://changelog.complete.org/archives/9971-a-partial-defense-of-debian">http://changelog.complete.org/archives/9971-a-partial-defense-of-debian</a></li>
</ul>

<p>Package management</p>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Package_management_system">https://en.wikipedia.org/wiki/Package_management_system</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Software_configuration_management">https://en.wikipedia.org/wiki/Software_configuration_management</a></li>
  <li><a href="https://whydoesaptnotusehttps.com/">https://whydoesaptnotusehttps.com/</a></li>
  <li><a href="https://blog.packagecloud.io/eng/2018/02/21/attacks-against-secure-apt-repositories/">https://blog.packagecloud.io/eng/2018/02/21/attacks-against-secure-apt-repositories/</a></li>
  <li><a href="https://justi.cz/security/2019/01/22/apt-rce.html">https://justi.cz/security/2019/01/22/apt-rce.html</a></li>
  <li><a href="https://fosdem.org/2020/schedule/event/sdnpof/">https://fosdem.org/2020/schedule/event/sdnpof/</a></li>
  <li><a href="https://nixers.net/showthread.php?tid=1883">https://nixers.net/showthread.php?tid=1883</a></li>
  <li><a href="https://nixers.net/showthread.php?tid=2049">https://nixers.net/showthread.php?tid=2049</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Software_build">https://en.wikipedia.org/wiki/Software_build</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Package_format">https://en.wikipedia.org/wiki/Package_format</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Deb_(file_format)">https://en.wikipedia.org/wiki/Deb_(file_format)</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Android_application_package">https://en.wikipedia.org/wiki/Android_application_package</a></li>
  <li><a href="http://ftp.rpm.org/max-rpm/s1-rpm-file-format-rpm-file-format.html">http://ftp.rpm.org/max-rpm/s1-rpm-file-format-rpm-file-format.html</a></li>
  <li><a href="https://askubuntu.com/questions/761245/what-is-the-snap-packaging-format">https://askubuntu.com/questions/761245/what-is-the-snap-packaging-format</a></li>
</ul>

<p>Conflict resolution &amp; dependencies management</p>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Directed_acyclic_graph">https://en.wikipedia.org/wiki/Directed_acyclic_graph</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Acyclic_dependencies_principle">https://en.wikipedia.org/wiki/Acyclic_dependencies_principle</a></li>
  <li><a href="https://fosdem.org/2020/schedule/event/package_management_panel/">https://fosdem.org/2020/schedule/event/package_management_panel/</a></li>
  <li><a href="https://fosdem.org/2020/schedule/event/ggaaattyp/">https://fosdem.org/2020/schedule/event/ggaaattyp/</a></li>
  <li><a href="https://www.tecmint.com/nix-package-manager-for-linux/">https://www.tecmint.com/nix-package-manager-for-linux/</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Nix_package_manager">https://en.wikipedia.org/wiki/Nix_package_manager</a></li>
  <li><a href="https://en.wikipedia.org/wiki/GNU_Guix">https://en.wikipedia.org/wiki/GNU_Guix</a></li>
  <li><a href="http://0pointer.net/blog/projects/stateless.html">http://0pointer.net/blog/projects/stateless.html</a></li>
  <li><a href="https://fosdem.org/2020/schedule/event/rhdlp/ homed">https://fosdem.org/2020/schedule/event/rhdlp/ homed</a></li>
  <li><a href="https://fosdem.org/2020/schedule/event/ussftbasd/">https://fosdem.org/2020/schedule/event/ussftbasd/</a></li>
</ul>

<p>Do Distros matter with containers, virtualisation, and specific and universal package managers</p>

<ul>
  <li><a href="http://0pointer.net/blog/revisiting-how-we-put-together-linux-systems.html">http://0pointer.net/blog/revisiting-how-we-put-together-linux-systems.html</a></li>
  <li><a href="https://apebox.org/wordpress/linux/1229">https://apebox.org/wordpress/linux/1229</a></li>
  <li><a href="https://fosdem.org/2020/schedule/event/dldsmwc/">https://fosdem.org/2020/schedule/event/dldsmwc/</a></li>
  <li><a href="https://blog.liw.fi/posts/2018/02/17/what_is_debian_all_about_really_or_friction_packaging_complex_applications/">https://blog.liw.fi/posts/2018/02/17/what_is_debian_all_about_really_or_friction_packaging_complex_applications/</a></li>
  <li><a href="http://joeyh.name/blog/entry/futures_of_distributions/">http://joeyh.name/blog/entry/futures_of_distributions/</a></li>
  <li><a href="https://opensource.com/article/19/2/linux-distributions-still-matter-containers">https://opensource.com/article/19/2/linux-distributions-still-matter-containers</a></li>
</ul>

<p>Attributions:</p>

<ul>
  <li>Marjory Collins / Public domain</li>
</ul></p>
<p>
<em><a href="https://venam.nixers.net/blog/unix/2020/03/29/distro-pkgs.html">March 28, 2020 10:00 PM</a></em>
</p>









<hr><h3 class="post"><a href="https://blog.ovalerio.net" title="Gonçalo Valério">Gonçalo Valério (dethos)</a></h3>


<h4><a href="https://blog.ovalerio.net/archives/1880">CSP headers using Cloudflare Workers</a></h4>
<p>
Last January I made a small post about setting up a &#8220;Content-Security-Policy&#8221; header for this blog. On that post I described the steps I took to reach a final result, that I thought was good enough given the &#8220;threats&#8221; this website faces. This process usually isn&#8217;t hard If you develop the website&#8217;s software and have [&#8230;]</p>
<p>
<em><a href="https://blog.ovalerio.net/archives/1880">March 28, 2020 12:35 PM</a></em>
</p>









<hr><h3 class="post"><a href="https://nikola.plejic.com/" title="Nikola Plejić">Nikola Plejić (nikola)</a></h3>


<h4><a href="https://nikola.plejic.com/blog/living-and-coding-in-times-of-crises">Living and Coding In Times of Crises</a></h4>
<p>
<p><em>Note: These are a few slightly melodramatic thoughts written in the aftermath
of several somewhat traumatic weeks involving a pandemic, an earthquake, and a
substantial change in the everyday. The few links that are scattered around I
find interesting and important; the rest is here as a permanent reminder to …</em></p></p>
<p>
<em><a href="https://nikola.plejic.com/blog/living-and-coding-in-times-of-crises">March 28, 2020 10:08 AM</a></em>
</p>





<h2>March 27, 2020</h2>




<hr><h3 class="post"><a href="https://j11g.com" title="Jan van den Berg">Jan van den Berg (j11g)</a></h3>


<h4><a href="https://j11g.com/2020/03/27/dylan-thomas-sidney-michaels/">Dylan Thomas – Sidney Michaels</a></h4>
<p>
<p>This book is a play from 1965, based on several accounts of the infamous travels Welsh poet Dylan Thomas made in the early 1950s to the US. If you know anything about Dylan Thomas you probably know he died young (39), and that he was an alcoholic. This play captures the last two or three [&#8230;]</p>
<p>The post <a rel="nofollow" href="https://j11g.com/2020/03/27/dylan-thomas-sidney-michaels/">Dylan Thomas &#8211; Sidney Michaels</a> appeared first on <a rel="nofollow" href="https://j11g.com">Jan van den Berg</a>.</p></p>
<p>
<em><a href="https://j11g.com/2020/03/27/dylan-thomas-sidney-michaels/">March 27, 2020 09:23 AM</a></em>
</p>









<hr><h3 class="post"><a href="http://www.petecorey.com/" title="Pete Corey">Pete Corey (petecorey)</a></h3>


<h4><a href="http://www.petecorey.com/blog/2020/03/27/glorious-voice-leader-reborn/">Glorious Voice Leader Reborn</a></h4>
<p>
I recently finished a major visual overhaul of my current pet project, Glorious Voice Leader. The redesign was primarily intended to give musicians a (hopefully) more natural interface for working with the tool.</p>
<p>
<em><a href="http://www.petecorey.com/blog/2020/03/27/glorious-voice-leader-reborn/">March 27, 2020 12:00 AM</a></em>
</p>





<h2>March 24, 2020</h2>




<hr><h3 class="post"><a href="https://venam.nixers.net/blog/" title="Venam's Blog">Patrick Louis (venam)</a></h3>


<h4><a href="https://venam.nixers.net/blog/psychology/2020/03/25/self-perception-transformation.html">The Self, Metaperceptions, and Self-Transformation</a></h4>
<p>
<p><img src="https://venam.nixers.net/blog/assets/infinite_reflections.jpg" alt="infinite reflections" /></p>

<p>How would you describe yourself?<br />
How do you usually talk about yourself?<br />
Do you feel like you are the writer of your own narrative?<br />
Who are you?</p>

<p>We all stand on a balance of being perceived and perceiving, of having
a visible and owning an invisible part, and of having control over and
being controlled by. It is amongst all this that we can find the nebulous
definition of who we are, what Locke calls “the sameness of a rational
being”.<br />
In view of this, we are both passengers and conductors of our
narrative. So how do we drive this narrative forward, is it possible
to have more agency in it than we currently have. And if we are our
narrative can we, as the narrative, choose another narrative without
self-annihilation.<br />
Metacognition can be dizzying.</p>

<p>I’ve previously discussed the topic of <a href="https://venam.nixers.net/blog/philosophy/2016/07/17/what-are-we.html">what we
are</a>
and now I’d like to focus on the self, its formation, its transformation,
and its actualization.</p>

<p>Who one is, over time, is created by the amalgamation of the historical
events, physical aspects, and external and internal reflections, that get
incorporated into one’s identity. The self is this element that sits in
the middle, taking in and taking out, what makes sense to us and for us.</p>

<p>From an external point of view, we could define ourselves in reaction to
the roles we play for others, the way we interact with them, eventually
adjusting our selves to the labels we’ve been given or have chosen.<br />
It is helpful to have others act as calibration to our internal system
when we have nothing else to base our definition unto, especially when
we are starting with our self exploration in teenage years. We aren’t
brains in a vat, a self doesn’t exist without a world. Yet, if we overly
emphasize on this sort of self definition, <em>the other</em> becomes our worse
nightmare and our only way of finding meaning and salvation. It leads
to interpreting the world with a heavy filter, and judge it the way we
think it judges us, harshly, and frequently inaccurately, because it is
shaped by our individual self-concept and personal biases. This is what
we call metaperception, the idea we have of how other people’s view of us.</p>

<p>Metaperception can be destructive if not handled properly. For instance,
someone who fixates on it may act in a self-centered way, imagining
that everyone is watching and evaluating their every move, that they
are the center of social interaction. They’ll shut themselves, limit
their spontaneity, and have an increasingly fragile ego. All the while,
not considering the unbridgeable gap that exists between selves.<br />
Being overwhelmed by <em>the other</em> makes it difficult to accept criticism,
to interpret someone else’s response; everything becomes emotionally
charged in a frenzied uncontrollable internal state.</p>

<p>From an internal point of view, we could defined ourselves as the main
character of our lives, the maker of the story. We could move in the
world in relation to what we perceive we’re doing to it.<br />
We are our own persons, with our own choices, so why not make the world
what we want of it. Yet, if we overly emphasize on this sort of self
definition, we become an actor, the protagonist, reading the main script,
trying to get the center of the stage, while everyone around plays a minor
role. It leads to clashes in narratives, cognitive dissonance, an illusion
of superiority, and an egocentric bias. Just like over-metaperception
creates lenses, the self-made-story does too. We cannot deny that, by
analogical thinking, others exist and that they have their own selves.</p>

<p>Therefore, that’s where the balance lies: knowing that we can be the masters
of our destinies, and knowing we are creatures living in a limited social
and physical world.<br />
How do we learn to be comfortable with the ambiguity of the self/other
boundary and get a better life experience. Why and how do we change
our selves.</p>

<p>Change is hard. It’s an arduous task we’d rather let happen
by itself gradually, let it pass by, barely noticing it after it has
happened. Unfortunately, life is riddled with issues and dissatisfactions.<br />
At first, we may pretend they are benign, non-existent, trivial. We
dismiss them and move on to do activities that take our focus away from
them…<br />
Until they are not trivial anymore, until our behavioral pattern becomes
destructive, until they become unmanageable, until we become intimately
aware of them.<br />
Then a realization emerges: Those problems are created by our sense of self,
they are the product of our definition, part of the narrative. Rejecting
them would mean rejecting one self. And this is what we do, we build
immunity to change, we protect our self consistence, we cocoon ourselves
away from the unknown changes. This is what we are and we feel stuck
with it.</p>

<blockquote>
  <p>The years pass by and nothing seems to change. - Henry David Thoreau</p>
</blockquote>

<p>Gradually, we may build constant feelings of guilt, shame, anxiety, and
regret. Desperate for change we see as unattainable, seeing everything
as an unfulfilling experience. Are we to forever remain haunted by what
might have been?</p>

<p>To cope with such emotions, we could rely on our old friend:
self-suppressive escapism. Namely, anything that is numbing, numbing to
the critical evaluation of the self, a cognitive narrowing, a cognitive
detachment from the disturbing elements of the self. All of this being
the easiest way to avoid the source of despair. Moreover, in themselves,
these kinds of actions could be blamed for our current state. We can
blame our inability to take productive actions to change on our anxiety,
depression, fear, or lack of confidence in our abilities. Additionally,
we may even believe that we have to first get rid of such feelings
before moving on to change, we’ll try meditation and introspection. Or
we may believe that we’ve wasted too much time, that it’s too late,
and be overwhelmed by intense feelings of guilt and regret. However,
the negative emotions are not the results of those but they are inherent
to the way we define ourselves and our fear of change.</p>

<blockquote>
  <p>Any obstruction of the natural processes of development …or getting
stuck on a level unsuited to one’s age, takes its revenge, if not
immediately, then later at the onset of the second half of life, in the
form of serious crises, nervous breakdowns, and all manner of physical
and psychic sufferings. Mostly they are accompanied by vague feelings
of guilt, by tormenting pangs of conscience, often not understood, in
face of which the individual is helpless. He knows he is not guilty of
any bad deed, he has not given way to an illicit impulse, and yet he is
plagued by uncertainty, discontent, despair, and above all by anxiety
– a constant, indefinable anxiety. And in truth he must usually be
pronounced “guilty”. His guilt does not lie in the fact that he has
a neurosis, but in the fact that, knowing he has one, he does nothing
to set about curing it. - Jolande Jacobi, The Way of Individuation</p>
</blockquote>

<blockquote>
  <p>We cannot change anything unless we accept it. - Carl Jung</p>
</blockquote>

<p>Thus, we should find the courage to tackle personal growth. If we don’t
accept what has been, we can’t move to what will be. The feelings of
dissatisfaction should be the catalyst of change, they should be welcomed
as stimuli in the struggle for the development of personality.</p>

<blockquote>
  <p>Neurotic symptoms such as these are a direct result of an inadequate
approach to life and act as signals communicating the necessity of
change. - Carl Jung</p>
</blockquote>

<p>Small changes are great and cumulate but when we’ve reached a point
where each step forward gets repelled by all our insecurities, we need
more assurance, we need to know which sort of exact self-induced changes
are the most useful.<br />
And this is what we need to do, we need to break our immunity to change,
we need to remove the shield of our self consistence, we need to face
the unknown changes right on. This is the step where we need to take
the courage to sacrifice our selves to be reborn.</p>

<blockquote>
  <p>Sacrifice always means the renunciation of a valuable part of oneself,
and through it the sacrificer escapes being devoured.
Difficult but necessary step to abandon an aspect of ourself in order
to pave the way for the emergence of the new. The sacrifice is critical
in the process of rebirth because what keeps us locked in our problem
is the inability to recognize that ways of life that served us in our
past may morph from promoters of our well being to the acute cause of
our suffering. - Carl Jung</p>
</blockquote>

<blockquote>
  <p>…The dying of one attitude or need may be the other side of the birth
of something new. One an choose to kill a neurotic strategy, a dependency,
a clinging, and then find that he can choose to live as a freer self… A
“dying” of part of one’s self is often followed by a heightened awareness
of self, a heightened sense of possibility. - Rollo May</p>
</blockquote>

<p>Unsurprisingly, any sudden unnatural change involves risks, especially
when already deep into the abyss. Such change may lead to disorder if,
by removing part of ourselves, we have nothing else to fill it with. This
may take us to the path of chaos and psychological breakdown.</p>

<blockquote>
  <p>[This] …is similar in principle to a psychotic disturbance; that is, it
differs from the initial stage of mental illness only by the fact that
it leads in the end to greater health, while the latter leads to yet
greater destruction. - Carl Jung</p>
</blockquote>

<blockquote>
  <p>Enters a labyrinth, and multiplies a thousandfold the dangers that life
in itself brings with it - of which not the least is that nobody can see
how and where he loses his way, becomes solitary, and is torn to pieces
by some cave-Minotaur of conscience. - Nietzsche</p>
</blockquote>

<p>So now that we’re aware of our situation and have the courage to leap
and let ourselves go, how do we direct the change and get out of the
loop we’re currently stuck in, how do we stop being an immovable pillar
of the past.</p>

<p>Just like we’ve accepted that parts of the self can be sacrificed, we
have to accept its ambiguity and its chaotic nature. Accept that there’s
a world within us that we may not currently understand, that there’s a
depth in each of us that remains to be discovered. We have to be aware
of the reality of our psyche.<br />
Indeed, a lot of the reasons why it remains hidden are related to the
self-suppression we externally exert on elements of our personality that
we think run counter to the moral system of our days. We are blinded by
the unquestioned social beliefs and standards.</p>

<blockquote>
  <p>All psychology so far has got hung up on moral prejudices and fears:
it has not dared to descend into the depths. - Nietzsche</p>
</blockquote>

<p>Similarly, how can we know ourselves if we are actors in a play, wearer
of the masks of society. How can we know ourselves if all we strive for
is fake-perfectionism, a fetishism for perfection and a repulsion for
anything that isn’t. Perfection hinders our development.<br />
Consequentially, we have to accept that perfection is not a thing to aim
for, that it is non-existent. Because how can one know what perfection
is if it is not complete to begin with.</p>

<blockquote>
  <p>One should never think that man can reach perfection, he can only aim
at completion - not to be perfect but to be complete. That would be the
necessity and the indispensable condition if there were only question of
perfection at all. For how can you perfect a thing if it is not complete?</p>

  <p>Make it complete first and see what it is then. But to make it complete
is already a mountain of a task, and by the time you arrive at absolute
completion, you find that you are already dead, so you never read that
preliminary condition for perfecting yourself.  - Carl Jung</p>
</blockquote>

<p>Completeness means grasping the wholeness of the self, the inner
foundation of one’s mind, how to impose form and harmony on the chaos
that is the totality of the self. We are chaos.<br />
We are composed of a multitude, and we need to make those emerge, to
bring the parts to light. As much as we dig, as much as the elements of
consciousness become apparent. We should do all we can to promote
this growth, we should be heroes and explorers of the chaos not passive
observers that are controlled by its forces. The myriads of chunks
are then seen from afar, for what they are, none taking authority on
the whole.<br />
Just like the body is coordinated, there can be a master to the chaos
of the mind. We can have an organizing idea that drives the rest. But
what is this drive, how do we cultivate it, how can we muster its power
to train the body it’s composed of.</p>

<p>If we keep experimenting and spend time bringing forward the chaotic
parts to understand them, it becomes clear. Our drives don’t come out
of thin air. Analogically to the reframing of the definition of the self,
we can reframe our connection to space and time.<br />
We are part of our history, our dreams, our will of achievements, our
unconscious thoughts, our past cultures, our institutions, our traditions,
our physical predispositions, our limits, our sense of imminent death, and
our primitive drives, all constitute our location in space-time. Those are
also expressions of our personal and collective unconscious. Altogether,
those create a common symbolic language, archetypes, universal elements,
original forms that are part of the specification of human nature.<br />
When one becomes conscious of their link with archetypes, they gain
knowledge of the timeless “pattern of human life”, it provides a link with
humanity. Additionally, this type of learning dissolves the feeling that
everything is absurd and provides a sense of being rooted.<br />
Considering this, we need to actively learn about basic prehistorical
drives and how we can take power over them, we need to learn about history
and how it repeats itself, we need to be familiar with the vestiges of
the past, feel them flow within us instead of being ashamed and repressing
them. The ruling passion should drive it all, sculpting our own heroic
meaning to life.</p>

<p>For that, we can choose to study examples of archetypes, anyone and
anything that we find excels in life, be it an imaginary being or
not. Like an artist, we can be active makers, using the same method that
gave birth to our self in the first place: imitation and emulation of the
others. We can create a second self based on traits, characteristics,
and how they handle adversity and challenges, of a role model while
still respecting what we know we can’t change in ourselves, our innate
strength and weaknesses.<br />
This mechanism, of having an alter-ego archetype as a feedback mechanism
that we slowly dissolve into, makes escapism easier and directed. Instead
of reaching for the numbing actions we should reach for the second self
we’ve created. Importantly keeping in mind that one of those numbing
action is to divulge to others that we are simple “acting it out”,
informing others would only be a sign of the anxiety we are having when
facing this novel situation and that we are looking for the recalibration
of our social norms via <em>the others</em>.<br />
We should not pretend, we should act as if we already were and remind
ourselves constantly, when we fall back to our old habits, that the past
was the actual acting and that the present is the reality.</p>

<p>All of this until we engender the shift in our mindset. We’ll finally
be a new self, looking above the previous one from a distance. It’s only
by taking a distance that we can understand the whole.<br />
Thus, we can continue on our self discovery, peeling more and more,
revealing potential we didn’t know we had. At this point we can rediscover
our internal and external worlds like never before. Introspection,
retrospection, discussion, connection of the minds, these take on a
different perspective: what we call psychological mindedness.</p>

<p>The field of developmental psychology has been enamored with such
encapsulated form of growth, subject/object, the one where as you move
along the previous self becomes the object of the current self or where
you radically change your perspective on life. For instance, Abraham
Maslow, Jean Piaget, Erik Erikson, Robert Kegan, are psychologists that
used such methods to convey cognitive and personality development.</p>

<p>Maslow talks about self-actualization, “man’s tendency to
actualize himself, to become his potentialities”, “the desire for
self-fulfillment”. This can be achieve by having something to aim at,
not for external rewards or achievement of the goal but rather because
the transformation of the self forces us to do it. The type of behavior
that requires self-discipline, skills, and that is constructive.<br />
Piaget and Kegan focus on the subject-object and inter-relation when it
comes to defining the self. Giving a sense to the self in a world that
is nebulous and has roots in history.<br />
Erikson prefers to emphasize what is important at every stage of life,
the “ego identities”, from childhood to senior years, all together
encompassing a stable self. Putting in perspective our common humanity.</p>

<pre>

</pre>

<p>Finally, maybe eventually, with all this, we can know who we are and
how to describe ourselves.</p>

<pre>










</pre>

<p>Attributions:</p>
<ul>
  <li>Gianni Crestani / CC0</li>
</ul></p>
<p>
<em><a href="https://venam.nixers.net/blog/psychology/2020/03/25/self-perception-transformation.html">March 24, 2020 10:00 PM</a></em>
</p>









<hr><h3 class="post"><a href="https://www.jeremymorgan.com/tags/programming/" title="programming on Jeremy Morgan :: Tech Blog">Jeremy Morgan (JeremyMorgan)</a></h3>


<h4><a href="http://feedproxy.google.com/~r/JeremyMorganProgramming/~3/gOQ3is08l78/">Stay Home and Learn JavaScript</a></h4>
<p>
If you&rsquo;re quarantined at home and always wanted to learn to code, now&rsquo;s your chance. I&rsquo;ll be creating a series of tutorials designed to take you from &ldquo;zero to hero&rdquo; as a React Developer. Before you start with React you should know some JavaScript. Unlike many front end frameworks/libraries React is uses JavaScript patterns extensively. So we&rsquo;ll cover some JavaScript basics.
In this tutorial, you will learn:
How to get your first webpage set up How to write text to the browser How to write text to the console We will cover some of the basics of JavaScript but won&rsquo;t get too deep.</p>
<p>
<em><a href="http://feedproxy.google.com/~r/JeremyMorganProgramming/~3/gOQ3is08l78/">March 24, 2020 08:32 PM</a></em>
</p>





<h2>March 23, 2020</h2>




<hr><h3 class="post"><a href="https://begriffs.com" title="begriffs.com">Joe Nelson (begriffs)</a></h3>


<h4><a href="https://begriffs.com/posts/2020-03-23-concurrent-programming.html">Concurrent programming, with examples</a></h4>
<p>
<p>Mention concurrency and you’re bound to get two kinds of unsolicited advice: first that it’s a nightmarish problem which will melt your brain, and second that there’s a magical programming language or niche paradigm which will make all your problems disappear.</p>
<p>We won’t run to either extreme here. Instead we’ll cover the production workhorses for concurrent software – threading and locking – and learn about them through a series of interesting programs. By the end of this article you’ll know the terminology and patterns used by POSIX threads (pthreads).</p>
<p>This is an introduction rather than a reference. Plenty of reference material exists for pthreads – whole books in fact. I won’t dwell on all the options of the API, but will briskly give you the big picture. None of the examples contain error handling because it would merely clutter them.</p>
<h3 id="table-of-contents">Table of contents</h3>
<ul>
<li><a href="https://begriffs.com/atom.xml#concurrency-vs-parallelism">Concurrency vs parallelism</a></li>
<li><a href="https://begriffs.com/atom.xml#our-first-concurrent-program">Our first concurrent program</a></li>
<li><a href="https://begriffs.com/atom.xml#data-races">Data races</a></li>
<li><a href="https://begriffs.com/atom.xml#locks-and-deadlock">Locks and deadlock</a></li>
<li><a href="https://begriffs.com/atom.xml#condition-variables">Condition variables</a></li>
<li><a href="https://begriffs.com/atom.xml#other-synchronization-primitives">Other synchronization primitives</a>
<ul>
<li><a href="https://begriffs.com/atom.xml#barriers">Barriers</a></li>
<li><a href="https://begriffs.com/atom.xml#spinlocks">Spinlocks</a></li>
<li><a href="https://begriffs.com/atom.xml#reader-writer-locks">Reader-writer locks</a></li>
<li><a href="https://begriffs.com/atom.xml#semaphores">Semaphores</a></li>
</ul></li>
<li><a href="https://begriffs.com/atom.xml#cancellation">Cancellation</a></li>
<li><a href="https://begriffs.com/atom.xml#development-tools">Development tools</a>
<ul>
<li><a href="https://begriffs.com/atom.xml#valgrind-drd-and-helgrind">Valgrind DRD and helgrind</a></li>
<li><a href="https://begriffs.com/atom.xml#clang-threadsanitizer-tsan">Clang ThreadSanitizer (TSan)</a></li>
<li><a href="https://begriffs.com/atom.xml#mutrace">Mutrace</a></li>
<li><a href="https://begriffs.com/atom.xml#off-cpu-profiling">Off-CPU profiling</a></li>
<li><a href="https://begriffs.com/atom.xml#macos-instruments">macOS Instruments</a></li>
<li><a href="https://begriffs.com/atom.xml#perf-c2c">perf c2c</a></li>
<li><a href="https://begriffs.com/atom.xml#intel-vtune-profiler">Intel VTune Profiler</a></li>
</ul></li>
<li><a href="https://begriffs.com/atom.xml#further-reading">Further reading</a></li>
</ul>
<h3 id="concurrency-vs-parallelism">Concurrency vs parallelism</h3>
<p>First it’s important to distinguish concurrency vs parallelism. <strong>Concurrency</strong> is the ability of parts of a program to work correctly when executed out of order. For instance, imagine tasks A and B. One way to execute them is sequentially, meaning doing all steps for A, then all for B:</p>

 A  B

<p>Concurrent execution, on the other hand, alternates doing a little of each task until both are all complete:</p>

        

<p>Concurrency allows a program to make progress even when certain parts are blocked. For instance, when one task is waiting for user input, the system can switch to another task and do calculations.</p>
<p>When tasks don’t just interleave, but run at the same time, that’s called <strong>parallelism</strong>. Multiple CPU cores can run instructions simultaneously:</p>

 A  B

<p>When a program – even without hardware parallelism – switches rapidly enough from one task to another, it can feel to the user that tasks are executing at the same time. You could say it provides the “illusion of parallelism.” However, true parallelism has the potential for greater processor throughput for problems that can be broken into independent subtasks. Some ways of dealing with concurrency, such as multi-threaded programming, can exploit hardware parallelism automatically when available.</p>
<p>Some languages (or more accurately, some language implementations) are unable to achieve true multi-threaded parallelism. Ruby MRI and CPython for instance use a global interpreter lock (GIL) to simplify their implementation. The GIL prevents more than one thread from running at once. Programs in these interpreters can benefit from I/O concurrency, but not extra computational power.</p>
<h3 id="our-first-concurrent-program">Our first concurrent program</h3>
<p>Languages and libraries offer different ways to add concurrency to a program. UNIX for instance has a bunch of disjointed mechanisms like signals, asynchronous I/O (AIO), select, poll, and setjmp/longjmp. Using these mechanisms can complicate program structure and make programs harder to read than sequential code.</p>
<p>Threads offer a cleaner and more consistent way to address these motivations. For I/O they’re usually clearer than polling or callbacks, and for processing they are more efficient than Unix processes.</p>
<h4 id="crazy-bankers">Crazy bankers</h4>
<p>Let’s get started by adding concurrency to a program to simulate a bunch of crazy bankers sending random amounts of money from one bank account to another. The bankers don’t communicate with one another, so this is a demonstration of concurrency without synchronization.</p>
<p>Adding concurrency is the easy part. The real work is in making threads wait for one another to ensure a correct result. We’ll see a number of mechanisms and patterns for synchronization later, but for now let’s see what goes wrong without synchronization.</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c"><span class="co">/* banker.c */</span>

<span class="pp">#include </span><span class="im">&lt;stdio.h&gt;</span>
<span class="pp">#include </span><span class="im">&lt;stdlib.h&gt;</span>
<span class="pp">#include </span><span class="im">&lt;pthread.h&gt;</span>
<span class="pp">#include </span><span class="im">&lt;time.h&gt;</span>

<span class="pp">#define N_ACCOUNTS 10</span>
<span class="pp">#define N_THREADS  20</span>
<span class="pp">#define N_ROUNDS   10000</span>

<span class="co">/* 10 accounts with $100 apiece means there's $1,000</span>
<span class="co">   in the system. Let's hope it stays that way...  */</span>
<span class="pp">#define INIT_BALANCE 100</span>

<span class="co">/* making a struct here for the benefit of future</span>
<span class="co">   versions of this program */</span>
<span class="kw">struct</span> account
{
	<span class="dt">long</span> balance;
} accts[N_ACCOUNTS];

<span class="co">/* Helper for bankers to choose an account and amount at</span>
<span class="co">   random. It came from Steve Summit's excellent C FAQ</span>
<span class="co">   http://c-faq.com/lib/randrange.html */</span>
<span class="dt">int</span> rand_range(<span class="dt">int</span> N)
{
	<span class="cf">return</span> (<span class="dt">int</span>)((<span class="dt">double</span>)rand() / ((<span class="dt">double</span>)RAND_MAX + <span class="dv">1</span>) * N);
}

<span class="co">/* each banker will run this function concurrently. The</span>
<span class="co">   weird signature is required for a thread function */</span>
<span class="dt">void</span> *disburse(<span class="dt">void</span> *arg)
{
	<span class="dt">size_t</span> i, from, to;
	<span class="dt">long</span> payment;

	<span class="co">/* idiom to tell compiler arg is unused */</span>
	(<span class="dt">void</span>)arg;

	<span class="cf">for</span> (i = <span class="dv">0</span>; i &lt; N_ROUNDS; i++)
	{
		<span class="co">/* pick distinct 'from' and 'to' accounts */</span>
		from = rand_range(N_ACCOUNTS);
		<span class="cf">do</span> {
			to = rand_range(N_ACCOUNTS);
		} <span class="cf">while</span> (to == from);

		<span class="co">/* go nuts sending money, try not to overdraft */</span>
		<span class="cf">if</span> (accts[from].balance &gt; <span class="dv">0</span>)
		{
			payment = <span class="dv">1</span> + rand_range(accts[from].balance);
			accts[from].balance -= payment;
			accts[to].balance   += payment;
		}
	}
	<span class="cf">return</span> NULL;
}

<span class="dt">int</span> main(<span class="dt">void</span>)
{
	<span class="dt">size_t</span> i;
	<span class="dt">long</span> total;
	pthread_t ts[N_THREADS];

	srand(time(NULL));

	<span class="cf">for</span> (i = <span class="dv">0</span>; i &lt; N_ACCOUNTS; i++)
		accts[i].balance = INIT_BALANCE;

	printf(<span class="st">&quot;Initial money in system: %d</span><span class="sc">\n</span><span class="st">&quot;</span>,
		N_ACCOUNTS * INIT_BALANCE);

	<span class="co">/* start the threads, using whatever parallelism the</span>
<span class="co">	   system happens to offer. Note that pthread_create</span>
<span class="co">	   is the *only* function that creates concurrency */</span>
	<span class="cf">for</span> (i = <span class="dv">0</span>; i &lt; N_THREADS; i++)
		pthread_create(&amp;ts[i], NULL, disburse, NULL);

	<span class="co">/* wait for the threads to all finish, using the</span>
<span class="co">	   pthread_t handles pthread_create gave us */</span>
	<span class="cf">for</span> (i = <span class="dv">0</span>; i &lt; N_THREADS; i++)
		pthread_join(ts[i], NULL);

	<span class="cf">for</span> (total = <span class="dv">0</span>, i = <span class="dv">0</span>; i &lt; N_ACCOUNTS; i++)
		total += accts[i].balance;

	printf(<span class="st">&quot;Final money in system: %ld</span><span class="sc">\n</span><span class="st">&quot;</span>, total);
}</code></pre></div>
<p>The following simple Makefile can be used to compile all the programs in this article:</p>
<div class="sourceCode"><pre class="sourceCode makefile"><code class="sourceCode makefile"><span class="ot">.POSIX:</span>
<span class="dt">CFLAGS </span><span class="ch">=</span><span class="st"> -std=c99 -pedantic -D_POSIX_C_SOURCE=200809L -Wall -Wextra</span>
<span class="dt">LDFLAGS </span><span class="ch">=</span><span class="st"> -lpthread</span></code></pre></div>
<p>Make’s default <a href="https://pubs.opengroup.org/onlinepubs/9699919799/utilities/make.html#tag_20_76_13_09">suffix rules</a> mean that if you have <code>foo.c</code> you can simply run <code>make foo</code> and it knows what to do without your needing to add any extra rules to the Makefile.</p>
<div class="alert alert-info">
<h4>
Note: building with gcc
</h4>
<p>
Most compilers work correctly with <code>-lpthread</code> but GCC is unusual and requires <code>-pthreads</code>. For portability we could attempt to use the POSIX <code>c99</code> compiler interface. In fact the latest standard <a href="https://pubs.opengroup.org/onlinepubs/9699919799/utilities/c99.html#tagtcjh_25"> provides</a> configuration variables containing the proper pthreads compiler options for whatever platform compiler underlies this interface:
</p>
<p>
<ul>
<li>
POSIX_V7_THREADS_CFLAGS
</li>
<li>
POSIX_V7_THREADS_LDFLAGS
</li>
</ul>
</p>
<p>
Makefiles would use <code>getconf</code> to retrieve these values and add them to CFLAGS and LDFLAGS. However the feature is too new to be supported by most systems. You’ll have to modify the Makefile manually for now if you’re in nonstandard GNU land.
</p>
</div>
<h3 id="data-races">Data races</h3>
<p>Try compiling and running <code>banker.c</code>. Notice anything strange?</p>
<p>Threads share memory directly. Each thread can read and write variables in shared memory without any overhead. However when threads simultaneously read and write the same data it’s called a <strong>data race</strong> and generally causes problems.</p>
<p>In particular, threads in <code>banker.c</code> have data races when they read and write account balances. The bankers program moves money between accounts, however the total amount of money in the system does not remain constant. The books don’t balance. Exactly how the program behaves depends on thread scheduling policies of the operating system. On OpenBSD the total money seldom stays at $1,000. Sometimes money gets duplicated, sometimes it vanishes. On macOS the result is generally that all the money disappears, or even becomes negative!</p>
<p>The property that money is neither created nor destroyed in a bank is an example of a <strong>program invariant</strong>, and it gets violated by data races. Note that parallelism is not required for a race, only concurrency.</p>
<p>Here’s the problematic code in the <code>disburse()</code> function:</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c">payment = <span class="dv">1</span> + rand_range(accts[from].balance);
accts[from].balance -= payment;
accts[to].balance   += payment;</code></pre></div>
<p>The threads running this code can be paused or interleaved at any time. Not just between any of the statements, but partway through arithmetic operations which may not execute atomically on the hardware. Never rely on “thread inertia,” which is the mistaken feeling that the thread will finish a group of statements without interference.</p>
<p>Let’s examine exactly how statements can interleave between banker threads, and the resulting problems. The columns of the table below are threads, and the rows are moments in time.</p>
<p>Here’s a timeline where two threads read the same account balance when planning how much money to transfer. It can cause an overdraft.</p>
<table class="table">
<caption>
Overdrafting
</caption>
<thead>
<tr>
<th>
Thread A
</th>
<th>
Thread B
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
payment = 1 + rand_range(accts[from].balance);
</td>
<td></td>
</tr>
<tr>
<td></td>
<td>
payment = 1 + rand_range(accts[from].balance);
</td>
</tr>
<tr>
<td colspan="2">
At this point, thread B’s payment-to-be may be in excess of the true balance because thread A has already earmarked some of the money unbeknownst to B.
</td>
</tr>
<tr>
<td>
accts[from].balance -= payment;
</td>
<td></td>
</tr>
<tr>
<td></td>
<td>
accts[from].balance -= payment;
</td>
</tr>
<tr>
<td colspan="2">
Some of the same dollars could be transferred twice and the originating account could even go negative if the overlap of the payments is big enough.
</td>
</tr>
</tbody>
</table>
<p>Here’s a timeline where the debit made by one thread can be undone by that made by another.</p>
<table class="table">
<caption>
Lost debit
</caption>
<thead>
<tr>
<th>
Thread A
</th>
<th>
Thread B
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
accts[from].balance -= payment;
</td>
<td>
accts[from].balance -= payment;
</td>
</tr>
<tr>
<td colspan="2">
If <code>-=</code> is not atomic, the threads might switch execution after reading the balance and after doing arithmetic, but before assignment. Thus one assignment would be overwritten by the other. The “lost update” creates extra money in the system.
</td>
</tr>
</tbody>
</table>
<p>Similar problems can occur when bankers have a data race in destination accounts. Races in the destination account would tend to decrease total money supply. (To learn more about concurrency problems, see my article <a href="https://begriffs.com/posts/2017-08-01-practical-guide-sql-isolation.html">Practical Guide to SQL Transaction Isolation</a>).</p>
<h3 id="locks-and-deadlock">Locks and deadlock</h3>
<p>In the example above, we found that a certain section of code was vulnerable to data races. Such tricky parts of a program are called <strong>critical sections.</strong> We must ensure each thread gets all the way through the section before another thread is allowed to enter it.</p>
<p>To give threads mutually exclusive access to a critical section, pthreads provides the mutually exclusive lock (<strong>mutex</strong> for short). The pattern is:</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c">pthread_mutex_lock(&amp;some_mutex);

<span class="co">/* ... do things in the critical section ... */</span>

pthread_mutex_unlock(&amp;some_mutex);</code></pre></div>
<p>Any thread calling <code>pthread_mutex_lock</code> on a previously locked mutex will go to sleep and not be scheduled until the mutex is unlocked (and any other threads already waiting on the mutex have gone first).</p>
<p>Another way to look at mutexes is that their job is to preserve program invariants. The critical section between locking and unlocking is a place where a certain invariant may be temporarily broken, as long as it is restored by the end. Some people recommend adding an <code>assert()</code> statement before unlocking, to help document the invariant. If an invariant is difficult to specify in an assertion, a comment can be useful instead.</p>
<p>A function is called <strong>thread-safe</strong> if multiple invocations can safely run concurrently. A cheap, but inefficient, way to make any function thread-safe is to give it its own mutex and lock it right away:</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c"><span class="co">/* inefficient but effective way to protect a function */</span>

pthread_mutex_t foo_mtx = PTHREAD_MUTEX_INITIALIZER;

<span class="dt">void</span> foo(<span class="co">/* some arguments */</span>)
{
	pthread_mutex_lock(&amp;foo_mtx);

	<span class="co">/* we're safe in here, but it's a bottleneck */</span>

	pthread_mutex_unlock(&amp;foo_mtx);
}</code></pre></div>
<p>To see why this is inefficient, imagine if <code>foo()</code> was designed to output characters to a file specified in its arguments. Because the function takes a global lock, no two threads could run it at once, even if they wanted to write to different files. Writing to different files should be independent activities, and what we really want to protect against are two threads concurrently writing the <em>same</em> file.</p>
<p>The amount of data that a mutex protects is called its <strong>granularity,</strong> and smaller granularity can often be more efficient. In our <code>foo()</code> example, we could store a mutex for every file we write, and have the function choose and lock the appropriate mutex. Multi-threaded programs typically add a mutex as a member variable to data structures, to associate the lock with its data.</p>
<p>Let’s update the banker program to keep a mutex in each account and prevent data races.</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c"><span class="co">/* banker_lock.c */</span>

<span class="pp">#include </span><span class="im">&lt;stdio.h&gt;</span>
<span class="pp">#include </span><span class="im">&lt;stdlib.h&gt;</span>
<span class="pp">#include </span><span class="im">&lt;pthread.h&gt;</span>
<span class="pp">#include </span><span class="im">&lt;time.h&gt;</span>

<span class="pp">#define N_ACCOUNTS 10</span>
<span class="pp">#define N_THREADS  100</span>
<span class="pp">#define N_ROUNDS   10000</span>

<span class="kw">struct</span> account
{
	<span class="dt">long</span> balance;
	<span class="co">/* add a mutex to prevent races on balance */</span>
	pthread_mutex_t mtx;
} accts[N_ACCOUNTS];

<span class="dt">int</span> rand_range(<span class="dt">int</span> N)
{
	<span class="cf">return</span> (<span class="dt">int</span>)((<span class="dt">double</span>)rand() / ((<span class="dt">double</span>)RAND_MAX + <span class="dv">1</span>) * N);
}

<span class="dt">void</span> *disburse(<span class="dt">void</span> *arg)
{
	<span class="dt">size_t</span> i, from, to;
	<span class="dt">long</span> payment;

	(<span class="dt">void</span>)arg;

	<span class="cf">for</span> (i = <span class="dv">0</span>; i &lt; N_ROUNDS; i++)
	{
		from = rand_range(N_ACCOUNTS);
		<span class="cf">do</span> {
			to = rand_range(N_ACCOUNTS);
		} <span class="cf">while</span> (to == from);

		<span class="co">/* get an exclusive lock on both balances before</span>
<span class="co">		   updating (there's a problem with this, see below) */</span>
		pthread_mutex_lock(&amp;accts[from].mtx);
		pthread_mutex_lock(&amp;accts[to].mtx);
		<span class="cf">if</span> (accts[from].balance &gt; <span class="dv">0</span>)
		{
			payment = <span class="dv">1</span> + rand_range(accts[from].balance);
			accts[from].balance -= payment;
			accts[to].balance   += payment;
		}
		pthread_mutex_unlock(&amp;accts[to].mtx);
		pthread_mutex_unlock(&amp;accts[from].mtx);
	}
	<span class="cf">return</span> NULL;
}

<span class="dt">int</span> main(<span class="dt">void</span>)
{
	<span class="dt">size_t</span> i;
	<span class="dt">long</span> total;
	pthread_t ts[N_THREADS];

	srand(time(NULL));

	<span class="co">/* set the initial balance, but also create a</span>
<span class="co">	   new mutex for each account */</span>
	<span class="cf">for</span> (i = <span class="dv">0</span>; i &lt; N_ACCOUNTS; i++)
		accts[i] = (<span class="kw">struct</span> account)
			{<span class="dv">100</span>, PTHREAD_MUTEX_INITIALIZER};

	<span class="cf">for</span> (i = <span class="dv">0</span>; i &lt; N_THREADS; i++)
		pthread_create(&amp;ts[i], NULL, disburse, NULL);

	puts(<span class="st">&quot;(This program will probably deadlock, &quot;</span>
	     <span class="st">&quot;and need to be manually terminated...)&quot;</span>);

	<span class="cf">for</span> (i = <span class="dv">0</span>; i &lt; N_THREADS; i++)
		pthread_join(ts[i], NULL);

	<span class="cf">for</span> (total = <span class="dv">0</span>, i = <span class="dv">0</span>; i &lt; N_ACCOUNTS; i++)
		total += accts[i].balance;

	printf(<span class="st">&quot;Total money in system: %ld</span><span class="sc">\n</span><span class="st">&quot;</span>, total);
}</code></pre></div>
<p>Now everything should be safe. No money being created or destroyed, just perfect exchanges between the accounts. The invariant is that the total balance of the source and destination accounts is the same before we transfer the money as after. It’s broken only inside the critical section.</p>
<p>As a side note, at this point you might think it would be more efficient be to take a single lock at a time, like this:</p>
<ul>
<li>lock the source account</li>
<li>withdraw money into a thread local variable</li>
<li>unlock the source account</li>
<li>(danger zone!)</li>
<li>lock the destination account</li>
<li>deposit the money</li>
<li>unlock the destination account</li>
</ul>
<p>This would not be safe. During the time between unlocking the source account and locking the destination, the invariant does not hold, yet another thread could observe this state. For instance a report running in another thread just at that time could read the balance of both accounts and observe money missing from the system.</p>
<p>We do need to lock both accounts during the transfer. However the way we’re doing it causes a different problem. Try to run the program. It gets stuck forever and never prints the final balance! Its threads are <strong>deadlocked.</strong></p>
<p>Deadlock is the second villain of concurrent programming, and happens when threads wait on each others’ locks, but no thread unlocks for any other. The case of the bankers is a classic simple form called the <strong>deadly embrace.</strong> Here’s how it plays out:</p>
<table class="table">
<caption>
Deadly embrace
</caption>
<thead>
<tr>
<th>
Thread A
</th>
<th>
Thread B
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
lock account 1
</td>
<td>
</td>
</tr>
<tr>
<td>
</td>
<td>
lock account 2
</td>
</tr>
<tr>
<td>
lock account 2
</td>
<td>
</td>
</tr>
<tr>
<td colspan="2">
At this point thread A is blocked because thread B already holds a lock on account 2.
</td>
</tr>
<tr>
<td>
</td>
<td>
lock account 1
</td>
</tr>
<tr>
<td colspan="2">
Now thread B is blocked because thread A holds a lock on account 1. However thread A will never unlock account 1 because thread A is blocked!
</td>
</tr>
</tbody>
</table>
<p>The problem happens because threads lock resources in different orders, and because they refuse to give locks up. We can solve the problem by addressing either of these causes.</p>
<p>The first approach to preventing deadlock is to enforce a <strong>locking hierarchy.</strong> This means the programmer comes up with an arbitrary order for locks, and always takes “earlier” locks before “later” ones. The terminology comes from locks in hierarchical data structures like trees, but it really amounts to using any kind of consistent locking order.</p>
<p>In our case of the banker program we store all the accounts in an array, so we can use the array index as the lock order. Let’s compare.</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c"><span class="co">/* the original way to lock mutexes, which caused deadlock */</span>

pthread_mutex_lock(&amp;accts[from].mtx);
pthread_mutex_lock(&amp;accts[to].mtx);
<span class="co">/* move money */</span>
pthread_mutex_unlock(&amp;accts[to].mtx);
pthread_mutex_unlock(&amp;accts[from].mtx);</code></pre></div>
<p>Here’s a safe way, enforcing a locking hierarchy:</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c"><span class="co">/* lock mutexes in earlier accounts first */</span>

<span class="pp">#define MIN(a,b) ((a) &lt; (b) ? (a) : (b))</span>
<span class="pp">#define MAX(a,b) ((a) &lt; (b) ? (b) : (a))</span>

pthread_mutex_lock(&amp;accts[MIN(from, to)].mtx);
pthread_mutex_lock(&amp;accts[MAX(from, to)].mtx);
<span class="co">/* move money */</span>
pthread_mutex_unlock(&amp;accts[MAX(from, to)].mtx);
pthread_mutex_unlock(&amp;accts[MIN(from, to)].mtx);

<span class="co">/* notice we unlock in opposite order */</span></code></pre></div>
<p>A locking hierarchy is the most efficient way to prevent deadlock, but it isn’t always easy to contrive. It’s also creates a potentially undocumented coupling between different parts of a program which need to collaborate in the convention.</p>
<p><strong>Backoff</strong> is a different way to prevent deadlock which works for locks taken in any order. It takes a lock, but then checks whether the next is obtainable. If not, it unlocks the first to allow another thread to make progress, and tries again.</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c"><span class="co">/* using pthread_mutex_trylock to dodge deadlock */</span>

<span class="cf">while</span> (<span class="dv">1</span>)
{
	pthread_mutex_lock(&amp;accts[from].mtx);
	
	<span class="cf">if</span> (pthread_mutex_trylock(&amp;accts[to].mtx) == <span class="dv">0</span>)
		<span class="cf">break</span>; <span class="co">/* got both locks */</span>

	<span class="co">/* didn't get the second one, so unlock the first */</span>
	pthread_mutex_unlock(&amp;accts[from].mtx);
	<span class="co">/* force a sleep so another thread can try --</span>
<span class="co">	   include &lt;sched.h&gt; for this function */</span>
	sched_yield();
}
<span class="co">/* move money */</span>
pthread_mutex_unlock(&amp;accts[to].mtx);
pthread_mutex_unlock(&amp;accts[from].mtx);</code></pre></div>
<p>One tricky part is the call to <code>sched_yield()</code>. Without it the loop will immediately try to grab the lock again, competing as hard as it can with other threads who could make more productive use of the lock. This causes <strong>livelock</strong>, where threads fight for access to the locks. The <code>sched_yield()</code> puts the calling thread to sleep and at the back of the scheduler’s run queue.</p>
<p>Despite its flexibility, backoff is definitely less efficient than a locking hierarchy because it can make wasted calls to lock and unlock mutexes. Try modifying the banker program with these approaches and measure how fast they run.</p>
<h3 id="condition-variables">Condition variables</h3>
<p>After safely getting access to a shared variable with a mutex, a thread may discover that the value of the variable is not yet suitable for the thread to act upon. For instance, if the thread was looking for an item to process in a shared queue, but found the queue was empty. The thread could poll the value, but this is inefficient. Pthreads provides <strong>condition variables</strong> to allow threads to wait for events of interest or notify other threads when these events happen.</p>
<p>Condition variables are not themselves locks, nor do they hold any value of their own. They are merely events with a programmer-assigned meaning. For example, a structure representing a queue could have a mutex for safely accessing the data, plus some condition variables. One to represent the event of the queue becoming empty, and another to announce when a new item is added.</p>
<p>Before getting deeper into how condition variables work, let’s see one in action with our banker program. We’ll measure contention between the bankers. First we’ll increase the number of threads and accounts, and keep statistics about how many bankers manage to get inside the <code>disburse()</code> critical section at once. Any time the max score is broken, we’ll signal a condition variable. A dedicated thread will wait on it and update a scoreboard.</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c"><span class="co">/* banker_stats.c */</span>

<span class="pp">#include </span><span class="im">&lt;stdio.h&gt;</span>
<span class="pp">#include </span><span class="im">&lt;stdlib.h&gt;</span>
<span class="pp">#include </span><span class="im">&lt;pthread.h&gt;</span>
<span class="pp">#include </span><span class="im">&lt;time.h&gt;</span>

<span class="co">/* increase the accounts and threads, but make sure there are</span>
<span class="co"> * &quot;too many&quot; threads so they tend to block each other */</span>
<span class="pp">#define N_ACCOUNTS 50</span>
<span class="pp">#define N_THREADS  100</span>
<span class="pp">#define N_ROUNDS   10000</span>

<span class="pp">#define MIN(a,b) ((a) &lt; (b) ? (a) : (b))</span>
<span class="pp">#define MAX(a,b) ((a) &lt; (b) ? (b) : (a))</span>

<span class="kw">struct</span> account
{
	<span class="dt">long</span> balance;
	pthread_mutex_t mtx;
} accts[N_ACCOUNTS];

<span class="dt">int</span> rand_range(<span class="dt">int</span> N)
{
	<span class="cf">return</span> (<span class="dt">int</span>)((<span class="dt">double</span>)rand() / ((<span class="dt">double</span>)RAND_MAX + <span class="dv">1</span>) * N);
}

<span class="co">/* keep a special mutex and condition variable</span>
<span class="co"> * reserved for just the stats */</span>
pthread_mutex_t stats_mtx = PTHREAD_MUTEX_INITIALIZER;
pthread_cond_t  stats_cnd = PTHREAD_COND_INITIALIZER;
<span class="dt">int</span> stats_curr = <span class="dv">0</span>, stats_best = <span class="dv">0</span>;

<span class="co">/* use this interface to modify the stats */</span>
<span class="dt">void</span> stats_change(<span class="dt">int</span> delta)
{
	pthread_mutex_lock(&amp;stats_mtx);
	stats_curr += delta;
	<span class="cf">if</span> (stats_curr &gt; stats_best)
	{
		stats_best = stats_curr;
		<span class="co">/* signal new high score */</span>
		pthread_cond_broadcast(&amp;stats_cnd);
	}
	pthread_mutex_unlock(&amp;stats_mtx);
}

<span class="co">/* a dedicated thread to update the scoreboard UI */</span>
<span class="dt">void</span> *stats_print(<span class="dt">void</span> *arg)
{
	<span class="dt">int</span> prev_best;

	(<span class="dt">void</span>)arg;

	<span class="co">/* we never return, nobody needs to</span>
<span class="co">	 * pthread_join() with us */</span>
	pthread_detach(pthread_self());

	<span class="cf">while</span> (<span class="dv">1</span>)
	{
		pthread_mutex_lock(&amp;stats_mtx);

		prev_best = stats_best;
		<span class="co">/* go to sleep until stats change, and always</span>
<span class="co">		 * check that they actually have changed */</span>
		<span class="cf">while</span> (prev_best == stats_best)
			pthread_cond_wait(
				&amp;stats_cnd, &amp;stats_mtx);

		<span class="co">/* overwrite current line with new score */</span>
		printf(<span class="st">&quot;</span><span class="sc">\r</span><span class="st">%2d&quot;</span>, stats_best);
		pthread_mutex_unlock(&amp;stats_mtx);

		fflush(stdout);
	}
}

<span class="dt">void</span> *disburse(<span class="dt">void</span> *arg)
{
	<span class="dt">size_t</span> i, from, to;
	<span class="dt">long</span> payment;

	(<span class="dt">void</span>)arg;

	<span class="cf">for</span> (i = <span class="dv">0</span>; i &lt; N_ROUNDS; i++)
	{
		from = rand_range(N_ACCOUNTS);
		<span class="cf">do</span> {
			to = rand_range(N_ACCOUNTS);
		} <span class="cf">while</span> (to == from);

		pthread_mutex_lock(&amp;accts[MIN(from, to)].mtx);
		pthread_mutex_lock(&amp;accts[MAX(from, to)].mtx);

		<span class="co">/* notice we still have a lock hierarchy, because</span>
<span class="co">		 * we call stats_change() after locking all account</span>
<span class="co">		 * mutexes (stats_mtx comes last) */</span>
		stats_change(<span class="dv">1</span>); <span class="co">/* another banker in crit sec */</span>
		<span class="cf">if</span> (accts[from].balance &gt; <span class="dv">0</span>)
		{
			payment = <span class="dv">1</span> + rand_range(accts[from].balance);
			accts[from].balance -= payment;
			accts[to].balance   += payment;
		}
		stats_change(-<span class="dv">1</span>); <span class="co">/* leaving crit sec */</span>

		pthread_mutex_unlock(&amp;accts[MAX(from, to)].mtx);
		pthread_mutex_unlock(&amp;accts[MIN(from, to)].mtx);
	}
	<span class="cf">return</span> NULL;
}

<span class="dt">int</span> main(<span class="dt">void</span>)
{
	<span class="dt">size_t</span> i;
	<span class="dt">long</span> total;
	pthread_t ts[N_THREADS], stats;

	srand(time(NULL));

	<span class="cf">for</span> (i = <span class="dv">0</span>; i &lt; N_ACCOUNTS; i++)
		accts[i] = (<span class="kw">struct</span> account)
			{<span class="dv">100</span>, PTHREAD_MUTEX_INITIALIZER};

	<span class="cf">for</span> (i = <span class="dv">0</span>; i &lt; N_THREADS; i++)
		pthread_create(&amp;ts[i], NULL, disburse, NULL);

	<span class="co">/* start thread to update the user on how many bankers</span>
<span class="co">	 * are in the disburse() critical section at once */</span>
	pthread_create(&amp;stats, NULL, stats_print, NULL);

	<span class="cf">for</span> (i = <span class="dv">0</span>; i &lt; N_THREADS; i++)
		pthread_join(ts[i], NULL);

	<span class="co">/* not joining with the thread running stats_print,</span>
<span class="co">	 * we'll let it disappar when main exits */</span>

	<span class="cf">for</span> (total = <span class="dv">0</span>, i = <span class="dv">0</span>; i &lt; N_ACCOUNTS; i++)
		total += accts[i].balance;

	printf(<span class="st">&quot;</span><span class="sc">\n</span><span class="st">Total money in system: %ld</span><span class="sc">\n</span><span class="st">&quot;</span>, total);
}</code></pre></div>
<p>With fifty accounts and a hundred threads, not all threads will be able to be in the critical section of <code>disburse()</code> at once. It varies between runs. Run the program and see how well it does on your machine. (One complication is that making all threads synchronize on <code>stats_mtx</code> may throw off the measurement, because there are threads who could have executed independently but now must interact.)</p>
<p>Let’s look at how to properly use condition variables. We notified threads of a new event with <code>pthread_cond_broadcast(&amp;stats_cnd)</code>. This function marks all threads waiting on <code>state_cnd</code> as ready to run.</p>
<p>Sometimes multiple threads are waiting on a single cond var. A broadcast will wake them all, but sometimes the event source knows that only one thread will be able to do any work. For instance if only one item is added to a shared queue. In that case the <code>pthread_cond_signal</code> function is better than <code>pthread_cond_broadcast</code>. Unnecessarily waking multiple threads causes overhead. In our case we know that only one thread is waiting on the cond var, so it really makes no difference.</p>
<p>Remember that it’s never <em>wrong</em> to use a broadcast, whereas in some cases it might be wrong to use a signal. Signal is just an optimized broadcast.</p>
<p>The waiting side of a cond var ought always to have this pattern:</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c">pthread_mutex_lock(&amp;mutex);
<span class="cf">while</span> (!PREDICATE)
	pthread_cond_wait(&amp;cond_var, &amp;mutex);
pthread_mutex_unlock(&amp;mutex);</code></pre></div>
<p>Condition variables are always associated with a predicate, and the association is implicit in the programmer’s head. You shouldn’t reuse a condition variable for multiple predicates. The intention is that code will signal the cond var when the predicate becomes true.</p>
<p>Before testing the predicate we lock a mutex that covers the data being tested. That way no other thread can change the data immediately after we test it (also <code>pthread_cond_wait()</code> requires a locked mutex). If the predicate is already true we needn’t wait on the cond var, so the loop falls through, otherwise the thread begins to wait.</p>
<p>Condition variables allow you to make this series of events atomic: unlock a mutex, register our interest in the event, and block. Without that atomicity another thread might awaken to take our lock and broadcast before we’ve registered ourselves as interested. Without the atomicity we could be blocked forever.</p>
<p>When <code>pthread_cond_wait()</code> returns, the calling thread awakens and atomically gets its mutex back. It’s all set to check the predicate again in the loop. But why check the predicate? Wasn’t the cond var signaled because the predicate was true, and isn’t the relevant data protected by a mutex? There are three reasons to check:</p>
<ol>
<li>If the condition variable had been broadcast, other threads might have been listening, and another might have been scheduled first and might have done our job. The loop tests for that interception.</li>
<li>On some multiprocessor systems, making condition variable wakeup completely predictable might substantially slow down all cond var operations. Such systems allow <strong>spurious wakeups</strong>, and threads need to be prepared to check if they were woken appropriately.</li>
<li>It can be convenient to signal on a loose predicate. Threads can signal the variables when the event seems <em>likely</em>, or even mistakenly signal, and the program will still work. For instance, we signal when when <code>stats_best</code> gets a new high score, but we could have chosen to signal at every invocation of <code>stats_change()</code>.</li>
</ol>
<p>Given that we have to pass a locked mutex to <code>pthread_cond_wait()</code>, which we had to create, why don’t cond vars come with their own built-in mutex? The reason is flexibility. Although you should use only one mutex with a cond var, there can be multiple cond vars for the same mutex. Think of the example of the mutex protecting a queue, and the different events that can happen in the queue.</p>
<h3 id="other-synchronization-primitives">Other synchronization primitives</h3>
<h4 id="barriers">Barriers</h4>
<p>It’s time to bid farewell to the banker programs, and turn to something more lively: Conway’s Game of Life! The game has a set of rules operating on a grid of cells that determines which cells live or die based on how many living neighbors each has.</p>
<p>The game can take advantage of multiple processors, using each processor to operate on a different part of the grid in parallel. It’s a so-called <strong>embarrassingly parallel</strong> problem because each section of the grid can be processed in isolation, without needing results from other sections.</p>
<p>Barriers ensure that all threads have reached a particular stage in a parallel computation before allowing any to proceed to the next stage. Each thread calls <code>pthread_barrier_wait()</code> to rendezvous with the others. One of the threads, chosen randomly, will see the <code>PTHREAD_BARRIER_SERIAL_THREAD</code> return value, which nominates that thread to do any cleanup or preparation between stages.</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c"><span class="co">/* life.c */</span>

<span class="pp">#include </span><span class="im">&lt;assert.h&gt;</span>
<span class="pp">#include </span><span class="im">&lt;pthread.h&gt;</span>
<span class="pp">#include </span><span class="im">&lt;stdbool.h&gt;</span>
<span class="pp">#include </span><span class="im">&lt;stdio.h&gt;</span>
<span class="pp">#include </span><span class="im">&lt;stdlib.h&gt;</span>
<span class="pp">#include </span><span class="im">&lt;string.h&gt;</span>
<span class="pp">#include </span><span class="im">&lt;time.h&gt;</span>

<span class="co">/* mandatory in POSIX.1-2008, but check laggards like macOS */</span>
<span class="pp">#include </span><span class="im">&lt;unistd.h&gt;</span>
<span class="pp">#if !defined(_POSIX_BARRIERS) || _POSIX_BARRIERS &lt; 0</span>
<span class="pp">#error your OS lacks POSIX barrier support</span>
<span class="pp">#endif</span>

<span class="co">/* dimensions of board */</span>
<span class="pp">#define ROWS 32</span>
<span class="pp">#define COLS 78</span>
<span class="co">/* how long to pause between rounds */</span>
<span class="pp">#define FRAME_MS 100</span>
<span class="pp">#define THREADS 4</span>

<span class="co">/* proper modulus (in C, '%' is merely remainder) */</span>
<span class="pp">#define MOD(x,N) (((x) &lt; 0) ? ((x) % (N) + (N)) : ((x) % (N)))</span>

bool alive[ROWS][COLS], alive_next[ROWS][COLS];
pthread_barrier_t tick;

<span class="co">/* Should a cell live or die? Using ssize_t because we have</span>
<span class="co">   to deal with signed arithmetic like row-1 when row=0 */</span>
bool fate(<span class="dt">ssize_t</span> row, <span class="dt">ssize_t</span> col)
{
	<span class="dt">ssize_t</span> i, j;
	<span class="dt">short</span> neighbors = <span class="dv">0</span>;

	assert(<span class="dv">0</span> &lt;= row &amp;&amp; row &lt; ROWS);
	assert(<span class="dv">0</span> &lt;= col &amp;&amp; col &lt; COLS);

	<span class="co">/* joined edges form a torus */</span>
	<span class="cf">for</span> (i = row-<span class="dv">1</span>; i &lt;= row+<span class="dv">1</span>; i++)
		<span class="cf">for</span> (j = col-<span class="dv">1</span>; j &lt;= col+<span class="dv">1</span>; j++)
			neighbors += alive[MOD(i, ROWS)][MOD(j, COLS)];
	<span class="co">/* don't count self as a neighbor */</span>
	neighbors -= alive[row][col];

	<span class="cf">return</span> neighbors == <span class="dv">3</span> ||
		(neighbors == <span class="dv">2</span> &amp;&amp; alive[row][col]);
}

<span class="co">/* overwrite the board on screen */</span>
<span class="dt">void</span> draw(<span class="dt">void</span>)
{
	<span class="dt">ssize_t</span> i, j;

	<span class="co">/* clear screen (non portable, requires ANSI terminal) */</span>
	fputs(<span class="st">&quot;</span><span class="sc">\033</span><span class="st">[2J</span><span class="sc">\033</span><span class="st">[1;1H&quot;</span>, stdout);

	flockfile(stdout);
	<span class="cf">for</span> (i = <span class="dv">0</span>; i &lt; ROWS; i++)
	{
		<span class="co">/* putchar_unlocked is thread safe when stdout is locked,</span>
<span class="co">		   and it's as fast as single-threaded putchar */</span>
		<span class="cf">for</span> (j = <span class="dv">0</span>; j &lt; COLS; j++)
			putchar_unlocked(alive[i][j] ? <span class="ch">'X'</span> : <span class="ch">' '</span>);
		putchar_unlocked(<span class="ch">'\n'</span>);
	}
	funlockfile(stdout);
	fflush(stdout);
}

<span class="dt">void</span> *update_strip(<span class="dt">void</span> *arg)
{
	<span class="dt">ssize_t</span> offset = *(<span class="dt">ssize_t</span>*)arg, i, j;
	<span class="kw">struct</span> timespec t;

	t.tv_sec = <span class="dv">0</span>;
	t.tv_nsec = FRAME_MS * <span class="dv">1000000</span>;

	<span class="cf">while</span> (<span class="dv">1</span>)
	{
		<span class="cf">if</span> (pthread_barrier_wait(&amp;tick) ==
			PTHREAD_BARRIER_SERIAL_THREAD)
		{
			<span class="co">/* we drew the short straw, so we're on graphics duty */</span>

			<span class="co">/* could have used pointers to multidimensional</span>
<span class="co">			 * arrays and swapped them rather than memcpy'ing</span>
<span class="co">			 * the array contents, but it makes the code a</span>
<span class="co">			 * little more complicated with dereferences */</span>
			memcpy(alive, alive_next, <span class="kw">sizeof</span> alive);
			draw();
			nanosleep(&amp;t, NULL);
		}

		<span class="co">/* rejoin at another barrier to avoid data race on</span>
<span class="co">		   the game board while it's copied and drawn */</span>
		pthread_barrier_wait(&amp;tick);
		<span class="cf">for</span> (i = offset; i &lt; offset + (ROWS / THREADS); i++)
			<span class="cf">for</span> (j = <span class="dv">0</span>; j &lt; COLS; j++)
				alive_next[i][j] = fate(i, j);
	}

	<span class="cf">return</span> NULL;
}

<span class="dt">int</span> main(<span class="dt">void</span>)
{
	pthread_t *workers;
	<span class="dt">ssize_t</span> *offsets;
	<span class="dt">size_t</span> i, j;

	assert(ROWS % THREADS == <span class="dv">0</span>);
	<span class="co">/* main counts as a thread, so need only THREADS-1 more */</span>
	workers = malloc(<span class="kw">sizeof</span>(*workers) * (THREADS-<span class="dv">1</span>));
	offsets = malloc(<span class="kw">sizeof</span>(*offsets) * ROWS / THREADS);

	srand(time(NULL));
	<span class="cf">for</span> (i = <span class="dv">0</span>; i &lt; ROWS; i++)
		<span class="cf">for</span> (j = <span class="dv">0</span>; j &lt; COLS; j++)
			alive_next[i][j] = rand() &lt; (<span class="dt">int</span>)((RAND_MAX+1u) / <span class="dv">3</span>);

	pthread_barrier_init(&amp;tick, NULL, THREADS);
	<span class="cf">for</span> (i = <span class="dv">0</span>; i &lt; THREADS-<span class="dv">1</span>; i++)
	{
		offsets[i] = i * ROWS / THREADS;
		pthread_create(&amp;workers[i], NULL, update_strip, &amp;offsets[i]);
	}

	<span class="co">/* use current thread as a worker too */</span>
	offsets[i] = i * ROWS / THREADS;
	update_strip(&amp;offsets[i]);

	<span class="co">/* shouldn't ever get here */</span>
	pthread_barrier_destroy(&amp;tick);
	free(offsets);
	free(workers);
	<span class="cf">return</span> EXIT_SUCCESS;
}</code></pre></div>
<p>It’s a fun example although slightly contrived. We’re adding a sleep between rounds to slow down the animation, so it’s unnecessary to chase parallelism. Also there’s a memoized algorithm called hashlife we should be using if pure speed is the goal. However our code illustrates a natural use for barriers.</p>
<p>Notice how we wait at the barrier twice in rapid succession. After emerging from the first barrier, one of the threads (chosen at random) copies the new state to the board and draws it. The other threads run ahead to the next barrier and wait there so they don’t cause a data race writing to the board. Once the drawing thread arrives at the barrier with them, then all can proceed to calculate cells’ fate for the next round.</p>
<p>Barriers are guaranteed to be present in POSIX.1-2008, but are optional in earlier versions of the standard. Notably macOS is stuck at an old version of POSIX. Presumably they’re too busy “innovating” with their keyboard touchbar to invest in operating system fundamentals.</p>
<h4 id="spinlocks">Spinlocks</h4>
<p>Spinlocks are implementations of mutexes optimized for fine-grained locking. Often used in low level code like drivers or operating systems, spinlocks are designed to be the most primitive and fastest sync mechanism available. They’re generally not appropriate for application programming. They are only truly necessary for situations like interrupt handlers when a thread is not allowed to go to sleep for any reason.</p>
<p>Aside from that scenario, it’s better to just use a mutex, since mutexes are pretty efficient these days. Modern mutexes often try a short-lived internal spinlock and fall back to heavier techniques only as needed. Mutexes also sometimes use a wait queue called a <strong>futex</strong>, which can take a lock in user-space whenever there is no contention from another thread.</p>
<p>When attempting to lock a spinlock, a thread runs a tight loop repeatedly checking a value in shared memory for a sign it’s safe to proceed. Spinlock implementations use special atomic assembly language instructions to test that the value is unlocked and lock it. The particular instructions vary per architecture, and can be performed in user space to avoid the overhead of a system call.</p>
<p>The while waiting for a lock, the loop doesn’t block the thread, but instead continues running and burns CPU energy. The technique works only on true multi-processor systems or a uniprocessor system with preemption enabled. On a uniprocessor system with cooperative threading the loop could never be interrupted, and will livelock.</p>
<p>In POSIX.1-2008 spinlock support is mandatory. In previous versions the presence of this feature was indicated by the <code>_POSIX_SPIN_LOCKS</code> macro. Spinlock functions start with <code>pthread_spin_</code>.</p>
<h4 id="reader-writer-locks">Reader-writer locks</h4>
<p>Whereas a mutex enforces mutual exclusion, a <strong>reader-writer lock</strong> allows concurrent read access. Multiple threads can read in parallel, but all block when a thread takes the lock for writing. The increased concurrency can improve application performance. However, blindly replacing mutexes with reader-writer locks “for performance” doesn’t work. Our earlier banker program, for instance, could suffer from duplicate withdrawals if it allowed multiple readers in an account at once.</p>
<p>Below is an rwlock example. It’s a password cracker I call 5dm (md5 backwards). It aims for maximum parallelism searching for a preimage of an MD5 hash. Worker threads periodically poll whether one among them has found an answer, and they use a reader-writer lock to avoid blocking on each other when doing so.</p>
<p>The example is slightly contrived, in that the difficulty of brute forcing passwords increases exponentially with their length. Using multiple threads reduces the time by only a constant factor – but 4x faster is still 4x faster on a four core computer!</p>
<p>The example below uses <code>MD5()</code> from OpenSSL. To build it, include <code>pkg-config --cflags libcrypto</code> in the CFLAGS and <code>pkg-config --libs libcrypto</code> in LDFLAGS. To run it, pass in an MD5 hash and max preimage search length. Note the <code>-n</code> in echo to suppress the newline, since newline is not in our search alphabet:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash">$ <span class="bu">time</span> ./5dm <span class="va">$(</span><span class="bu">echo</span> -n <span class="st">'fun'</span> <span class="kw">|</span> <span class="ex">md5</span><span class="va">)</span> 5
<span class="ex">fun</span>

<span class="ex">real</span>  0m0.067s
<span class="ex">user</span>  0m0.205s
<span class="ex">sys</span>	  0m0.007s</code></pre></div>
<p>Notice how 0.2 seconds of CPU time elapsed in parallel, but the user got their answer in 0.067 seconds.</p>
<p>On to the code:</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c"><span class="co">/* 5dm.c */</span>

<span class="pp">#include </span><span class="im">&lt;stdbool.h&gt;</span>
<span class="pp">#include </span><span class="im">&lt;stdio.h&gt;</span>
<span class="pp">#include </span><span class="im">&lt;stdlib.h&gt;</span>
<span class="pp">#include </span><span class="im">&lt;string.h&gt;</span>

<span class="pp">#include </span><span class="im">&lt;openssl/md5.h&gt;</span>
<span class="pp">#include </span><span class="im">&lt;pthread.h&gt;</span>

<span class="co">/* build arbitrary words from the ascii between ' ' and '~' */</span>
<span class="pp">#define ASCII_FIRST ' '</span>
<span class="pp">#define ASCII_LAST  '~'</span>
<span class="pp">#define N_ALPHA (1 + ASCII_LAST - ASCII_FIRST)</span>
<span class="co">/* refuse to search beyond this astronomical length */</span>
<span class="pp">#define LONGEST_PREIMAGE 128</span>

<span class="pp">#define MAX(x,y) ((x)&lt;(y) ? (y) : (x))</span>

<span class="co">/* a fast way to enumerate words, operating on an array in-place */</span>
<span class="dt">unsigned</span> word_advance(<span class="dt">char</span> *word, <span class="dt">unsigned</span> delta)
{
	<span class="cf">if</span> (delta == <span class="dv">0</span>)
		<span class="cf">return</span> <span class="dv">0</span>;
	<span class="cf">if</span> (*word == '\<span class="dv">0</span>')
	{
		*word++ = ASCII_FIRST + delta - <span class="dv">1</span>;
		*word = '\<span class="dv">0</span>';
	}
	<span class="cf">else</span>
	{
		<span class="dt">char</span> c = *word - ASCII_FIRST;
		*word = ASCII_FIRST + ((c + delta) % N_ALPHA);
		<span class="cf">if</span> (c + delta &gt;= N_ALPHA)
			<span class="cf">return</span> <span class="dv">1</span> + word_advance(word+<span class="dv">1</span>, <span class="dv">1</span> <span class="co">/* not delta */</span>);
	}
	<span class="cf">return</span> <span class="dv">1</span>;
}

<span class="co">/* pack each pair of ASCII hex digits into single bytes */</span>
bool hex2md5(<span class="dt">const</span> <span class="dt">char</span> *hex, <span class="dt">unsigned</span> <span class="dt">char</span> *b)
{
	<span class="dt">int</span> offset = <span class="dv">0</span>;
	<span class="cf">if</span>(strlen(hex) != MD5_DIGEST_LENGTH*<span class="dv">2</span>)
		<span class="cf">return</span> false;
	<span class="cf">while</span> (offset &lt; MD5_DIGEST_LENGTH*<span class="dv">2</span>)
	{
		<span class="cf">if</span> (sscanf(hex+offset, <span class="st">&quot;%2hhx&quot;</span>, b++) == <span class="dv">1</span>)
			offset += <span class="dv">2</span>;
		<span class="cf">else</span>
			<span class="cf">return</span> false;
	}
	<span class="cf">return</span> true;
}

<span class="co">/* random things a worker will need, since thread</span>
<span class="co"> * functions receive only one argument */</span>
<span class="kw">struct</span> goal
{
	<span class="co">/* input */</span>
	pthread_t *workers;
	<span class="dt">size_t</span> n_workers;
	<span class="dt">size_t</span> max_len;
	<span class="dt">unsigned</span> <span class="dt">char</span> hash[MD5_DIGEST_LENGTH];

	<span class="co">/* output */</span>
	pthread_rwlock_t lock;
	<span class="dt">char</span> preimage[LONGEST_PREIMAGE];
	bool success;
};

<span class="co">/* custom starting word for each worker, but shared goal */</span>
<span class="kw">struct</span> task
{
	<span class="kw">struct</span> goal *goal;
	<span class="dt">char</span> initial_preimage[LONGEST_PREIMAGE];
};

<span class="dt">void</span> *crack_thread(<span class="dt">void</span> *arg)
{
	<span class="kw">struct</span> task *t = arg;
	<span class="dt">unsigned</span> len, changed;
	<span class="dt">unsigned</span> <span class="dt">char</span> hashed[MD5_DIGEST_LENGTH];
	<span class="dt">char</span> preimage[LONGEST_PREIMAGE];
	<span class="dt">int</span> iterations = <span class="dv">0</span>;

	strcpy(preimage, t-&gt;initial_preimage);
	len = strlen(preimage);

	<span class="cf">while</span> (len &lt;= t-&gt;goal-&gt;max_len)
	{
		MD5((<span class="dt">const</span> <span class="dt">unsigned</span> <span class="dt">char</span>*)preimage, len, hashed);
		<span class="cf">if</span> (memcmp(hashed, t-&gt;goal-&gt;hash, MD5_DIGEST_LENGTH) == <span class="dv">0</span>)
		{
			<span class="co">/* success -- tell others to call it off */</span>
			pthread_rwlock_wrlock(&amp;t-&gt;goal-&gt;lock);

			t-&gt;goal-&gt;success = true;
			strcpy(t-&gt;goal-&gt;preimage, preimage);

			pthread_rwlock_unlock(&amp;t-&gt;goal-&gt;lock);
			<span class="cf">return</span> NULL;
		}
		<span class="co">/* each worker jumps ahead n_workers words, and all workers</span>
<span class="co">		   started at an offset, so all words are covered */</span>
		changed = word_advance(preimage, t-&gt;goal-&gt;n_workers);
		len = MAX(len, changed);

		<span class="co">/* check if another worker has succeeded, but only every</span>
<span class="co">		   thousandth iteration, since taking the lock adds overhead */</span>
		<span class="cf">if</span> (iterations++ % <span class="dv">1000</span> == <span class="dv">0</span>)
		{
			<span class="co">/* in the overwhelming majority of cases workers only read,</span>
<span class="co">			   so an rwlock allows them to continue in parallel */</span>
			pthread_rwlock_rdlock(&amp;t-&gt;goal-&gt;lock);
			<span class="dt">int</span> success = t-&gt;goal-&gt;success;
			pthread_rwlock_unlock(&amp;t-&gt;goal-&gt;lock);
			<span class="cf">if</span> (success)
				<span class="cf">return</span> NULL;
		}
	}
	<span class="cf">return</span> NULL;
}

<span class="co">/* launch a parallel search for an md5 preimage */</span>
bool crack(<span class="dt">const</span> <span class="dt">unsigned</span> <span class="dt">char</span> *md5, <span class="dt">size_t</span> max_len,
           <span class="dt">unsigned</span> threads, <span class="dt">char</span> *result)
{
	<span class="kw">struct</span> goal g =
	{
		.workers   = malloc(threads * <span class="kw">sizeof</span>(pthread_t)),
		.n_workers = threads,
		.max_len   = max_len,
		.success   = false,
		.lock      = PTHREAD_RWLOCK_INITIALIZER
	};
	memcpy(g.hash, md5, MD5_DIGEST_LENGTH);

	<span class="kw">struct</span> task *tasks = malloc(threads * <span class="kw">sizeof</span>(<span class="kw">struct</span> task));

	<span class="cf">for</span> (<span class="dt">size_t</span> i = <span class="dv">0</span>; i &lt; threads; i++)
	{
		tasks[i].goal = &amp;g;
		tasks[i].initial_preimage[<span class="dv">0</span>] = '\<span class="dv">0</span>';
		<span class="co">/* offset the starting word for each worker by i */</span>
		word_advance(tasks[i].initial_preimage, i);
		pthread_create(g.workers+i, NULL, crack_thread, tasks+i);
	}

	<span class="co">/* if one worker finds the answer, others will abort */</span>
	<span class="cf">for</span> (<span class="dt">size_t</span> i = <span class="dv">0</span>; i &lt; threads; i++)
		pthread_join(g.workers[i], NULL);

	<span class="cf">if</span> (g.success)
		strcpy(result, g.preimage);

	free(tasks);
	free(g.workers);
	<span class="cf">return</span> g.success;
}

<span class="dt">int</span> main(<span class="dt">int</span> argc, <span class="dt">char</span> **argv)
{
	<span class="dt">char</span> preimage[LONGEST_PREIMAGE];
	<span class="dt">int</span> max_len = <span class="dv">4</span>;
	<span class="dt">unsigned</span> <span class="dt">char</span> md5[MD5_DIGEST_LENGTH];

	<span class="cf">if</span> (argc != <span class="dv">2</span> &amp;&amp; argc != <span class="dv">3</span>)
	{
		fprintf(stderr,
		        <span class="st">&quot;Usage: %s md5-string [search-depth]</span><span class="sc">\n</span><span class="st">&quot;</span>,
		        argv[<span class="dv">0</span>]);
		<span class="cf">return</span> EXIT_FAILURE;
	}

	<span class="cf">if</span> (!hex2md5(argv[<span class="dv">1</span>], md5))
	{
		fprintf(stderr,
		       <span class="st">&quot;Could not parse as md5: %s</span><span class="sc">\n</span><span class="st">&quot;</span>, argv[<span class="dv">1</span>]);
		<span class="cf">return</span> EXIT_FAILURE;
	}

	<span class="cf">if</span> (argc &gt; <span class="dv">2</span> &amp;&amp; strtol(argv[<span class="dv">2</span>], NULL, <span class="dv">10</span>))
		<span class="cf">if</span> ((max_len = strtol(argv[<span class="dv">2</span>], NULL, <span class="dv">10</span>)) &gt; LONGEST_PREIMAGE)
		{
			fprintf(stderr,
					<span class="st">&quot;Preimages limited to %d characters</span><span class="sc">\n</span><span class="st">&quot;</span>,
					LONGEST_PREIMAGE);
			<span class="cf">return</span> EXIT_FAILURE;
		}

	<span class="cf">if</span> (crack(md5, max_len, <span class="dv">4</span>, preimage))
	{
		puts(preimage);
		<span class="cf">return</span> EXIT_SUCCESS;
	}
	<span class="cf">else</span>
	{
		fprintf(stderr,
				<span class="st">&quot;Could not find result in strings up to length %d</span><span class="sc">\n</span><span class="st">&quot;</span>,
		        max_len);
		<span class="cf">return</span> EXIT_FAILURE;
	}
}</code></pre></div>
<p>Although read-write locks can be implemented in terms of mutexes and condition variables, such implementations are significantly less efficient than is possible. Therefore, this synchronization primitive is included in POSIX.1-2008 for the purpose of allowing more efficient implementations in multi-processor systems.</p>
<p>The final thing to be aware of is that an rwlock implementation can choose either reader-preference or writer-preference. When readers and writers are contending for a lock, the preference determines who gets to skip the queue and go first. When there is a lot of reader activity with a reader-preference, then a writer will continually get moved to the end of the line and experience <strong>starvation</strong>, where it never gets to write. I noticed writer starvation on Linux (glibc) when running four threads on a little 1-core virtual machine. Glibc provides the nonportable <code>pthread_rwlockattr_setkind_np()</code> function to specify a preference.</p>
<p>You may have noticed that workers in our password cracker use polling to see whether the solution has been found, and whether they should give up. We’ll examine a more explicit method of cancellation in a later section.</p>
<h4 id="semaphores">Semaphores</h4>
<p>Semaphores keep count of, in the abstract, an amount of resource “units” available. Threads can safely add or remove a unit without causing a data race. When a thread requests a unit but there are none, then the thread will block.</p>
<p>A semaphore is like a mix between a lock and a condition variable. Unlike mutexes, semaphores have no concept of an owner. Any thread may release threads blocked on a semaphore, whereas with a mutex the lock holder must unlock it. Unlike a condition variable, a semaphore operates independently of a predicate.</p>
<p>An example of a problem uniquely suited for semaphores would be to ensure that exactly two threads run at once on a task. You would initialize the semaphore to the value two, and allow a bunch of threads to wait on the semaphore. After two get past, the rest will block. When each thread is done, it posts one unit back to the semaphore, which allows another thread to take its place.</p>
<p>In reality, if you’ve got pthreads, you only <em>need</em> semaphores for asynchronous signal handlers. You <em>can</em> use them in other situations, but this is the only place they are needed. Mutexes aren’t async signal safe. Making them so would be much slower than an implementation that isn’t async signal safe, and would slow down ordinary mutex operation.</p>
<p>Here’s an example of posting a semaphore from a signal handler:</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c"><span class="co">/* sem_tickler.c */</span>

<span class="pp">#include </span><span class="im">&lt;semaphore.h&gt;</span>
<span class="pp">#include </span><span class="im">&lt;signal.h&gt;</span>
<span class="pp">#include </span><span class="im">&lt;stdio.h&gt;</span>

<span class="pp">#include </span><span class="im">&lt;unistd.h&gt;</span>
<span class="pp">#if !defined(_POSIX_SEMAPHORES) || _POSIX_SEMAPHORES &lt; 0</span>
<span class="pp">#error your OS lacks POSIX semaphore support</span>
<span class="pp">#endif</span>

sem_t tickler;

<span class="dt">void</span> int_catch(<span class="dt">int</span> sig)
{
	(<span class="dt">void</span>) sig;

	signal(SIGINT, &amp;int_catch);
	sem_post(&amp;tickler); <span class="co">/* async signal safe: */</span>
}

<span class="dt">int</span> main(<span class="dt">void</span>)
{
	sem_init(&amp;tickler, <span class="dv">0</span>, <span class="dv">0</span>);
	signal(SIGINT, &amp;int_catch);

	<span class="cf">for</span> (<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; <span class="dv">3</span>; i++)
	{
		sem_wait(&amp;tickler);
		puts(<span class="st">&quot;That tickles!&quot;</span>);
	}
	puts(<span class="st">&quot;(Died from overtickling)&quot;</span>);
	<span class="cf">return</span> <span class="dv">0</span>;
}</code></pre></div>
<p>Semaphores aren’t even necessary for proper signal handling. It’s easier to have a thread simply <code>sigwait()</code> than it is to set up an asynchronous handler. In the example below, the main thread waits, but you can spawn a dedicated thread for this in a real application.</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c"><span class="co">/* sigwait_tickler.c */</span>

<span class="pp">#include </span><span class="im">&lt;signal.h&gt;</span>
<span class="pp">#include </span><span class="im">&lt;stdio.h&gt;</span>

<span class="dt">int</span> main(<span class="dt">void</span>)
{
	sigset_t set;
	<span class="dt">int</span> which;
	sigemptyset(&amp;set);
	sigaddset(&amp;set, SIGINT);

	<span class="cf">for</span> (<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; <span class="dv">3</span>; i++)
	{
		sigwait(&amp;set, &amp;which);
		puts(<span class="st">&quot;That tickles!&quot;</span>);
	}
	puts(<span class="st">&quot;(Died from overtickling)&quot;</span>);
	<span class="cf">return</span> <span class="dv">0</span>;
}</code></pre></div>
<p>So don’t feel dependent on semaphores. In fact your system may not have them. The POSIX semaphore API works with pthreads and is present in POSIX.1-2008, but is an optional part of POSIX.1b in earlier versions. Apple, for one, <a href="https://lists.apple.com/archives/darwin-kernel/2009/Apr/msg00010.html">decided</a> to punt, so the semaphore functions on macOS are stubbed to return error codes.</p>
<h3 id="cancellation">Cancellation</h3>
<p>Thread cancellation is generally used when you have threads doing long-running tasks and there’s a way for a user to abort through the UI or console. Another common scenario is when multiple threads set off to explore a search space and one finds the answer first.</p>
<p>Our previous reader-writer lock example was the second scenario, where the threads explored a search space. It was an example of do-it-yourself cancellation through polling. However sometimes threads aren’t able to poll, such as when they are blocked on I/O or a lock. Pthreads offers an API to cancel threads even in those situations.</p>
<p>By default a cancelled thread isn’t immediately blown away, because it may have a mutex locked, be holding resources, or have a potentially broken invariant. The canceller wouldn’t know how to repair that invariant without some complicated logic. The thread to be canceled needs to be written to do cleanup and unlock mutexes.</p>
<p>For each thread, cancellation can be enabled or disabled, and if enabled, may be in deferred or asynchronous mode. The default is enabled and deferred, which allows a cancelled thread to survive until the next <strong>cancellation points</strong>, such as waiting on a condition variable or blocking on IO (see <a href="https://pubs.opengroup.org/onlinepubs/9699919799/functions/V2_chap02.html#tag_15_09_05_02">full list</a>). In a purely computational section of code you can add your own cancellation points with <code>pthread_testcancel()</code>.</p>
<p>Let’s see how to modify our previous MD5 cracking example using standard pthread cancellation. Three of the functions are the same as before: <code>word_advance()</code>, <code>hex2md5()</code>, and <code>main()</code>. But we now use a condition variable to alert <code>crack()</code> whenever a <code>crack_thread()</code> returns.</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c"><span class="co">/* 5dm-testcancel.c */</span>

<span class="pp">#include </span><span class="im">&lt;stdbool.h&gt;</span>
<span class="pp">#include </span><span class="im">&lt;stdio.h&gt;</span>
<span class="pp">#include </span><span class="im">&lt;stdlib.h&gt;</span>
<span class="pp">#include </span><span class="im">&lt;string.h&gt;</span>

<span class="pp">#include </span><span class="im">&lt;openssl/md5.h&gt;</span>
<span class="pp">#include </span><span class="im">&lt;pthread.h&gt;</span>

<span class="pp">#define ASCII_FIRST ' '</span>
<span class="pp">#define ASCII_LAST  '~'</span>
<span class="pp">#define N_ALPHA (1 + ASCII_LAST - ASCII_FIRST)</span>
<span class="pp">#define LONGEST_PREIMAGE 128</span>

<span class="pp">#define MAX(x,y) ((x)&lt;(y) ? (y) : (x))</span>

<span class="dt">unsigned</span> word_advance(<span class="dt">char</span> *word, <span class="dt">unsigned</span> delta)
{
	<span class="cf">if</span> (delta == <span class="dv">0</span>)
		<span class="cf">return</span> <span class="dv">0</span>;
	<span class="cf">if</span> (*word == '\<span class="dv">0</span>')
	{
		*word++ = ASCII_FIRST + delta - <span class="dv">1</span>;
		*word = '\<span class="dv">0</span>';
	}
	<span class="cf">else</span>
	{
		<span class="dt">char</span> c = *word - ASCII_FIRST;
		*word = ASCII_FIRST + ((c + delta) % N_ALPHA);
		<span class="cf">if</span> (c + delta &gt;= N_ALPHA)
			<span class="cf">return</span> <span class="dv">1</span> + word_advance(word+<span class="dv">1</span>, <span class="dv">1</span> <span class="co">/* not delta */</span>);
	}
	<span class="cf">return</span> <span class="dv">1</span>;
}

bool hex2md5(<span class="dt">const</span> <span class="dt">char</span> *hex, <span class="dt">unsigned</span> <span class="dt">char</span> *b)
{
	<span class="dt">int</span> offset = <span class="dv">0</span>;
	<span class="cf">if</span>(strlen(hex) != MD5_DIGEST_LENGTH*<span class="dv">2</span>)
		<span class="cf">return</span> false;
	<span class="cf">while</span> (offset &lt; MD5_DIGEST_LENGTH*<span class="dv">2</span>)
	{
		<span class="cf">if</span> (sscanf(hex+offset, <span class="st">&quot;%2hhx&quot;</span>, b++) == <span class="dv">1</span>)
			offset += <span class="dv">2</span>;
		<span class="cf">else</span>
			<span class="cf">return</span> false;
	}
	<span class="cf">return</span> true;
}

<span class="kw">struct</span> goal
{
	<span class="co">/* input */</span>
	pthread_t *workers;
	<span class="dt">size_t</span> n_workers;
	<span class="dt">size_t</span> max_len;
	<span class="dt">unsigned</span> <span class="dt">char</span> hash[MD5_DIGEST_LENGTH];

	<span class="co">/* output */</span>
	pthread_mutex_t lock;
	pthread_cond_t returning;
	<span class="dt">unsigned</span> n_done;
	<span class="dt">char</span> preimage[LONGEST_PREIMAGE];
	bool success;
};

<span class="kw">struct</span> task
{
	<span class="kw">struct</span> goal *goal;
	<span class="dt">char</span> initial_preimage[LONGEST_PREIMAGE];
};

<span class="dt">void</span> *crack_thread(<span class="dt">void</span> *arg)
{
	<span class="kw">struct</span> task *t = arg;
	<span class="dt">unsigned</span> len, changed;
	<span class="dt">unsigned</span> <span class="dt">char</span> hashed[MD5_DIGEST_LENGTH];
	<span class="dt">char</span> preimage[LONGEST_PREIMAGE];
	<span class="dt">int</span> iterations = <span class="dv">0</span>;

	strcpy(preimage, t-&gt;initial_preimage);
	len = strlen(preimage);

	<span class="cf">while</span> (len &lt;= t-&gt;goal-&gt;max_len)
	{
		MD5((<span class="dt">const</span> <span class="dt">unsigned</span> <span class="dt">char</span>*)preimage, len, hashed);
		<span class="cf">if</span> (memcmp(hashed, t-&gt;goal-&gt;hash, MD5_DIGEST_LENGTH) == <span class="dv">0</span>)
		{
			pthread_mutex_lock(&amp;t-&gt;goal-&gt;lock);

			t-&gt;goal-&gt;success = true;
			strcpy(t-&gt;goal-&gt;preimage, preimage);
			t-&gt;goal-&gt;n_done++;

			<span class="co">/* alert the boss that another worker is done */</span>
			pthread_cond_signal(&amp;t-&gt;goal-&gt;returning);
			pthread_mutex_unlock(&amp;t-&gt;goal-&gt;lock);
			<span class="cf">return</span> NULL;
		}
		changed = word_advance(preimage, t-&gt;goal-&gt;n_workers);
		len = MAX(len, changed);

		<span class="cf">if</span> (iterations++ % <span class="dv">1000</span> == <span class="dv">0</span>)
			pthread_testcancel(); <span class="co">/* add a cancellation point */</span>
	}

	pthread_mutex_lock(&amp;t-&gt;goal-&gt;lock);
	t-&gt;goal-&gt;n_done++;
	<span class="co">/* alert the boss that another worker is done */</span>
	pthread_cond_signal(&amp;t-&gt;goal-&gt;returning);
	pthread_mutex_unlock(&amp;t-&gt;goal-&gt;lock);
	<span class="cf">return</span> NULL;
}

<span class="co">/* cancellation cleanup function that we also call</span>
<span class="co"> * during regular exit from the crack() function */</span>
<span class="dt">void</span> crack_cleanup(<span class="dt">void</span> *arg)
{
	<span class="kw">struct</span> task *tasks = arg;
	<span class="kw">struct</span> goal *g = tasks[<span class="dv">0</span>].goal;

	<span class="co">/* this mutex unlock pairs with the lock in the crack() function */</span>
	pthread_mutex_unlock(&amp;g-&gt;lock);
	<span class="cf">for</span> (<span class="dt">size_t</span> i = <span class="dv">0</span>; i &lt; g-&gt;n_workers; i++)
	{
		pthread_cancel(g-&gt;workers[i]);
		<span class="co">/* must wait for each to terminate, so that freeing</span>
<span class="co">		 * their shared memory is safe */</span>
		pthread_join(g-&gt;workers[i], NULL);
	}
	<span class="co">/* now it's safe to free memory */</span>
	free(g-&gt;workers);
	free(tasks);
}

bool crack(<span class="dt">const</span> <span class="dt">unsigned</span> <span class="dt">char</span> *md5, <span class="dt">size_t</span> max_len,
           <span class="dt">unsigned</span> threads, <span class="dt">char</span> *result)
{
	<span class="kw">struct</span> goal g =
	{
		.workers   = malloc(threads * <span class="kw">sizeof</span>(pthread_t)),
		.n_workers = threads,
		.max_len   = max_len,
		.success   = false,
		.n_done    = <span class="dv">0</span>,
		.lock      = PTHREAD_MUTEX_INITIALIZER,
		.returning = PTHREAD_COND_INITIALIZER
	};
	memcpy(g.hash, md5, MD5_DIGEST_LENGTH);

	<span class="kw">struct</span> task *tasks = malloc(threads * <span class="kw">sizeof</span>(<span class="kw">struct</span> task));

	<span class="cf">for</span> (<span class="dt">size_t</span> i = <span class="dv">0</span>; i &lt; threads; i++)
	{
		tasks[i].goal = &amp;g;
		tasks[i].initial_preimage[<span class="dv">0</span>] = '\<span class="dv">0</span>';
		word_advance(tasks[i].initial_preimage, i);
		pthread_create(g.workers+i, NULL, crack_thread, tasks+i);
	}

	<span class="co">/* coming up to cancellation points, so establish</span>
<span class="co">	 * a cleanup handler */</span>
	pthread_cleanup_push(crack_cleanup, tasks);

	pthread_mutex_lock(&amp;g.lock);
	<span class="co">/* We can't join() on all the workers now because it's up to</span>
<span class="co">	 * us to cancel them after one finds the answer. We have to</span>
<span class="co">	 * remain responsive and not block on any particular worker */</span>
	<span class="cf">while</span> (!g.success &amp;&amp; g.n_done &lt; threads)
		pthread_cond_wait(&amp;g.returning, &amp;g.lock);
	<span class="co">/* at this point either a thread succeeded or all have given up */</span>
	<span class="cf">if</span> (g.success)
		strcpy(result, g.preimage);
	<span class="co">/* mutex unlocked in the cleanup handler */</span>

	<span class="co">/* Use the same cleanup handler for normal exit too. The &quot;1&quot;</span>
<span class="co">	 * argument says to execute the function we had previous pushed */</span>
	pthread_cleanup_pop(<span class="dv">1</span>);
	<span class="cf">return</span> g.success;
}

<span class="dt">int</span> main(<span class="dt">int</span> argc, <span class="dt">char</span> **argv)
{
	<span class="dt">char</span> preimage[LONGEST_PREIMAGE];
	<span class="dt">int</span> max_len = <span class="dv">4</span>;
	<span class="dt">unsigned</span> <span class="dt">char</span> md5[MD5_DIGEST_LENGTH];

	<span class="cf">if</span> (argc != <span class="dv">2</span> &amp;&amp; argc != <span class="dv">3</span>)
	{
		fprintf(stderr,
		        <span class="st">&quot;Usage: %s md5-string [search-depth]</span><span class="sc">\n</span><span class="st">&quot;</span>,
		        argv[<span class="dv">0</span>]);
		<span class="cf">return</span> EXIT_FAILURE;
	}

	<span class="cf">if</span> (!hex2md5(argv[<span class="dv">1</span>], md5))
	{
		fprintf(stderr,
		       <span class="st">&quot;Could not parse as md5: %s</span><span class="sc">\n</span><span class="st">&quot;</span>, argv[<span class="dv">1</span>]);
		<span class="cf">return</span> EXIT_FAILURE;
	}

	<span class="cf">if</span> (argc &gt; <span class="dv">2</span> &amp;&amp; strtol(argv[<span class="dv">2</span>], NULL, <span class="dv">10</span>))
		<span class="cf">if</span> ((max_len = strtol(argv[<span class="dv">2</span>], NULL, <span class="dv">10</span>)) &gt; LONGEST_PREIMAGE)
		{
			fprintf(stderr,
					<span class="st">&quot;Preimages limited to %d characters</span><span class="sc">\n</span><span class="st">&quot;</span>,
					LONGEST_PREIMAGE);
			<span class="cf">return</span> EXIT_FAILURE;
		}

	<span class="cf">if</span> (crack(md5, max_len, <span class="dv">4</span>, preimage))
	{
		puts(preimage);
		<span class="cf">return</span> EXIT_SUCCESS;
	}
	<span class="cf">else</span>
	{
		fprintf(stderr,
				<span class="st">&quot;Could not find result in strings up to length %d</span><span class="sc">\n</span><span class="st">&quot;</span>,
		        max_len);
		<span class="cf">return</span> EXIT_FAILURE;
	}
}</code></pre></div>
<p>Using cancellation is actually a little more flexible than our rwlock implementation in 5dm. If the <code>crack()</code> function is running in its own thread, the whole thing can now be cancelled. The cancellation handler will “pass along” the cancellation to each of the worker threads.</p>
<p>Writing general purpose library code that works with threads requires some care. It should handle deferred cancellation gracefully, including disabling cancellation when appropriate and always using cleanup handlers.</p>
<p>For cleanup handlers, notice the pattern of how we <code>pthread_cleanup_push()</code> the cancellation handler, and later <code>pthread_cleanup_pop()</code> it for regular (non-cancel) cleanup too. Using the same cleanup procedure in all situations makes the code more reliable.</p>
<p>Also notice how the boss thread now cancels workers, rather than the winning worker cancelling the others. You can join a canceled thread, but you can’t cancel an already joined (or detached) thread. If you want to both cancel and join a thread it ought to be done in one place.</p>
<p>Let’s turn out attention to the new worker threads. They are still polling for cancellation, like they polled with the reader-writer locks, but in this case they do it with a new function:</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c"><span class="cf">if</span> (iterations++ % <span class="dv">1000</span> == <span class="dv">0</span>)
	pthread_testcancel();</code></pre></div>
<p>Admittedly it adds a little overhead to poll every thousandth loop, both with the rwlock, and with the testcancel. It also adds latency to the time between the cancellation request and the thread quitting, since the loop could run up to 999 times in between. A more efficient but dangerous method is to enable <strong>asynchronous cancellation</strong>, meaning the thread immediately dies when cancelled.</p>
<p>Async cancellation is dangerous because code is seldom async-cancel-safe. Anything that uses locks or works with shared state even slightly can break badly. Async-cancel-safe code can call very few functions, since those functions may not be safe. This includes calling libraries that use something as innocent as <code>malloc()</code>, since stopping malloc part way through could corrupt the heap.</p>
<p>Our <code>crack_thread()</code> function should be async-cancel-safe, at least during its calculation and not when taking locks. The <code>MD5()</code> function from OpenSSL also appears to be safe. Here’s how we can rewrite our function (notice how we disable cancellation before taking a lock):</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c"><span class="co">/* rewritten to use async cancellation */</span>

<span class="dt">void</span> *crack_thread(<span class="dt">void</span> *arg)
{
	<span class="kw">struct</span> task *t = arg;
	<span class="dt">unsigned</span> len, changed;
	<span class="dt">unsigned</span> <span class="dt">char</span> hashed[MD5_DIGEST_LENGTH];
	<span class="dt">char</span> preimage[LONGEST_PREIMAGE];
	<span class="dt">int</span> cancel_type, cancel_state;

	strcpy(preimage, t-&gt;initial_preimage);
	len = strlen(preimage);

	<span class="co">/* async so we don't have to pthread_testcancel() */</span>
	pthread_setcanceltype(
			PTHREAD_CANCEL_ASYNCHRONOUS, &amp;cancel_type);

	<span class="cf">while</span> (len &lt;= t-&gt;goal-&gt;max_len)
	{
		MD5((<span class="dt">const</span> <span class="dt">unsigned</span> <span class="dt">char</span>*)preimage, len, hashed);
		<span class="cf">if</span> (memcmp(hashed, t-&gt;goal-&gt;hash, MD5_DIGEST_LENGTH) == <span class="dv">0</span>)
		{
			<span class="co">/* protect the mutex against async cancellation */</span>
			pthread_setcancelstate(
					PTHREAD_CANCEL_DISABLE, &amp;cancel_state);
			pthread_mutex_lock(&amp;t-&gt;goal-&gt;lock);

			t-&gt;goal-&gt;success = true;
			strcpy(t-&gt;goal-&gt;preimage, preimage);
			t-&gt;goal-&gt;n_done++;

			pthread_cond_signal(&amp;t-&gt;goal-&gt;returning);
			pthread_mutex_unlock(&amp;t-&gt;goal-&gt;lock);
			<span class="cf">return</span> NULL;
		}
		changed = word_advance(preimage, t-&gt;goal-&gt;n_workers);
		len = MAX(len, changed);
	}

	<span class="co">/* restore original cancellation type */</span>
	pthread_setcanceltype(cancel_type, &amp;cancel_type);

	pthread_mutex_lock(&amp;t-&gt;goal-&gt;lock);
	t-&gt;goal-&gt;n_done++;
	pthread_cond_signal(&amp;t-&gt;goal-&gt;returning);
	pthread_mutex_unlock(&amp;t-&gt;goal-&gt;lock);
	<span class="cf">return</span> NULL;
}</code></pre></div>
<p>Asynchronous cancellation does not appear to work on macOS, but as we’ve seen that’s par for the course on that operating system.</p>
<h3 id="development-tools">Development tools</h3>
<h4 id="valgrind-drd-and-helgrind">Valgrind DRD and helgrind</h4>
<p><a href="https://valgrind.org/docs/manual/drd-manual.html">DRD</a> and <a href="https://valgrind.org/docs/manual/hg-manual.html">Helgrind</a> are Valgrind tools for detecting errors in multithreaded C and C++ programs. The tools work for any program that uses the POSIX threading primitives or that uses threading concepts built on top of the POSIX threading primitives.</p>
<p>The tools have overlapping abilities like detecting data races and improper use of the pthreads API. Additionally, Helgrind can detect locking hierarchy violations, and DRD can alert when there is lock contention.</p>
<p>Both tools pinpoint the lines of code where problems arise. For example, we can run DRD on our first crazy bankers program:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash"><span class="fu">valgrind</span> --tool=drd ./banker</code></pre></div>
<p>Here is a characteristic example of an error it emits:</p>
<pre><code>==8524== Thread 3:
==8524== Conflicting load by thread 3 at 0x003090b0 size 8
==8524==    at 0x1088BD: disburse (banker.c:48)
==8524==    by 0x4C324F3: vgDrd_thread_wrapper (drd_pthread_intercepts.c:444)
==8524==    by 0x4E514A3: start_thread (pthread_create.c:456)
==8524== Allocation context: BSS section of /home/admin/banker
==8524== Other segment start (thread 2)
==8524==    at 0x514FD01: clone (clone.S:80)
==8524== Other segment end (thread 2)
==8524==    at 0x509D820: rand (rand.c:26)
==8524==    by 0x108857: rand_range (banker.c:26)
==8524==    by 0x1088A0: disburse (banker.c:42)
==8524==    by 0x4C324F3: vgDrd_thread_wrapper (drd_pthread_intercepts.c:444)
==8524==    by 0x4E514A3: start_thread (pthread_create.c:456)</code></pre>
<p>It finds conflicting loads and stores from lines 48, 51, and 52.</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c"><span class="dv">48</span>: <span class="cf">if</span> (accts[from].balance &gt; <span class="dv">0</span>)
<span class="dv">49</span>: {
<span class="dv">50</span>:		payment = <span class="dv">1</span> + rand_range(accts[from].balance);
<span class="dv">51</span>:		accts[from].balance -= payment;
<span class="dv">52</span>:		accts[to].balance   += payment;
<span class="dv">53</span>: }</code></pre></div>
<p>Helgrind can identify the lock hierarchy violation in our example of deadlocking bankers:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash"><span class="fu">valgrind</span> --tool=helgrind ./banker_lock</code></pre></div>
<pre><code>==8989== Thread #4: lock order &quot;0x3091F8 before 0x3090D8&quot; violated
==8989==
==8989== Observed (incorrect) order is: acquisition of lock at 0x3090D8
==8989==    at 0x4C3010C: mutex_lock_WRK (hg_intercepts.c:904)
==8989==    by 0x1089B9: disburse (banker_lock.c:38)
==8989==    by 0x4C32D06: mythread_wrapper (hg_intercepts.c:389)
==8989==    by 0x4E454A3: start_thread (pthread_create.c:456)
==8989==
==8989==  followed by a later acquisition of lock at 0x3091F8
==8989==    at 0x4C3010C: mutex_lock_WRK (hg_intercepts.c:904)
==8989==    by 0x1089D1: disburse (banker_lock.c:39)
==8989==    by 0x4C32D06: mythread_wrapper (hg_intercepts.c:389)
==8989==    by 0x4E454A3: start_thread (pthread_create.c:456)</code></pre>
<p>To identify when there is too much contention for a lock, we can ask DRD to alert us when a thread blocks for more than <em>n</em> milliseconds on a mutex:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash"><span class="fu">valgrind</span> --tool=drd --exclusive-threshold=2 ./banker_lock_hierarchy</code></pre></div>
<p>Since we throw too many threads at a small number of accounts, we see wait times that cross the threshold, like this one that waited seven ms:</p>
<pre><code>==7565== Acquired at:
==7565==    at 0x483F428: pthread_mutex_lock_intercept (drd_pthread_intercepts.c:888)
==7565==    by 0x483F428: pthread_mutex_lock (drd_pthread_intercepts.c:898)
==7565==    by 0x109280: disburse (banker_lock_hierarchy.c:40)
==7565==    by 0x483C114: vgDrd_thread_wrapper (drd_pthread_intercepts.c:444)
==7565==    by 0x4863FA2: start_thread (pthread_create.c:486)
==7565==    by 0x49764CE: clone (clone.S:95)
==7565== Lock on mutex 0x10c258 was held during 7 ms (threshold: 2 ms).
==7565==    at 0x4840478: pthread_mutex_unlock_intercept (drd_pthread_intercepts.c:978)
==7565==    by 0x4840478: pthread_mutex_unlock (drd_pthread_intercepts.c:991)
==7565==    by 0x109395: disburse (banker_lock_hierarchy.c:47)
==7565==    by 0x483C114: vgDrd_thread_wrapper (drd_pthread_intercepts.c:444)
==7565==    by 0x4863FA2: start_thread (pthread_create.c:486)
==7565==    by 0x49764CE: clone (clone.S:95)
==7565== mutex 0x10c258 was first observed at:
==7565==    at 0x483F368: pthread_mutex_lock_intercept (drd_pthread_intercepts.c:885)
==7565==    by 0x483F368: pthread_mutex_lock (drd_pthread_intercepts.c:898)
==7565==    by 0x109280: disburse (banker_lock_hierarchy.c:40)
==7565==    by 0x483C114: vgDrd_thread_wrapper (drd_pthread_intercepts.c:444)
==7565==    by 0x4863FA2: start_thread (pthread_create.c:486)
==7565==    by 0x49764CE: clone (clone.S:95)</code></pre>
<h4 id="clang-threadsanitizer-tsan">Clang ThreadSanitizer (TSan)</h4>
<p>ThreadSanitizer is a clang instrumentation module. To use it, choose <code>CC = clang</code> and add <code>-fsanitize=thread</code> to CFLAGS. Then when you build programs, they will be modified to detect data races and print statistics to stderr.</p>
<p>Here’s a portion of the output when running the bankers program:</p>
<pre><code>WARNING: ThreadSanitizer: data race (pid=11312)
  Read of size 8 at 0x0000014aeeb0 by thread T2:
    #0 disburse /home/admin/banker.c:48 (banker+0x0000004a4372)

  Previous write of size 8 at 0x0000014aeeb0 by thread T1:
    #0 disburse /home/admin/banker.c:52 (banker+0x0000004a43ba)</code></pre>
<p>TSan can also detect lock hierarchy violations, such as in banker_lock:</p>
<pre><code>WARNING: ThreadSanitizer: lock-order-inversion (potential deadlock) (pid=10095)
  Cycle in lock order graph: M1 (0x0000014aef78) =&gt; M2 (0x0000014aeeb8) =&gt; M1

  Mutex M2 acquired here while holding mutex M1 in thread T1:
    #0 pthread_mutex_lock &lt;null&gt; (banker_lock+0x000000439a10)
    #1 disburse /home/admin/banker_lock.c:39 (banker_lock+0x0000004a4398)

    Hint: use TSAN_OPTIONS=second_deadlock_stack=1 to get more informative warning message

  Mutex M1 acquired here while holding mutex M2 in thread T9:
    #0 pthread_mutex_lock &lt;null&gt; (banker_lock+0x000000439a10)
    #1 disburse /home/admin/banker_lock.c:39 (banker_lock+0x0000004a4398)</code></pre>
<h4 id="mutrace">Mutrace</h4>
<p>While Valgrind DRD can identify highly contended locks, it virtualizes the execution of the program under test, and skews the numbers. Other utilities can use software probes to get this information from a test running at full speed. In BSD land there is the <a href="http://dtrace.org/guide/chp-plockstat.html">plockstat</a> provider for DTrace, and on Linux there is the specially-written <a href="http://0pointer.de/blog/projects/mutrace.html">mutrace</a>. I had a lot of trouble trying to get plockstat to work on FreeBSD, so here’s an example of using mutrace to analyze our banker program.</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash"><span class="ex">mutrace</span> ./banker_lock_hierarchy</code></pre></div>
<pre><code>mutrace: Showing 10 most contended mutexes:

 Mutex #   Locked  Changed    Cont. tot.Time[ms] avg.Time[ms] max.Time[ms]  Flags
       0   200211   153664    95985      991.349        0.005        0.267 M-.--.
       1   200552   142173    61902      641.963        0.003        0.170 M-.--.
       2   199657   140837    47723      476.737        0.002        0.125 M-.--.
       3   199566   140863    39268      371.451        0.002        0.108 M-.--.
       4   199936   141381    33243      295.909        0.001        0.090 M-.--.
       5   199548   141297    28193      232.647        0.001        0.084 M-.--.
       6   200329   142027    24230      183.301        0.001        0.066 M-.--.
       7   199951   142338    21018      142.494        0.001        0.057 M-.--.
       8   200145   142990    18201      107.692        0.001        0.052 M-.--.
       9   200105   143794    15713       76.231        0.000        0.028 M-.--.
                                                                           ||||||
                                                                           /|||||
          Object:                                     M = Mutex, W = RWLock /||||
           State:                                 x = dead, ! = inconsistent /|||
             Use:                                 R = used in realtime thread /||
      Mutex Type:                 r = RECURSIVE, e = ERRRORCHECK, a = ADAPTIVE /|
  Mutex Protocol:                                      i = INHERIT, p = PROTECT /
     RWLock Kind: r = PREFER_READER, w = PREFER_WRITER, W = PREFER_WRITER_NONREC

mutrace: Note that the flags column R is only valid in --track-rt mode!

mutrace: Total runtime is 1896.903 ms.

mutrace: Results for SMP with 4 processors.</code></pre>
<h4 id="off-cpu-profiling">Off-CPU profiling</h4>
<p>Typical profilers measure the amount of CPU time spent in each function. However when a thread is blocked by I/O, a lock, or a condition variable, then it isn’t using CPU time. To determine where functions spend the most “wall clock time,” we need to sample the call stack for all threads at intervals, and count how frequently we see each entry. When a thread is off-CPU its call stack stays unchanged.</p>
<p>The <code>pstack</code> program is traditionally the way to get a snapshot of a running program’s stack. It exists on old Unices, and used to be on Linux until Linux made a breaking change. The most portable way to get stack snapshots is using gdb with an awk wrapper, as documented in the <a href="http://poormansprofiler.org">Poor Man’s Profiler</a>.</p>
<p>Remember our early condition variable example that measured how many threads entered the critical section in <code>disburse()</code> at once? We asked whether synchronization on <code>stats_mtx</code> threw off the measurement. With off-CPU profiling we can look for clues.</p>
<p>Here’s a script based on the Poor Man’s Profiler:</p>
<div class="sourceCode"><pre class="sourceCode sh"><code class="sourceCode bash"><span class="ex">./banker_stats</span> <span class="kw">&amp;</span>
<span class="va">pid=$!</span>

<span class="kw">while</span> <span class="bu">kill</span> -0 <span class="va">$pid</span>
  <span class="kw">do</span>
    <span class="fu">gdb</span> -ex <span class="st">&quot;set pagination 0&quot;</span> -ex <span class="st">&quot;thread apply all bt&quot;</span> -batch -p <span class="va">$pid</span>
  <span class="kw">done</span> <span class="kw">|</span> <span class="kw">\</span>
<span class="fu">awk</span> <span class="st">'</span>
<span class="st">  BEGIN { s = &quot;&quot;; }</span>
<span class="st">  /^Thread/ { print s; s = &quot;&quot;; }</span>
<span class="st">  /^\#/ { if (s != &quot;&quot; ) { s = s &quot;,&quot; $4} else { s = $4 } }</span>
<span class="st">  END { print s }'</span> <span class="kw">|</span> <span class="kw">\</span>
<span class="fu">sort</span> <span class="kw">|</span> <span class="fu">uniq</span> -c <span class="kw">|</span> <span class="fu">sort</span> -r -n -k 1,1</code></pre></div>
<p>It outputs limited information, but we can see that waiting for locks in <code>disburse()</code> takes the majority of program time, being present in 872 of our samples. By contrast, waiting for the <code>stats_mtx</code> lock in <code>stats_update()</code> doesn’t appear in our sample at all. It must have had very little affect on our parallelism.</p>
<pre><code>    872 at,__GI___pthread_mutex_lock,disburse,start_thread,clone
     11 at,__random,rand,rand_range,disburse,start_thread,clone
      9 expected=0,,mutex=0x562533c3f0c0,&lt;stats_cnd&gt;,,stats_print,start_thread,clone
      9 __GI___pthread_timedjoin_ex,main
      5 at,__pthread_mutex_unlock_usercnt,disburse,start_thread,clone
      1 at,__pthread_mutex_unlock_usercnt,stats_change,disburse,start_thread,clone
      1 at,__GI___pthread_mutex_lock,stats_change,disburse,start_thread,clone
      1 __random,rand,rand_range,disburse,start_thread,clone</code></pre>
<h4 id="macos-instruments">macOS Instruments</h4>
<p>Although Mac’s POSIX thread support is pretty weak, its XCode tooling does include a nice profiler. From the Instruments application, choose the profiling template called “System Trace.” It adds a GUI on top of DTrace to display thread states (among other things). I modified our banker program to use only five threads and recorded its run. The Instruments app visualizes every event that happens, including threads blocking and being interrupted:</p>
<div class="figure">
<img src="https://begriffs.com/images/thread-states.png" alt="thread states" />
<p class="caption">thread states</p>
</div>
<p>Within the program you can zoom into the history and hover over events for info.</p>
<h4 id="perf-c2c">perf c2c</h4>
<p>Perf is a Linux tool to measure hardware performance counters during the execution of a program. Joe Mario created a Perf feature called <a href="https://joemario.github.io/blog/2016/09/01/c2c-blog/">c2c</a> which detects <strong>false sharing</strong> of variables between CPUs.</p>
<p>In a NUMA multi-core computer, each CPU has its own set of caches, and all CPUs share main memory. Memory is divided into fixed size blocks (often 64 bytes) called <strong>cache lines</strong>. Any time a CPU reads or writes memory, it must fetch or store the entire cache line surrounding the desired address. If one CPU has already cached a line, and another CPU writes to that area in memory, the system has to perform an expensive operation to make the caches coherent.</p>
<p>When two unrelated variables in a program are stored close enough together in memory to be in the same cache line, it can cause a performance problem in multi-threaded programs. If threads running on separate CPUs access the unrelated variables, it can cause a tug of war between their underlying cache line, which is called false sharing.</p>
<p>For instance, our Game of Life simulator could potentially have false sharing at the edges of each section of board accessed by each thread. To verify this, I attempted to run perf c2c on an Amazon EC2 instance (since I lack a physical computer running Linux), but got an error that memory events are not supported on the virtual machine. I was running kernel 4.19.0 on Intel Xeon Platinum 8124M CPUs, so I assume this was a security restriction from Amazon.</p>
<p>If you are able to run c2c, and detect false sharing in a multi-threaded program, the solution is to align the variables more aggressively. POSIX provides the <a href="https://pubs.opengroup.org/onlinepubs/9699919799/functions/posix_memalign.html">posix_memalign()</a> function to allocate bytes aligned on a desired boundary. In our Life example, we could have used an array of pointers to dynamically allocated rows rather than a contiguous two-dimensional array.</p>
<h4 id="intel-vtune-profiler">Intel VTune Profiler</h4>
<p>The VTune Profiler is available for free (with registration) on Linux, macOS, and Windows. It works on x86 hardware only of course. I haven’t used it, but their <a href="https://software.intel.com/en-us/vtune/features/multithreaded">marketing page</a> shows some nice pictures. The tool can visually identify the granularity of locks, present a prioritized list of synchronization objects that hurt performance, and visualize lock contention.</p>
<h3 id="further-reading">Further reading</h3>
<ul>
<li><a href="https://www.goodreads.com/book/show/987956.Programming_with_Posix_Threads">Programming with Posix Threads</a> by David R. Butenhof</li>
<li><a href="https://www.goodreads.com/book/show/828272.Pthreads_Programming">Pthreads Programming</a> by Bradford Nichols, Dick Buttlar, Jacqueline Farrell</li>
<li><a href="https://www.goodreads.com/book/show/15710583-is-parallel-programming-hard-and-if-so-what-can-you-do-about-it">Is Parallel Programming Hard, And, If So, What Can You Do About It?</a> by Paul McKenney</li>
</ul></p>
<p>
<em><a href="https://begriffs.com/posts/2020-03-23-concurrent-programming.html">March 23, 2020 12:00 AM</a></em>
</p>





<h2>March 22, 2020</h2>




<hr><h3 class="post"><a href="http://shape-of-code.coding-guidelines.com" title="The Shape of Code">Derek Jones (derek-jones)</a></h3>


<h4><a href="http://shape-of-code.coding-guidelines.com/2020/03/22/coronavirus-a-silver-lining-for-evidence-based-software-engineering/">Coronavirus: a silver lining for evidence-based software engineering?</a></h4>
<p>
People rarely measure things in software engineering, and when they do they rarely hang onto the measurements; this might also be true in many other work disciplines. When I worked on optimizing compilers, I used to spend time comparing code size and performance. It surprised me that many others in the field did not, they [&#8230;]</p>
<p>
<em><a href="http://shape-of-code.coding-guidelines.com/2020/03/22/coronavirus-a-silver-lining-for-evidence-based-software-engineering/">March 22, 2020 09:39 PM</a></em>
</p>









<hr><h3 class="post"><a href="http://brooker.co.za/blog/" title="Marc Brooker's Blog">Marc Brooker (mjb)</a></h3>


<h4><a href="http://brooker.co.za/blog/2020/03/22/rust.html">Two Years With Rust</a></h4>
<p>
<h1>Two Years With Rust</h1>

<p class="meta">I like it. I hope it's going to be big.</p>


<p>It's been just over two years since I started learning Rust. Since then, I've used it heavily at my day job, including work in the <a href="https://github.com/firecracker-microvm/firecracker">Firecracker</a> code base, and a number of other projects. Rust is a great fit for the systems-level work I've been doing over the last few years: often performance- and density-sensitive, always security-sensitive. I find the type system, object life cycle, and threading model both well-suited to this kind of work and fairly intuitive. Like most people, I still fight with the compiler from time-to-time, but we mostly get on now.</p>

<p>Rust has also mostly replaced Go as my go-to language for writing small performance-sensitive programs, like the numerical simulators I use a lot. Go replaced C in that role for me, and joined R and Python as my day-to-day go-to tools. I've found that I still spend more time writing a Rust program than I do Go, and more than C (except where C is held back by a lack of sane data structures and string handling). I've also found that programs seem more likely to work on their first run, but haven't made any effort to quantify that.</p>

<p>Over my career, I've done for-pay work in C, C++, Java, Python, Ruby, Go, Rust, Scheme, Basic, Perl, Bash, TLA+, Delphi, Matlab, ARM and x86 assembly, and R (probably forgetting a few). There's likely some of my code in each of those languages still running somewhere. I've also learned a bunch of other languages, because it's something I enjoy doing. Recently, for example, I've been loving playing with <a href="https://frinklang.org/">Frink</a>. I don't tend to be highly opinionated about languages.</p>

<p>However, in some cases I steer colleagues and teams away from particular choices. C and C++, for example, seem to be difficult and expensive to use in a way that avoids dangerous memory-safety bugs, and users need to be willing to invest deeply in their code if these bugs matter to them. It's possible to write great safe C, but the path there requires a challenging blend of tools and humility. Rust isn't a panacea, but is a really nice alternative where they were fairly thin before. I find myself recommending and choosing it more and more often for small command-line programs, high-performance services, and system-level code.</p>

<p><strong>Why I like Rust</strong>
There are a lot of good programming languages in the world. There are even multiple that fit Rust's broad description, and place in the ecosystem. This is a very good place, with real problems to solve. I'm not convinced that Rust is necessarily technically superior to its nearest neighbors, but there are some things it seems to do particularly well.</p>

<p>I like how friendly and helpful the compiler's error messages are. The free book and standard library documentation are all very good. The type system is nice to work with. The built-in tooling (rustup, cargo and friends) are easy and powerful. A standard formatting tool goes a long way to keeping code-bases tidy and bikesheds unpainted. Static linking and cross-compiling are built-in. The smattering of functional idioms seem to add a good amount of power and expressiveness. Features that actively lead to obtuse code (like macros) are discouraged. Out-of-the-box performance is pretty great. <a href="https://doc.rust-lang.org/book/ch16-00-concurrency.html#fearless-concurrency">Fearless Concurrency</a> actually delivers.</p>

<p>There's a lot more, too.</p>

<p><strong>What might make Rust unsuccessful?</strong>
There are also some things I don't particularly like about Rust. Some of those are short-term. Learning how to write async networking code in Rust during the year or so before <em>async</em> and <em>await</em> were stabilized was a frustrating mess of inconsistent documentation and broken APIs. The compiler isn't as smart about optimizations like loop unrolling and autovectorization as C compilers tend to be (even where it does a great job eliding the safety checks, and other Rust-specific overhead). Some parts of the specification, like aliasing rules and the exact definitions of <a href="https://doc.rust-lang.org/std/sync/atomic/enum.Ordering.html">atomic memory orderings</a>, are still a little fuzzier than I would like. Static analysis tooling has a way to go. Allocating aligned memory is tricky, especially if you still want to use some of the standard data structures. And so on.</p>

<p>In each of these cases, and more like them, the situation seems to have improved every time I look at it in detail. The community seems to be making great progress. <em>async</em> and <em>await</em> were particularly big wins.</p>

<p>The biggest long-term issue in my mind is <em>unsafe</em>. Rust makes what seems like a very reasonable decision to allow sections of code to be marked as <em>unsafe</em>, which allows one to color outside the lines of the memory and life cycle guarantees. As the name implies <em>unsafe</em> code tends to be <em>unsafe</em>. The big problem with <em>unsafe</em> code isn't that the code inside the block is unsafe, it's that it can break the safety properties of safe code in subtle and non-obvious ways. Even safe code that's thousands of lines away. This kind of action-at-a-distance can make it difficult to reason about the properties of any code-base that contains <em>unsafe</em> code. For low-level systems code, that's probably all of them.</p>

<p>This isn't a surprise to the community. The Rust community is very realistic about the costs and benefits of <em>unsafe</em>. Sometimes that debate goes too far (as <a href="https://words.steveklabnik.com/a-sad-day-for-rust">Steve Klabnik has written about</a>), but mostly the debate and culture seems healthy to me as a relative outsider.</p>

<p>The problem is that this spooky behavior of <em>unsafe</em> tends not to be obvious to new Rust programmers. The mental model I've seen nearly everybody start with, including myself, is that <em>unsafe</em> blocks can break things inside them and so care needs to be paid to writing that code well. Unfortunately, that's not sufficient.</p>

<p>Better static and dynamic analysis tooling could help here, as well as some better help from the compiler, and alternatives to some uses of <em>unsafe</em>. I suspect that the long-term success of Rust as a systems language is going to depend on how well the community and tools handle <em>unsafe</em>. A lot of the value of Rust lies in its safety, and it's still too easy to break that safety without knowing it.</p>

<p>Another long-term risk is the size of the language. It's been over 10 years since I last worked with C++ every day, and I'm nowhere near being a competent C++ programmer anymore. Part of that is because C++ has evolved, which is a very good thing. Part of it is because C++ is <em>huge</em>. From a decade away, it seems hard to be a competent part-time C++ programmer: you need to be fully immersed, or you'll never fit the whole thing in your head. Rust could go that way too, and it would be a pity.</p></p>
<p>
<em><a href="http://brooker.co.za/blog/2020/03/22/rust.html">March 22, 2020 12:00 AM</a></em>
</p>









<hr><h3 class="post"><a href="https://www.jeremymorgan.com/tags/programming/" title="programming on Jeremy Morgan :: Tech Blog">Jeremy Morgan (JeremyMorgan)</a></h3>


<h4><a href="http://feedproxy.google.com/~r/JeremyMorganProgramming/~3/Ebx9w2RF68s/">How to Find Your Browser Developer Console</a></h4>
<p>
Debugging web applications can be tricky. Accessing your browser&rsquo;s developer console is the easiest way to &ldquo;pop the hood&rdquo; and see what&rsquo;s going on with your application. It&rsquo;s like a secret backdoor that isn&rsquo;t very secret.
Google Chrome Google&rsquo;s browser is one of the most popular out there, and it&rsquo;s easy to access the developer console:
In the upper right hand corner of the browser, click the 3 dots:
Then select More Tools -&gt; then Developer Tools</p>
<p>
<em><a href="http://feedproxy.google.com/~r/JeremyMorganProgramming/~3/Ebx9w2RF68s/">March 22, 2020 12:00 AM</a></em>
</p>





<h2>March 21, 2020</h2>




<hr><h3 class="post"><a href="https://j11g.com" title="Jan van den Berg">Jan van den Berg (j11g)</a></h3>


<h4><a href="https://j11g.com/2020/03/21/my-music-discoveries-of-2019/">My Music Discoveries of 2019</a></h4>
<p>
<p>Here are my favorite music discoveries of 2019. Earlier editions are here:&#160;2015,&#160;2016,&#160;2017&#160;and&#160;2018 (part 1) and 2018 (part 2). You know the drill. A few sentences and a YouTube video. No less than 19 videos. All songs need to be listened to. And all songs I obsessed about at one point or another in 2019. Here [&#8230;]</p>
<p>The post <a rel="nofollow" href="https://j11g.com/2020/03/21/my-music-discoveries-of-2019/">My Music Discoveries of 2019</a> appeared first on <a rel="nofollow" href="https://j11g.com">Jan van den Berg</a>.</p></p>
<p>
<em><a href="https://j11g.com/2020/03/21/my-music-discoveries-of-2019/">March 21, 2020 09:24 PM</a></em>
</p>









<hr><h3 class="post"><a href="https://amontalenti.com" title="Andrew Montalenti">Andrew Montalenti (amontalenti)</a></h3>


<h4><a href="https://amontalenti.com/2020/03/21/best-remote-work-equipment-webcams-mics-headphones">Best remote work equipment in 2020</a></h4>
<p>
If you’re working on a fully distributed team, partially remote team, or even just working from home occasionally, this is a selection of low-cost equipment you can use to get your home office setup to a “professional” level. All of this equipment has been tested extensively to work on: Google Hangouts Google Meet Zoom Video &#8230; <a href="https://amontalenti.com/2020/03/21/best-remote-work-equipment-webcams-mics-headphones" class="more-link">Continue reading <span class="screen-reader-text">Best remote work equipment in 2020</span></a></p>
<p>
<em><a href="https://amontalenti.com/2020/03/21/best-remote-work-equipment-webcams-mics-headphones">March 21, 2020 09:07 PM</a></em>
</p>









<hr><h3 class="post"><a href="https://kaushikghose.wordpress.com" title="Pages from the fire">Pages From The Fire (kghose)</a></h3>


<h4><a href="">Buffering writes</a></h4>
<p>
Many scientific computing applications consist of processing data and then writing out to disk. Often the application will be I/O bound, which means that the computation time is shorter that the time it takes to read or write data to disk. Even though modern OSes do their best to write efficiently to the hardware, there&#8230; <a class="more-link" href="https://kaushikghose.wordpress.com/2020/03/20/buffering-writes/">Read More <span class="screen-reader-text">Buffering writes</span></a></p>
<p>
<em><a href="">March 21, 2020 03:05 AM</a></em>
</p>





<h2>March 20, 2020</h2>




<hr><h3 class="post"><a href="https://www.wezm.net/v2" title="Wesley Moore">Wesley Moore (wezm)</a></h3>


<h4><a href="https://www.wezm.net/v2/posts/2020/rust-top-alternatives/">Comparing Alternatives to top Written in Rust</a></h4>
<p>
<p>Recently I aliased <code>top</code> to <a href="https://github.com/cjbassi/ytop">ytop</a>. Then I became aware of <a href="https://github.com/ClementTsang/bottom">bottom</a>, and
<a href="https://github.com/bvaisvil/zenith">zenith</a>. These are all terminal based system monitoring tools that you might
use instead of <code>top</code>. In this post I set out to compare them.</p>

  <a href="https://www.wezm.net/v2/&#x2F;&#x2F;www.wezm.net&#x2F;v2/posts&#x2F;2020&#x2F;rust-top-alternatives&#x2F;ytop-btm-zenith-screenshot.png"><img src="https://www.wezm.net/v2/&#x2F;&#x2F;www.wezm.net&#x2F;v2/posts&#x2F;2020&#x2F;rust-top-alternatives&#x2F;ytop-btm-zenith-screenshot.png" alt="Screenshot of ytop, bottom, and zenith while building some Rust code" /></a>
  Left to right: ytop, bottom, and zenith.

<span id="continue-reading"></span>
  <div class="emoji text-center">💡</div>
  <strong>Why Rust?</strong>
  <p>The Rust programming language helps people write efficient, reliable software.
I like the language and the tools people are
building with it.</p>
<p>If you're interested in more Rust CLI tools check out my
post: <a href="https://www.wezm.net/technical/2019/10/useful-command-line-tools/">An Illustrated Guide to Some Useful Command Line
Tools</a>.</p>

<p>As the title states all three tools are written in Rust. They show similar
information and are all open source under the MIT license. I tested each one
on: Arch Linux, FreeBSD 12.1, macOS Mojave, and Windows 10. At the time of
testing, all three failed to build on FreeBSD and Windows. Figures below are
from the Arch Linux system, which is a <a href="https://bitcannon.net/page/ryzen9-pc/">12 core AMD Ryzen desktop PC</a>.</p>
<p><code>ytop</code> and <code>bottom</code> use a layout that appears to be inspired by <a href="https://github.com/cjbassi/gotop">gotop</a>. In
fact, <code>ytop</code> is written by the same person as <code>gotop</code>. <code>zenith</code> uses a layout
that's a bit more like traditional <code>top</code> with histograms above the process
list.</p>
<p>I typically use <code>top</code> to:</p>
<ul>
<li>Check on overall system load and free memory.</li>
<li>Find specific processes that are using a lot of CPU or memory.</li>
<li>Observe CPU and memory use over time.</li>
<li>Occasionally kill processes.</li>
</ul>
<p>I find the <code>zenith</code> layout more information dense, with less space taken up
with graphs. I also like the header row with info and help. The main feature
that it is missing compared to the others is temperatures — but that's in the
list of planned features. <del>There is one issue with <code>zenith</code>: it doesn't show my
ZFS pool. My system has an NVMe system disk and a ZFS pool of 3 SSDs that is
mounted as <code>/home</code>, which is absent in the disk summary. I've raised <a href="https://github.com/bvaisvil/zenith/issues/9">an issue
on GitHub</a>.</del></p>
<p><strong>Update 27 March 2020:</strong> Zenith 0.7.7 now shows ZFS pools.</p>
<p>The individual lines for each CPU in <code>bottom</code> makes the display quite noisy. I
prefer the aggregated line that <code>ytop</code> shows. <code>ytop</code> has a handy <code>-m</code> option
to only show CPU, memory, and process list.</p>
<p>So, after reviewing them all I'm going to start using <code>zenith</code>. It might not
be quite as pretty in screenshots but it's the best for doing this things
I want to do with a <code>top</code> like tool.</p>
<p>Read on for further information about each tool, including an additional
honorable mention, <a href="https://github.com/epilys/bb">bb</a>.</p>
<h3 id="bottom">bottom</h3>
<p><img src="https://www.wezm.net/v2/posts/2020/rust-top-alternatives/bottom.png" alt="Screnshot of bottom" /></p>
<p><a href="https://github.com/ClementTsang/bottom">Repository</a></p>
<p><strong>Version tested:</strong> 0.2.2<br />
<strong>Runtime dependencies:</strong> None<br />
<strong>Lines of code:</strong> 4894<br />
<strong>Cargo dependencies:</strong> 109<br />
<strong>Stripped binary size:</strong> 3.4MiB</p>
<p><code>bottom</code> has <code>vi</code> style key bindings for navigating the process list. The
selection is not stable across updates but there is a key binding, <code>f</code> to
freeze the display that allows you navigate the list without it changing. It
supports killing processes with <code>dd</code> but does not prompt for the signal to
send. It shows a confirmation before killing the process.</p>
<p><strong>Usage:</strong></p>
<pre>
bottom 0.2.2
Clement Tsang &lt;cjhtsang@uwaterloo.ca&gt;
A cross-platform graphical process/system monitor with a customizable interface and a multitude of features. Supports
Linux, macOS, and Windows.

USAGE:
    btm [FLAGS] [OPTIONS]

FLAGS:
    -a, --avg_cpu                Enables showing the average CPU usage.
    -S, --case_sensitive         Match case when searching by default.
    -c, --celsius                Sets the temperature type to Celsius.  This is the default option.
        --cpu_default            Selects the CPU widget to be selected by default.
        --disk_default           Selects the disk widget to be selected by default.
    -m, --dot_marker             Use a dot marker instead of the default braille marker.
    -f, --fahrenheit             Sets the temperature type to Fahrenheit.
    -g, --group                  Groups processes with the same name together on launch.
    -k, --kelvin                 Sets the temperature type to Kelvin.
    -l, --left_legend            Puts external chart legends on the left side rather than the default right side.
        --memory_default         Selects the memory widget to be selected by default.
        --network_default        Selects the network widget to be selected by default.
        --process_default        Selects the process widget to be selected by default.  This is the default if nothing
                                 is set.
    -R, --regex                  Use regex in searching by default.
    -s, --show_disabled_data     Show disabled data entries.
        --temperature_default    Selects the temp widget to be selected by default.
    -u, --current_usage          Within Linux, sets a process' CPU usage to be based on the total current CPU usage,
                                 rather than assuming 100% usage.
    -W, --whole_word             Match whole word when searching by default.
    -h, --help                   Prints help information
    -V, --version                Prints version information

OPTIONS:
    -C, --config &lt;CONFIG_LOCATION&gt;    Sets the location of the config file.  Expects a config file in the TOML format.
    -r, --rate &lt;RATE_MILLIS&gt;          Sets a refresh rate in milliseconds; the minimum is 250ms, defaults to 1000ms.
                                      Smaller values may take more resources.
</pre><h3 id="ytop">ytop</h3>
<p><img src="https://www.wezm.net/v2/posts/2020/rust-top-alternatives/ytop.png" alt="Screnshot of ytop" /></p>
<p><a href="https://github.com/cjbassi/ytop">Repository</a></p>
<p><strong>Version tested:</strong> 0.5.1<br />
<strong>Runtime dependencies:</strong> None<br />
<strong>Lines of code:</strong> 1903<br />
<strong>Cargo dependencies:</strong> 89<br />
<strong>Stripped binary size:</strong> 2.1MiB</p>
<p><code>ytop</code> has <code>vi</code> style key bindings for navigating the process list. The
selection remains on the same process across updates. It supports killing
processes with <code>dd</code> but does not prompt for the signal to send. There is
no confirmation when typing <code>dd</code>.</p>
<p><strong>Usage:</strong></p>
<pre>
ytop 0.5.1

USAGE:
    ytop [FLAGS] [OPTIONS]

FLAGS:
    -a, --average-cpu    Show average CPU in the CPU widget
    -b, --battery        Show Battery widget (overridden by 'minimal' flag)
    -f, --fahrenheit     Show temperatures in fahrenheit
    -h, --help           Prints help information
    -m, --minimal        Only show the CPU, Mem, and Process widgets
    -p, --per-cpu        Show each CPU in the CPU widget
    -s, --statusbar      Show a statusbar with the time
    -V, --version        Prints version information

OPTIONS:
    -c, --colorscheme &lt;colorscheme&gt;    Set a colorscheme [default: default]
    -i, --interface &lt;interface&gt;        The name of the network interface to show in the Net widget. 'all' shows all
                                       interfaces [default: all]
    -I, --interval &lt;interval&gt;          Interval in seconds between updates of the CPU and Mem widgets. Can specify
                                       either a whole number or a fraction with a numerator of 1 [default: 1]
</pre><h3 id="zenith">zenith</h3>
<p><img src="https://www.wezm.net/v2/posts/2020/rust-top-alternatives/zenith.png" alt="Screnshot of zenith" /></p>
<p><a href="https://github.com/bvaisvil/zenith">Repository</a></p>
<p><strong>Version tested:</strong> 0.7.5<br />
<strong>Runtime dependencies:</strong> None<br />
<strong>Lines of code:</strong> 2006<br />
<strong>Cargo dependencies:</strong> 105<br />
<strong>Stripped binary size:</strong> 2.6MiB</p>
<p><code>zenith</code> has a small number of key bindings for changing the panes. You can
navigate the process list with the arrow keys. The selection is not stable
across updates but the default update frequency is 2 seconds. Pressing Enter on
process shows expanded information about it and allows you to send it various
signals:</p>
<p><img src="https://www.wezm.net/v2/posts/2020/rust-top-alternatives/zenith-process.png" alt="zenith process view" /></p>
<p><strong>Usage:</strong></p>
<pre>
zenith 0.7.5
Benjamin Vaisvil &lt;ben@neuon.com&gt;
Zenith, sort of like top but with histograms.
Up/down arrow keys move around the process table. Return (enter) will focus on a process.
Tab switches the active section. Active sections can be expanded (e) and minimized (m).
Using this you can create the layout you want.

USAGE:
    zenith [FLAGS] [OPTIONS]

FLAGS:
        --disable-history    Disables history when flag is present
    -h, --help               Prints help information
    -V, --version            Prints version information

OPTIONS:
    -c, --cpu-height &lt;INT&gt;        Height of CPU/Memory visualization. [default: 10]
        --db &lt;STRING&gt;             Database to use, if any. [default: /home/wmoore/.zenith]
    -d, --disk-height &lt;INT&gt;       Height of Disk visualization. [default: 10]
    -n, --net-height &lt;INT&gt;        Height of Network visualization. [default: 10]
    -p, --process-height &lt;INT&gt;    Min Height of Process Table. [default: 8]
    -r, --refresh-rate &lt;INT&gt;      Refresh rate in milliseconds. [default: 2000]
</pre><h3 id="bb">bb</h3>
<p><img src="https://www.wezm.net/v2/posts/2020/rust-top-alternatives/bb.png" alt="Screnshot of bb" /></p>
<p><a href="https://github.com/epilys/bb">Repository</a></p>
<p><strong>Version tested:</strong> git 35c3017<br />
<strong>Runtime dependencies:</strong> None<br />
<strong>Lines of code:</strong> 8450<br />
<strong>Cargo dependencies:</strong> 27<br />
<strong>Stripped binary size:</strong> 534KiB</p>
<p><code>bb</code> is closer to regular <code>top</code> than the other tools. It shows a CPU histograms
and a process list.  It has the best process view though, allowing sending all
named signals, filtering the list by name or pid, toggleable tree view and
following a process group. It also has the fewest crate dependencies and
smallest binary. The drawback is the author describes it as, &quot;a &quot;weekend&quot;
side-project made for fun&quot;, and it hasn't seen any updates since Nov 2019.</p>
<p><strong>Usage:</strong></p>
<p><code>bb</code> does not have any command line arguments.</p>
<h3 id="test-notes">Test Notes</h3>
<p>The dependency count was calculated using <a href="https://github.com/sfackler/cargo-tree">cargo-tree</a> as follows:</p>
<pre>
cargo tree --no-dev-dependencies --no-indent -q | sed 's/ (\*)$//' | sort -u | wc -l
</pre>
<p>The lines of code values were calculated using <a href="https://github.com/XAMPPRocky/tokei">tokei</a>. The value of the Code
column in the Total row from the output of <code>tokei src</code> was used. E.g. 2372 in
the output below:</p>
<pre>
-------------------------------------------------------------------------------
 Language            Files        Lines         Code     Comments       Blanks
-------------------------------------------------------------------------------
 JSON                    5          105          105            0            0
 Markdown                2          231          231            0            0
 Rust                   18         2404         2001           87          316
 TOML                    2           39           35            2            2
-------------------------------------------------------------------------------
 Total                  27         2779         2372           89          318
-------------------------------------------------------------------------------
</pre></p>
<p>
<em><a href="https://www.wezm.net/v2/posts/2020/rust-top-alternatives/">March 20, 2020 11:45 PM</a></em>
</p>









<hr><h3 class="post"><a href="https://amontalenti.com" title="Andrew Montalenti">Andrew Montalenti (amontalenti)</a></h3>


<h4><a href="https://amontalenti.com/2020/03/20/30min-chats">Chat with me for 30 minutes about distributed team management</a></h4>
<p>
Have you been trying to figure out this new world order with regard to work-from-home (WFH), remote work, distributed teams, and the like? I&#8217;ve opened up my calendar for 30-minute chats. You can schedule them with me here: https://calendly.com/amontalenti/distributed If you want to read up on distributed teams, here are some past posts from my &#8230; <a href="https://amontalenti.com/2020/03/20/30min-chats" class="more-link">Continue reading <span class="screen-reader-text">Chat with me for 30 minutes about distributed team management</span></a></p>
<p>
<em><a href="https://amontalenti.com/2020/03/20/30min-chats">March 20, 2020 10:32 PM</a></em>
</p>





<h2>March 16, 2020</h2>




<hr><h3 class="post"><a href="https://j11g.com" title="Jan van den Berg">Jan van den Berg (j11g)</a></h3>


<h4><a href="https://j11g.com/2020/03/16/corona-links/">Corona Links</a></h4>
<p>
<p>This is a collection of COVID-19 related information links. Stats Worldwide map, with counts https://experience.arcgis.com/experience/685d0ace521648f8a5beeeee1b9125cd Worldwide stats with specific recovery stats https://www.worldometers.info/coronavirus/ Worldwide charts and figures split out per country https://covid19info.live/ Different dashboards updated hourly http://covid19dashboards.com/ Direct link to the Dutch RIVM URL with national stats https://www.rivm.nl/nieuws/actuele-informatie-over-coronavirus Background A collaborative guide to COVID-19 care https://covid-at-home.info/ [&#8230;]</p>
<p>The post <a rel="nofollow" href="https://j11g.com/2020/03/16/corona-links/">Corona Links</a> appeared first on <a rel="nofollow" href="https://j11g.com">Jan van den Berg</a>.</p></p>
<p>
<em><a href="https://j11g.com/2020/03/16/corona-links/">March 16, 2020 07:11 AM</a></em>
</p>









<hr><h3 class="post"><a href="http://www.petecorey.com/" title="Pete Corey">Pete Corey (petecorey)</a></h3>


<h4><a href="http://www.petecorey.com/blog/2020/03/16/lissajous-curves/">Lissajous Curves</a></h4>
<p>
A YouTube mathematician drew me into the beautiful rabbit hole of Lissajous curves. To satisfy my curiosity, I wrote a quick React application that renders a grid of Lissajous curves to an HTML5 canvas.</p>
<p>
<em><a href="http://www.petecorey.com/blog/2020/03/16/lissajous-curves/">March 16, 2020 12:00 AM</a></em>
</p>





<h2>March 15, 2020</h2>




<hr><h3 class="post"><a href="https://www.jeremymorgan.com/tags/programming/" title="programming on Jeremy Morgan :: Tech Blog">Jeremy Morgan (JeremyMorgan)</a></h3>


<h4><a href="http://feedproxy.google.com/~r/JeremyMorganProgramming/~3/MCXP2GSmQzI/">Donate Your Unused CPU Cycles to Fight Coronavirus</a></h4>
<p>
The Folding at Home research project uses crowd sourced CPU power to help model simulations to develop treatments for diseases. You can help them by taking 5 minutes to download their client, and donate some CPU Cycles.
For more info:
After initial quality control and limited testing phases, Folding@home team has released an initial wave of projects simulating potentially druggable protein targets from SARS-CoV-2 (the virus that causes COVID-19) and the related SARS-CoV virus (for which more structural data is available) into full production on Folding@home.</p>
<p>
<em><a href="http://feedproxy.google.com/~r/JeremyMorganProgramming/~3/MCXP2GSmQzI/">March 15, 2020 10:45 PM</a></em>
</p>









<hr><h3 class="post"><a href="http://shape-of-code.coding-guidelines.com" title="The Shape of Code">Derek Jones (derek-jones)</a></h3>


<h4><a href="http://shape-of-code.coding-guidelines.com/2020/03/15/exercises-in-programming-style-the-python-way/">Exercises in Programming Style: the python way</a></h4>
<p>
Exercises in Programming Style by Cristina Lopes is an interesting little book. The books I have previously read on programming style pick a language, and then write various programs in that language using different styles, idioms, or just following quirky rules, e.g., no explicit loops, must use sets, etc. &#8220;Algorithms in Snobol 4&#8221; by James [&#8230;]</p>
<p>
<em><a href="http://shape-of-code.coding-guidelines.com/2020/03/15/exercises-in-programming-style-the-python-way/">March 15, 2020 10:37 PM</a></em>
</p>









<hr><h3 class="post"><a href="https://www.jeffcarp.com/" title="jeffcarp">Jeff Carpenter (jeffcarp)</a></h3>


<h4><a href="https://www.jeffcarp.com/posts/2020/most-common-chinese-words-on-weibo/">The Most Commonly Used Chinese Words</a></h4>
<p>
I think the most effective way to learn a language is to prioritize learning the day-to-day most frequently used words. Picking words to study in order of frequency is the optimal way to maximally increase your marginal understanding of the language for each successive word you learn.
To that end, I took a dataset of Weibo (China&rsquo;s Twitter) posts and ranked all words that appeared in the dataset order of frequency.</p>
<p>
<em><a href="https://www.jeffcarp.com/posts/2020/most-common-chinese-words-on-weibo/">March 15, 2020 10:23 PM</a></em>
</p>









<hr><h3 class="post"><a href="https://www.gkbrk.com/" title="Gokberk Yaltirakli">Gokberk Yaltirakli (gkbrk)</a></h3>


<h4><a href="https://www.gkbrk.com/2020/03/encryption/">Rolling your own encryption</a></h4>
<p>
Encryption is tricky to get right. Because some data and communications might be very sensitive or even life-critical for people, beginners are often - and quite rudely- shunned away from playing around with how it works. But if people don’t learn by making bad ciphers, they will have difficulty understanding why the good ones are good.</p>
<p>
<em><a href="https://www.gkbrk.com/2020/03/encryption/">March 15, 2020 12:00 AM</a></em>
</p>





<h2>March 14, 2020</h2>




<hr><h3 class="post"><a href="http://stsievert.com/" title="Scott Sievert">Scott Sievert (stsievert)</a></h3>


<h4><a href="http://stsievert.com/blog/2020/03/14/covid-19/">Visualization of the COVID-19 infection rates</a></h4>
<p>
<p>The Wuhan virus/COVID-19 is spreading through the world. The WHO classifies it
as a pandemic (<a href="https://www.who.int/dg/speeches/detail/who-director-general-s-opening-remarks-at-the-media-briefing-on-covid-19---11-march-2020">source</a>), and the United States has declared a
national emergency because of it (<a href="https://en.wikipedia.org/wiki/List_of_national_emergencies_in_the_United_States">source</a>).</p>

<p>Data on the infection rate is difficult to find. This post will present some
data sources and show some visualizations of the infections. It’ll also
provide some tips on how to avoid coronavirus.</p>

<p><em>This post will be updated frequently (hopefully daily).</em></p>

<!--More-->

<p>First, let’s visualize the fraction of people that are infected in each
country. Where are different countries in the coronavirus infection
cycle?<sup id="fnref:data"><a href="https://stsievert.com/atom.xml#fn:data" class="footnote">1</a></sup></p>

<p><img src="https://stsievert.com/assets/2020-covid-19/imgs/coronavirus.svg" width="100%" class="center" /></p>

<p><em>This is frightening on 2020-03-14</em>.<sup id="fnref:share"><a href="https://stsievert.com/atom.xml#fn:share" class="footnote">2</a></sup> Not for me – I’d probably be
asymptomatic if I contracted COVID-19 because I’m young and healthy. My primary
concern is with the load on the US health care system. Case in point: what
happens when grocery stores or FedEx distribution centers can’t be staffed
because workers refuse to work because they’re fearful of getting sick? Food
insecurity and supply chain/economic collapse.</p>

<p>It looks the health care system will be overrun on in early April on
2020-03-14.  Hopefully the infection rate slows before that can
happen.<sup id="fnref:success"><a href="https://stsievert.com/atom.xml#fn:success" class="footnote">3</a></sup> How can we aid the infection
slowing down?</p>

<h2 id="slowing-the-rate-of-infection">Slowing the rate of infection</h2>

<p>Right now (2020-03-14) it seems that the only hope is social distancing. I
think the timeline for a vaccine is too long (<a href="https://www.sciencealert.com/who-says-a-coronavirus-vaccine-is-18-months-away">around 18
months</a>), and cures/therapeutic drugs aren’t here yet (though
<a href="https://www.nbcnews.com/health/health-news/here-are-some-existing-drugs-may-be-repurposed-treat-coronavirus-n1162021">they’re coming</a>). Here are some resources to help with social distancing:</p>

<ul>
  <li><a href="http://www.cidrap.umn.edu/sites/default/files/public/php/185/185_factsheet_social_distancing.pdf">CDC fact sheet on social distancing</a></li>
  <li>Forbes “<a href="https://www.forbes.com/sites/brucelee/2020/03/14/with-covid-19-coronavirus-here-are-10-ways-to-social-distance-yourself/">What Is Social Distancing? Here Are 10 Ways To Keep The Coronavirus
Away</a>”</li>
</ul>

<p>In short, avoid social contact as much as possible. The biggest tips are to
work from home and avoid large crowds. Social distancing is why so many
<a href="https://www.espn.com/olympics/story/_/id/28824781/list-sporting-events-canceled-coronavirus">sporting events have been canceled</a> and so many <a href="https://www.msn.com/en-us/news/us/universities-across-the-us-are-canceling-in-person-classes-due-to-coronavirus/ar-BB1105xZ">universities are
canceling class</a>.</p>

<p>The positive effect of immediate and extreme social distancing is best
illustrated with the 1918 flu epidemic/the Spanish flu. The hardest hit city
was Philadelphia. The infection hit the city very suddenly, meaning the health
care system was quickly saturated and overrun. One effect of this: they had to
stack bodies on the sidewalk because the morgues were overflowing
(<a href="https://www.stltoday.com/news/local/metro/st-louis-saw-the-deadly-spanish-flu-epidemic-coming-shutting/article_52e5e46d-1f30-5f31-a706-786785692bb5.html">source</a>).</p>

<p>However, St. Louis practiced immediate and extreme social distancing when the
flu hit the city. Just 2 days after the flu hit the civilian population, Dr.
Max Starkloff quickly ordered the closer of schools, movie theaters, sporting
events and public gatherings.<sup id="fnref:1918img"><a href="https://stsievert.com/atom.xml#fn:1918img" class="footnote">4</a></sup></p>

<p>This meant the flu spread much more slowly throughout St. Louis than
Philadelphia. Here’s a graph of the death rate for the two cities<sup id="fnref:1918img:1"><a href="https://stsievert.com/atom.xml#fn:1918img" class="footnote">4</a></sup></p>

<p><img src="https://stsievert.com/assets/2020-covid-19/static-imgs/st-louis.svg" width="100%" class="center" /></p>

<p><em>Functionally, the time taken to start social distancing is the only difference
between these two curves.</em> St. Louis responded about 14 days quicker than
Philadelphia. That meant St. Louis had half the total death rate of
Philadelphia, and they didn’t have to pile bodies on the streets because their
morgues were too full.</p>

<p>The difference between these two cities is discussed more in these two
articles:</p>

<ul>
  <li>“<a href="https://www.stltoday.com/news/local/metro/st-louis-saw-the-deadly-spanish-flu-epidemic-coming-shutting/article_52e5e46d-1f30-5f31-a706-786785692bb5.html">St. Louis saw the deadly 1918 Spanish flu epidemic coming.  Shutting down
the city saved countless lives</a>”.</li>
  <li>“<a href="https://qz.com/1816060/a-chart-of-the-1918-spanish-flu-shows-why-social-distancing-works/">This chart of the 1918 Spanish flu shows why social distancing works</a>”
(published on March 11th).</li>
</ul>

<h2 id="how-fast-is-the-virus-spreading">How fast is the virus spreading?</h2>

<p>The direct visualization of this is with the number of new cases each day:</p>

<p><img src="https://stsievert.com/assets/2020-covid-19/imgs/new-cases.svg" width="80%" class="center" /></p>

<p>This perhaps isn’t the best visualization; it’s pretty noisy, and there’s no
information about the retired population or the quality/size of the health care
system. Here’s a different visualization:</p>

<p><img src="https://stsievert.com/assets/2020-covid-19/imgs/rate.svg" width="90%" class="center" /></p>

<p>It appears the number of confirmed cases is doubling every 2.4 days before the
infection gets under control<sup id="fnref:china"><a href="https://stsievert.com/atom.xml#fn:china" class="footnote">5</a></sup> (as with South Korea and Italy).  Details
on the back-of-the-envelope calculation are in <a href="https://stsievert.com/atom.xml#appendix">the appendix</a>;
briefly, I take the number of cases required to Italy’s health care system and
scale by the population that’s 65 years or older and number of hospital beds.</p>

<p>This looks to be rather scary for the U.K. The Prime Minister Boris Johnson has
largely kept the UK open.  Schools and universities have been kept open far too
long, and many businesses and citizens didn’t take coronavirus seriously
(<a href="https://www.independent.co.uk/news/health/coronavirus-herd-immunity-uk-nhs-outbreak-pandemic-government-a9399101.html">source</a>).
For example, on March 12th the government said it didn’t want to “disrupt daily
life before it was absolutely necessary”.<sup id="fnref:uk-mar"><a href="https://stsievert.com/atom.xml#fn:uk-mar" class="footnote">6</a></sup> It looks like the UK will
have more deaths and a higher economic cost.<sup id="fnref:uk-est"><a href="https://stsievert.com/atom.xml#fn:uk-est" class="footnote">7</a></sup></p>

<h3 id="how-fast-is-the-virus-spreading-in-the-us">How fast is the virus spreading in the US?</h3>

<p>How many infections does the US have? When will the number of people who need
hospitalization overwhelm the number of hospital beds?</p>

<p><img src="https://stsievert.com/assets/2020-covid-19/imgs/us.svg" width="80%" class="center" /></p>

<p>If social distancing does not work and no medicine is developed, it looks like
this virus will overwhelm the health care system sometime in late March.</p>

<p>How fast is the US spreading in each state?</p>

<p><img src="https://stsievert.com/assets/2020-covid-19/imgs/us-states-hist.svg" width="90%" class="center" /></p>

<p>In most states, it appears the number of confirmed coronavirus cases is
growing more slowly on 2020-03-31!</p>

<p>These tests are confounded by testing. On 2020-03-22, it looks like New York is
rapidly expanding testing, or the virus is spreading faster. I believe they’re
expanding testing – they recently opened a drive-thru testing facility
(<a href="https://www.ny1.com/nyc/all-boroughs/news/2020/03/19/first-nyc-drive-thru-coronavirus-testing-facility-opens-on-staten-island">source</a>), and NY has about 8× the number of cases as WA but
only 1.2× the number of deaths (on 2020-03-22).</p>

<p>I interpret the increase in testing to be finding cases earlier in the
infection cycle and/or discovering the infection in unconcerned populations
(e.g., college students), especially because I doubt the virus can spread
faster than doubling once every 2.4 days. The increased testing is likely
masking the effect I’m concerned about, the load on the health care system.</p>

<p>It appears New York City is a hotspot, and confounded by testing. Regardless if
that’s the case, let’s generate the same plot but without the data from New
York<sup id="fnref:scaling"><a href="https://stsievert.com/atom.xml#fn:scaling" class="footnote">8</a></sup>:</p>

<p><img src="https://stsievert.com/assets/2020-covid-19/imgs/us-wo-ny.svg" width="80%" class="center" /></p>

<p>It looks like the infections in the US are starting to slow down, presuming
that NY is doing more testing. If true, that’s <em>great</em> news! A couple points:</p>

<ul>
  <li><em>Social distancing is working!</em> The effect we’re seeing is probably from
5–10 days previous, so March 11th–16th on 2020-03-21. That’s right when the
US started social distancing.</li>
  <li>If it continues, social distancing has bought the US <em>at least</em> 4 days,
probably 5 before the health care system saturates. That’s 4× fewer total
cases!</li>
</ul>

<h3 id="how-serious-are-people-about-social-distancing">How serious are people about social distancing?</h3>

<p>Let’s study a weak proxy for this question, the number of restaurant
reservations bookings through OpenTable:</p>

<p><img src="https://stsievert.com/assets/2020-covid-19/imgs/opentable.svg" width="70%" class="center" />
<img src="https://stsievert.com/assets/2020-covid-19/imgs/opentable-cities.svg" width="70%" class="center" /></p>

<p>Here’s a visualization of the subway usage in New York City:</p>

<p><img src="https://stsievert.com/assets/2020-covid-19/imgs/nyc-subway-rides.svg" width="60%" class="center" /></p>

<p>For an interactive version of this graph, visit the <a href="https://toddwschneider.com/dashboards/nyc-subway-turnstiles/">New York City Subway Usage
Dashboard</a> by <a href="https://toddwschneider.com/">Todd Schneider</a>.</p>

<p>The result of this: it looks like the virus is decreasing rapidly!  Kinsa
Health makes smart thermometers, and they’ve done some analysis to see the
level of total infection in the US (not just COVID-19). For a better
description, see “<a href="https://www.nytimes.com/2020/03/18/health/coronavirus-fever-thermometers.html">Can Smart Thermometers Track the Spread of the
Coronavirus?</a>”.</p>

<p><a href="https://healthweather.us/">Kinsa’s fever dashboard</a> looks promising:</p>

<p><img src="https://stsievert.com/assets/2020-covid-19/static-imgs/kinsa-us.png" width="80%" class="center" />
<img src="https://stsievert.com/assets/2020-covid-19/static-imgs/kinsa-ny.png" width="80%" class="center" /></p>

<h2 id="further-reading">Further reading</h2>

<p>This blog post is written as a projection for the very initial stages of the
pandemic. The visualizations are geared towards the question “can the US health
care system handle COVID-19?” The following links give some more information on
other aspects, including questions like “how quickly will the pandemic be
over?” and “how many people will the Wuhan virus infect?”</p>

<ul>
  <li>“<a href="https://medium.com/@ali_razavian/covid-19-from-a-data-scientists-perspective-95bd4e84843b">COVID-19 from a data scientists perspective</a>.” This
post looks at Iceland (which did some pretty heavy testing) and extrapolates
to the entire world. Main conclusions: the Wuhan virus will infect 96% of the
world and have a 0.06% mortality rate.</li>
  <li>“<a href="https://aatishb.com/covidtrends/?location=Australia&location=Germany&location=Iceland&location=Italy&location=South+Korea&location=US&location=United+Kingdom">COVID Trends Dashboard</a>.” This shows some metrics on how fast
the virus is spreading, specifically the total number of cases/deaths versus
the cases/deaths in the last week.</li>
</ul>

<h2 id="appendix">Appendix</h2>

<h3 id="uks-approach">U.K.’s approach</h3>
<p>On March 12th, the U.K. goverment said that their approach…</p>

<blockquote>
  <p>include[d] asking people with even [a] very mild cough and flu symptoms to
stay home, but stopped short of the measures seen in most other European
countries and increasingly in North America, including closing schools and
colleges.</p>

  <p>The government said Thursday [March 12th] that it may have to impose these
more stringent measures at some point in the future, but that doing so now
would be premature, disrupting daily life before it was absolutely necessary,
and risking the public would grow tired of complying with the restrictions
and begin to ignore them just when the peak number of infections might be
expected ….</p>

  <p>—”<a href="https://fortune.com/2020/03/14/coronavirus-uk-cases-herd-immunity-covid-19/">Even while canceling mass gatherings, the U.K. is still aiming for
deliberate ‘herd immunity’</a>”. Fortune, March 14th.</p>
</blockquote>

<p>They waited 6 days until March 18th before they “disrupted daily life”. It
looks like they waited too long – 6 days means 5.6× more cases because the
infection doubles every 2.4 days. That’d be bad even if they had a quality
health care system; however, I estimate the U.K.’s health care system can
handle 5× fewer patients than the US health care system.</p>

<h3 id="graphs">Graphs</h3>

<p>My visualizations are geared towards to the US because I live there. If you’d
like to customize these plots, visit the repository at <a href="https://github.com/stsievert/covid-19">stsievert/covid-19</a>.</p>

<p>If you’re interested, I’ve published <a href="https://stsievert.com/assets/2020-covid-19/imgs/">a page with all the images</a> in this post
without any text.</p>

<h4 id="data-sources">Data sources</h4>

<p>Visit the <a href="https://github.com/stsievert/covid-19">stsievert/covid-19</a> for all the data sources. Briefly, some of my
main data sources include the following:</p>

<ul>
  <li><a href="https://www.worldometers.info/coronavirus/">Worldometers</a> for country level infections</li>
  <li><a href="https://github.com/nytimes/covid-19-data">nytimes/covid-19-data</a> for state level infections</li>
  <li><a href="https://www.opentable.com/state-of-industry">OpenTable’s dataset</a> for restaurant reservations</li>
  <li>The MTA’s <a href="http://web.mta.info/developers/turnstile.html">public turnstile data</a> for their data on NYC subway rides through <a href="https://toddwschneider.com/">Todd Schneider</a>’s
wonderful <a href="https://toddwschneider.com/dashboards/nyc-subway-turnstiles/">New York City Subway Usage Dashboard</a></li>
  <li>Wikipedia for misc. stats (populations, hospital beds, etc)</li>
</ul>

<p>For full detail, please the repository at <a href="https://github.com/stsievert/covid-19">stsievert/covid-19</a>.</p>

<div class="footnotes">
  <ol>
    <li id="fn:data">
      <p>The very useful data sources are mentioned in <a href="https://stsievert.com/atom.xml#data-sources">the appendix</a>. <a href="https://stsievert.com/atom.xml#fnref:data" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:share">
      <p>It’s been frightening since I first started plotting it on March 9th. <a href="https://stsievert.com/atom.xml#fnref:share" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:success">
      <p><em>(edit)</em> It looks like it started slowing down around late March!
       Sometime between 2020-03-25 and 2020-03-29. <a href="https://stsievert.com/atom.xml#fnref:success" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:1918img">
      <p>“<a href="https://www.pnas.org/content/pnas/104/18/7582.full.pdf">Public health interventions and epidemic intensity during the 1918 influenza pandemic</a>” by Richard J.
       Hatchett, Carter E. Mecher, and Marc Lipsitch. 2007.
       <a href="https://doi.org/10.1073/pnas.0610941104">https://doi.org/10.1073/pnas.0610941104</a> (the chart I show is
       a modification of fig. 1). <a href="https://stsievert.com/atom.xml#fnref:1918img" class="reversefootnote">&#8617;</a> <a href="https://stsievert.com/atom.xml#fnref:1918img:1" class="reversefootnote">&#8617;<sup>2</sup></a></p>
    </li>
    <li id="fn:china">
      <p>China first reported the virus doubled every 6.2 days
     (<a href="https://www.ccn.com/dramatic-hong-kong-data-predicts-coronavirus-outbreak-infecting-150000-every-day/">source</a>). Either China is lying or the virus becoming more virulent as it ages. <a href="https://stsievert.com/atom.xml#fnref:china" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:uk-mar">
      <p>From <a href="https://fortune.com/2020/03/14/coronavirus-uk-cases-herd-immunity-covid-19/">an article published March 14th in Fortune</a>. More
      context for the quote is shown in <a href="https://stsievert.com/atom.xml#appendix">the appendix</a> <a href="https://stsievert.com/atom.xml#fnref:uk-mar" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:uk-est">
      <p>I can’t estimate the amount (on 2020-03-21). <a href="https://stsievert.com/atom.xml#fnref:uk-est" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:scaling">
      <p>And (naively) scaling the beds/ventilators. <a href="https://stsievert.com/atom.xml#fnref:scaling" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div></p>
<p>
<em><a href="http://stsievert.com/blog/2020/03/14/covid-19/">March 14, 2020 05:00 AM</a></em>
</p>









<hr><h3 class="post"><a href="https://sulami.github.io" title="sulami's blog">Robin Schroer (sulami)</a></h3>


<h4><a href="https://sulami.github.io/posts/how-to-read-a-book/index.html">How to Read a Book</a></h4>
<p>
<p>A while ago I read <em><a href="https://www.goodreads.com/book/show/567610.How_to_Read_a_Book">How to Read a Book</a></em>, the guide to extracting information from non-fiction books first published in 1940. Like many older books, there are parts of it that haven’t aged well, and in a particularly ironic fashion the book is quite verbose. I thought it might be useful to compile a short and simple step-by-step guide to efficiently reading non-fiction.</p>
<p>Imagine a book as an object with two dimensions: scope and detail. If you read the entire book cover to cover, you will learn about the full scope covered, in the level of detail of the book.<span><label for="sn-1" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-1" class="margin-toggle" /><span class="sidenote">Well, not really. Performing a single, cover to cover reading usually does not suffice to extract everything from a book.<br />
<br />
</span></span> But many books are several hundred pages long, and active reading demands attention and energy.</p>
<p>You can compromise on either of those dimensions (or both). If you just read the first half of the book, you are compromising on scope, as there is a whole second half of the subject you did not cover at all. If instead you want to compromise on detail, you should read “outside-in”, starting with strategic skimming and delving in deeper afterwards.</p>
<p>Start by getting a vague idea of everything covered in the book, going more and more into detail at each step. At any step you can stop and decide if the next level of details is worth the additional time required, but the knowledge you have extracted at that point is likely more useful than if you had compromised on scope.</p>
<p>The outside-in method is also useful for picking out books to read at a bookstore, as you can just start with the first few steps right there, and buy the book if you want to continue.</p>
<p>Simply follow these steps below, as long as you feel like gaining deeper understanding is worth the additional time. Ideally you want to have a way of taking notes, both to capture sections or topics to investigate further, but also to aid active reading.<span><label for="sn-2" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-2" class="margin-toggle" /><span class="sidenote">Active reading is one of these barely defined terms, but what I’m trying to express is the notion of thinking about the text as you read it, and actively trying to take in information. I might publish a piece on note-taking in the future.<br />
<br />
</span></span></p>
<ol>
<li>Read the back cover, and any other summaries and publisher blurbs.</li>
<li>Read the table of contents, note the scope and structure. Identify the important and pivotal chapters.</li>
<li>Read the preface.</li>
<li>Scan the index and references for anything interesting to look at, both inside and outside this book.</li>
<li>Read the opening and closing parts of the pivotal chapters, usually about a page each.</li>
<li>Read the final part of the book containing content, such as a conclusion chapter or section.</li>
<li>Pick a handful of random sections throughout the whole book and read a page or two each.</li>
</ol>
<p>At this point you should have spent between 30 minutes and one hour, and have answers to these questions:</p>
<ul>
<li>What is the book about, and which scope does it cover?</li>
<li>Are there any additional topics or works to investigate outside of its scope?</li>
<li>Which conclusions or opinions does it offer?</li>
</ul>
<p>The last question is particularly important if you want to continue, as it sets the context of this book in comparison to others covering the same subject. Authors have different backgrounds and biases, which colour their works.<span><label for="sn-3" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-3" class="margin-toggle" /><span class="sidenote">A good example is David Allen’s <em><a href="https://www.goodreads.com/book/show/1633.Getting_Things_Done">Getting Things Done</a></em>, which does hold some value for everyone, like the notion of the task inbox, but also contains a lot of absurd examples and use-cases which clearly show the kind of life he’s living, and the priorities he has.<br />
<br />
</span></span></p>
<p>The more thorough levels of reading take a lot more time, but can be useful if you want to get a deeper understanding of the subject. There are two more steps you can take to gain more insight:</p>
<ol>
<li>Continue reading the chapters, actually reading entire chapters now.</li>
<li>Use other works covering the same subject and cross-reference the important points as you come across them. This allows you to get different viewpoints on the individual points.<span><label for="sn-4" class="margin-toggle sidenote-number"></label><input type="checkbox" id="sn-4" class="margin-toggle" /><span class="sidenote">This is what Adler calls “syntopical” reading, which is a whole discipline on its own. I won’t cover it here, but you can find plenty of material online, and How to Read a Book also has a more detailed explanation.<br />
<br />
</span></span></li>
</ol>
<p>If you get this deep into a subject, the first few steps will be very quick to perform, as you are already familiar with the subject, so you only need to find answers to the questions above before delving in deeper.</p></p>
<p>
<em><a href="https://sulami.github.io/posts/how-to-read-a-book/index.html">March 14, 2020 12:00 AM</a></em>
</p>





<h2>March 13, 2020</h2>




<hr><h3 class="post"><a href="https://defn.io/" title="defn.io">Bogdan Popa (bogdan)</a></h3>


<h4><a href="https://defn.io/2020/03/13/property-testing-api/">Testing a Web API using rackcheck</a></h4>
<p>
Yesterday, I announced rackcheck, my new property-based testing library for Racket and I wanted to do a quick dive into one of the examples in the rackcheck repo where a simple web API is integration tested using PBT.
You can find the full example here.
The app being tested is a simple leaderboard HTTP API with 3 endpoints:
  GET /players: lists all the registered players in order from highest score to lowest.</p>
<p>
<em><a href="https://defn.io/2020/03/13/property-testing-api/">March 13, 2020 09:00 AM</a></em>
</p>









<hr><h3 class="post"><a href="https://blog.ovalerio.net" title="Gonçalo Valério">Gonçalo Valério (dethos)</a></h3>


<h4><a href="https://blog.ovalerio.net/archives/1856">Django Friday Tips: Testing emails</a></h4>
<p>
I haven&#8217;t written one of these supposedly weekly posts with small Django tips for a while, but at least I always post them on Fridays. This time I gonna address how we can test emails with the tools that Django provides and more precisely how to check the attachments of those emails. The testing behavior [&#8230;]</p>
<p>
<em><a href="https://blog.ovalerio.net/archives/1856">March 13, 2020 12:03 AM</a></em>
</p>





<h2>March 12, 2020</h2>




<hr><h3 class="post"><a href="https://j11g.com" title="Jan van den Berg">Jan van den Berg (j11g)</a></h3>


<h4><a href="https://j11g.com/2020/03/12/remote-jason-fried-and-david-heinemeier-hansson/">Remote – Jason Fried and David Heinemeier Hansson</a></h4>
<p>
<p>I saw this tweet yesterday, and If you know me, you know I will not pass on an opportunity for a free book! But more seriously, I have known Jason Fried and DHH for some time now. From their blog, their Twitter and multiple different podcasts. They have built their company around very clear and [&#8230;]</p>
<p>The post <a rel="nofollow" href="https://j11g.com/2020/03/12/remote-jason-fried-and-david-heinemeier-hansson/">Remote &#8211; Jason Fried and David Heinemeier Hansson</a> appeared first on <a rel="nofollow" href="https://j11g.com">Jan van den Berg</a>.</p></p>
<p>
<em><a href="https://j11g.com/2020/03/12/remote-jason-fried-and-david-heinemeier-hansson/">March 12, 2020 10:21 PM</a></em>
</p>









<hr><h3 class="post"><a href="https://defn.io/" title="defn.io">Bogdan Popa (bogdan)</a></h3>


<h4><a href="https://defn.io/2020/03/12/ann-rackcheck/">Announcing rackcheck</a></h4>
<p>
I&rsquo;ve been playing around with property-based testing in Racket this past week. I started by forking the existing quickcheck library to try and add support for shrinking, but I quickly realized that I&rsquo;d have to make a number of breaking changes to get it to work the way I wanted so, in the end, I decided to start a new library from scratch.
The library is called rackcheck and you can grab it off of the package server.</p>
<p>
<em><a href="https://defn.io/2020/03/12/ann-rackcheck/">March 12, 2020 12:00 PM</a></em>
</p>





<h2>March 11, 2020</h2>




<hr><h3 class="post"><a href="https://www.jeffcarp.com/" title="jeffcarp">Jeff Carpenter (jeffcarp)</a></h3>


<h4><a href="https://www.jeffcarp.com/posts/2020/napa-half-race-report/">Napa Half Race Report</a></h4>
<p>
The end of the pain cave. Note: the clock time in the picture is for a different race. &#x1F606;   I PR&rsquo;d my half marathon at the Napa Half!! Yeahh!!!!
 Old PR: 1:31:37 at the 2019 Kaiser SF Half. New PR: 1:28:59 (link). Improvement: 2.9% (-2:38)  In this post I want to look into the race and more closely analyze what went well, what could have gone better, and what was interesting about this race.</p>
<p>
<em><a href="https://www.jeffcarp.com/posts/2020/napa-half-race-report/">March 11, 2020 04:24 PM</a></em>
</p>









<hr><h3 class="post"><a href="https://danluu.com/atom/index.xml" title="Dan Luu">Dan Luu (dl)</a></h3>


<h4><a href="https://danluu.com/corp-eng-blogs/">How (some) good corporate engineering blogs are written</a></h4>
<p>
<p>I've been comparing notes with people who run corporate engineering blogs and one thing that I think is curious is that it's pretty common for my personal blog to get more traffic than the entire corp eng blog for a company with a nine to ten figure valuation and it's not uncommon for my blog to get an order of magnitude more traffic.</p>

<p>I think this is odd because tech companies in that class often have hundreds to thousands of employees. They're overwhelmingly likely to be better equipped to write a compelling blog than I am and companies get a lot more value from having a compelling blog than I do.</p>

<p>With respect to the former, employees of the company will have done more interesting engineering work, have more fun stories, and have more in-depth knowledge than any one person who has a personal blog. On the latter, my blog helps me with job searching and it helps companies hire. But I only need one job, so more exposure, at best, gets me a slightly better job, whereas all but one tech company I've worked for is desperate to hire and loses candidates to other companies all the time. Moreover, I'm not really competing against other candidates when I interview (even if we interview for the same job, if the company likes more than one of us, it will usually just make more jobs). The high-order bit on this blog with respect to job searching is whether or not the process can take significant non-interview feedback or if <a href="http://danluu.com/algorithms-interviews/">I'll fail the interview because they do a conventional interview</a> and the marginal value of an additional post is probably very low with respect to that. On the other hand, companies compete relatively directly when recruiting, so being more compelling relative to another company has value to them; replicating the playbook Cloudflare or Segment has used with their engineering &quot;brands&quot; would be a significant recruiting advantage. The playbook isn't secret: these companies broadcast their output to the world and are generally happy to talk about their blogging process.</p>

<p>Despite the seemingly obvious benefits of having a &quot;good&quot; corp eng blog, most corp eng blogs are full of stuff engineers don't want to read. Vague, high-level fluff about how amazing everything is, content marketing, handwave-y posts about the new hotness (today, that might be using deep learning for inappropriate applications; ten years ago, that might have been using &quot;big data&quot; for inappropriate applications), etc.</p>

<p>To try to understand what companies with good corporate engineering blog have in common, I interviewed folks at three different companies that have compelling corporate engineering blogs (Cloudflare, Heap, and Segment) as well as folks at three different companies that have lame corporate engineering blogs (which I'm not going to name).</p>

<p>At a high level, the compelling engineering blogs had processes that shared the following properties:</p>

<ul>
<li>Easy approval process, not many approvals necessary</li>
<li>Few or no non-engineering approvals required</li>
<li>Implicit or explicit fast <a href="https://en.wikipedia.org/wiki/Service-level_objective">SLO</a> on approvals</li>
<li>Approval/editing process mainly makes posts more compelling to engineers</li>
<li>Direct, high-level (co-founder, C-level, or VP-level) support for keeping blog process lightweight</li>
</ul>

<p>The less compelling engineering blogs had processes that shared the following properties:</p>

<ul>
<li>Slow approval process</li>
<li>Many approvals necessary</li>
<li>Significant non-engineering approvals necessary

<ul>
<li>Non-engineering approvals suggest changes authors find frustrating</li>
<li>Back-and-forth can go on for months</li>
</ul></li>
<li>Approval/editing process mainly de-risks posts, removes references to specifics, makes posts vaguer and less interesting to engineers</li>
<li>Effectively no high-level support for blogging

<ul>
<li>Leadership may agree that blogging is good in the abstract, but it's not a high enough priority to take concrete action</li>
<li>Reforming process to make blogging easier very difficult; previous efforts have failed</li>
<li>Changing process to reduce overhead requires all &quot;stakeholders&quot; to sign off (14 in one case)

<ul>
<li>Any single stakeholder can block</li>
<li>No single stakeholder can approve</li>
</ul></li>
<li>Stakeholders wary of approving anything that reduces overhead

<ul>
<li>Approving involves taking on perceived risk (what if something bad happens) with no perceived benefit to them</li>
</ul></li>
</ul></li>
</ul>

<p>One person at a company with a compelling blog noted that a downside of having only one approver and/or one primary approver is that if that person is busy, it can takes weeks to get posts approved. That's fair, that's a downside of having centralized approval. However, when we compare to the alternative processes, at one company, people noted that it's typical for approvals to take three to six months and tail cases can take a year.</p>

<p>While a few weeks can seem like a long time for someone used to a fast moving company, people at slower moving companies would be ecstatic to have an approval process that only takes twice that long.</p>

<p>Here are the processes, as described to me, for the three companies I interviewed (presented in <code>sha512sum</code> order, which is coincidentally ordered by increasing size of company, from a couple hundred employees to nearly one thousand employees):</p>

<h4 id="heap">Heap</h4>

<ul>
<li>Someone has an idea to write a post</li>
<li>Writer (who is an engineer) is paired with a &quot;buddy&quot;, who edits and then approves the post

<ul>
<li>Buddy is an engineer who has a track record of producing reasonable writing</li>
<li>This may take a few rounds, may change thrust of the post</li>
</ul></li>
<li>CTO reads and approves

<ul>
<li>Usually only minor feedback</li>
<li>May make suggestions like &quot;a designer could make this graph look better&quot;</li>
</ul></li>
<li>Publish post</li>
</ul>

<p>The first editing phase used to involve posting a draft to a slack channel where &quot;everyone&quot; would comment on the post. This was an unpleasant experience since &quot;everyone&quot; would make comments and a lot of revision would be required. This process was designed to avoid getting &quot;too much&quot; feedback.</p>

<h4 id="segment">Segment</h4>

<ul>
<li>Someone has an idea to write a post

<ul>
<li>Often comes from: internal docs, external talk, shipped project, open source tooling (built by Segment)</li>
</ul></li>
<li>Writer (who is an engineer) writes a draft

<ul>
<li>May have a senior eng work with them to write the draft</li>
</ul></li>
<li>Until recently, no one really owned the feedback process

<ul>
<li>Calvin French-Owen (co-founder) and Rick (engineering manager) would usually give most feedback</li>
<li>Maybe also get feedback from manager and eng leadership</li>
<li>Typically, 3rd draft is considered finished</li>
<li>Now, have a full-time editor who owns editing posts</li>
</ul></li>
<li>Also socialize among eng team, get get feedback from 15-20 people</li>
<li>PR and legal will take a look, lightweight approval</li>
</ul>

<p>Some changes that have been made include</p>

<ul>
<li>At one point, when trying to establish an &quot;engineering brand&quot;, making in-depth technical posts a top-level priority</li>
<li>had a &quot;blogging retreat&quot;, one week spent on writing a post</li>
<li>added writing and speaking as explicit criteria to be rewarded in performance reviews and career ladders</li>
</ul>

<p>Although there's legal and PR approval, Calvin noted &quot;In general we try to keep it fairly lightweight. I see the bigger problem with blogging being a lack of posts or vague, high level content which isn't interesting rather than revealing too much.&quot;</p>

<h4 id="cloudflare">Cloudflare</h4>

<ul>
<li>Someone has an idea to write a post

<ul>
<li>Internal blogging is part of the culture, some posts come from the internal blog</li>
</ul></li>
<li>John Graham-Cumming (CTO) reads every post, other folks will read and comment

<ul>
<li>John is approver for posts</li>
</ul></li>
<li>Matthew Prince (CEO) also generally supportive of blogging</li>
<li>&quot;Very quick&quot; legal approval process, SLO of 1 hour

<ul>
<li>This process is so lightweight that one person didn't really think of it as an approval, another person didn't mention it at all (a third person did mention this step)</li>
<li>Comms generally not involved</li>
</ul></li>
</ul>

<p>One thing to note is that this only applies to technical blog posts. Product announcements have a heavier process because they're tied to sales material, press releases, etc.</p>

<p>One thing I find interesting is that Marek interviewed at Cloudflare because of their blog (<a href="https://blog.cloudflare.com/a-tour-inside-cloudflares-latest-generation-servers/">this 2013 blog post on their 4th generation servers caught his eye</a>) and he's now both a key engineer for them as well as one of the main sources of compelling Cloudflare blog posts. At this point, the Cloudflare blog has generated at least a few more generations of folks who interviewed because they saw a blog post and now write compelling posts for the blog.</p>

<h3 id="general-comments">General comments</h3>

<p>My opinion is that the natural state of a corp eng blog where people <a href="http://danluu.com/p95-skill/">get a bit of feedback</a> is a pretty interesting blog. There's <a href="https://twitter.com/rakyll/status/1043952902157459456">a dearth of real, in-depth, technical writing</a>, which makes any half decent, honest, public writing about technical work interesting.</p>

<p>In order to have a boring blog, the corporation has to actively stop engineers from putting interesting content out there. Unfortunately, it appears that the natural state of large corporations tends towards risk aversion and blocking people from writing, just in case it causes a legal or PR or other problem. Individual contributors (ICs) might have the opinion that it's ridiculous to block engineers from writing low-risk technical posts while, simultaneously, C-level execs and VPs regularly make public comments that turn into PR disasters, but ICs in large companies don't have the authority or don't feel like they have the authority to do something just because it makes sense. And none of the fourteen stakeholders who'd have to sign off on approving a streamlined process care about streamlining the process since that would be good for the company in a way that doesn't really impact them, not when that would mean seemingly taking responsibility for the risk a streamlined process would add, however small. An exec or a senior VP willing to take a risk can take responsibility for the fallout and, if they're interested in engineering recruiting or morale, they may see a reason to do so.</p>

<p>One comment I've often heard from people at more bureaucratic companies is something like &quot;every company our size is like this&quot;, but that's not true. Cloudflare, a $6B company approaching 1k employees is in the same size class as many other companies with a much more onerous blogging process. The corp eng blog situation seems similar to situation on giving real interview feedback. <a href="http://blog.interviewing.io/no-engineer-has-ever-sued-a-company-because-of-constructive-post-interview-feedback-so-why-dont-employers-do-it/">interviewing.io claims that there's significant upside and very little downside to doing so</a>. Some companies actually do give real feedback and the ones that do generally find that it gives them an easy advantage in recruiting with little downside, but the vast majority of companies don't do this and people at those companies will claim that it's impossible to do give feedback since you'll get sued or the company will be &quot;cancelled&quot; even though this generally doesn't happen to companies that give feedback and there are even entire industries where it's common to give interview feedback. It's easy to handwave that some risk exists and very few people have the authority to dismiss vague handwaving about risk when it's coming from multiple orgs.</p>

<p>Although this is a small sample size and it's dangerous to generalize too much from small samples, the idea that you need high-level support to blast through bureaucracy is consistent with what I've seen in other areas where most large companies have a hard time doing something easy that has obvious but diffuse value. While this post happens to be about blogging, I've heard stories that are the same shape on a wide variety of topics.</p>

<h3 id="appendix-examples-of-compelling-blog-posts">Appendix: examples of compelling blog posts</h3>

<p>Here are some blog posts from the blogs mentioned with a short comment on why I thought the post was compelling. This time, in reverse sha512 hash order.</p>

<h4 id="cloudflare-1">Cloudflare</h4>

<ul>
<li><a href="https://blog.cloudflare.com/how-verizon-and-a-bgp-optimizer-knocked-large-parts-of-the-internet-offline-today/">https://blog.cloudflare.com/how-verizon-and-a-bgp-optimizer-knocked-large-parts-of-the-internet-offline-today/</a>

<ul>
<li>Talks about a real technical problem that impacted a lot of people, reasonably in depth</li>
<li>Timely, released only eight hours after the outage, when people were still really interested in hearing about what happened; most companies can't turn around a compelling blog post this quickly or can only do it on a special-case basis, Cloudflare is able to crank out timely posts semi-regularly</li>
</ul></li>
<li><a href="https://blog.cloudflare.com/the-relative-cost-of-bandwidth-around-the-world/">https://blog.cloudflare.com/the-relative-cost-of-bandwidth-around-the-world/</a>

<ul>
<li>Exploration of some data</li>
</ul></li>
<li><a href="https://blog.cloudflare.com/the-story-of-one-latency-spike/">https://blog.cloudflare.com/the-story-of-one-latency-spike/</a>

<ul>
<li>A debugging story</li>
</ul></li>
<li><a href="https://blog.cloudflare.com/when-bloom-filters-dont-bloom/">https://blog.cloudflare.com/when-bloom-filters-dont-bloom/</a>

<ul>
<li>A debugging story, this time in the context of developing a data structure</li>
</ul></li>
</ul>

<h4 id="segment-1">Segment</h4>

<ul>
<li><a href="https://segment.com/blog/when-aws-autoscale-doesn-t/">https://segment.com/blog/when-aws-autoscale-doesn-t/</a>

<ul>
<li>Concrete explanation of a gotcha in a widely used service</li>
</ul></li>
<li><a href="https://segment.com/blog/gotchas-from-two-years-of-node/">https://segment.com/blog/gotchas-from-two-years-of-node/</a>

<ul>
<li>Concrete example and explanation of a gotcha in a widely used tool</li>
</ul></li>
<li><a href="https://segment.com/blog/automating-our-infrastructure/">https://segment.com/blog/automating-our-infrastructure/</a>

<ul>
<li>Post with specific details about how a company operates; in theory, any company could write this, but few do</li>
</ul></li>
</ul>

<h4 id="heap-1">Heap</h4>

<ul>
<li><a href="https://heap.io/blog/engineering/basic-performance-analysis-saved-us-millions">https://heap.io/blog/engineering/basic-performance-analysis-saved-us-millions</a>

<ul>
<li>Talks about a real problem and solution</li>
</ul></li>
<li><a href="https://heap.io/blog/engineering/clocksource-aws-ec2-vdso">https://heap.io/blog/engineering/clocksource-aws-ec2-vdso</a>

<ul>
<li>Talks about a real problem and solution</li>
<li>In HN comments, engineers (malisper, kalmar) have technical responses with real reasons in them and not just the usual dissembling that you see in most cases</li>
</ul></li>
<li><a href="https://heap.io/blog/analysis/migrating-to-typescript">https://heap.io/blog/analysis/migrating-to-typescript</a>

<ul>
<li>Real talk about how the first attempt at driving a company-wide technical change failed</li>
</ul></li>
</ul>

<p>One thing to note is that these blogs all have different styles. Personally, I prefer the style of Cloudflare's blog, which has a higher proportion of &quot;deep dive&quot; technical posts, but different people will prefer different styles. There are a lot of styles that can work.</p>

<p><small>Thanks to Marek Majkowski, Kamal Marhubi, Calvin French-Owen, John Graham-Cunning, Michael Malis, Matthew Prince, Yuri Vishnevsky, Julia Evans, Wesley Aptekar-Cassels, Nathan Reed, Jake Seliger, an anonymous commenter, plus sources from the companies I didn't name for comments/corrections/discussion; none of the people explicitly mentioned in the acknowledgements were sources for information on the less compelling blogs</small></p>

<p>


</p></p>
<p>
<em><a href="https://danluu.com/corp-eng-blogs/">March 11, 2020 12:00 AM</a></em>
</p>





<h2>March 10, 2020</h2>




<hr><h3 class="post"><a href="http://gerikson.com/blog" title="The occasional scrivener">Gustaf Erikson (gerikson)</a></h3>


<h4><a href="http://gerikson.com/blog/books/read/Old-Venus.html"><em>Old Venus</em>, George R.R. Martin &amp; Gardner Dozois (editors)</a></h4>
<p>
</p>
<p>
<em><a href="http://gerikson.com/blog/books/read/Old-Venus.html">March 10, 2020 06:13 PM</a></em>
</p>









<hr><h3 class="post"><a href="https://j11g.com" title="Jan van den Berg">Jan van den Berg (j11g)</a></h3>


<h4><a href="https://j11g.com/2020/03/10/the-quotable-walt-disney-disney-book-group/">The Quotable Walt Disney – Disney Book Group</a></h4>
<p>
<p>I picked up this book on our honeymoon to Disney World. But I never read it, because; how do you read a book full of quotes? The answer is slowly! Just grab it every now and then. And read a few pages. Of course this is probably a heavily edited and well scrutinized book. Assembled [&#8230;]</p>
<p>The post <a rel="nofollow" href="https://j11g.com/2020/03/10/the-quotable-walt-disney-disney-book-group/">The Quotable Walt Disney &#8211; Disney Book Group</a> appeared first on <a rel="nofollow" href="https://j11g.com">Jan van den Berg</a>.</p></p>
<p>
<em><a href="https://j11g.com/2020/03/10/the-quotable-walt-disney-disney-book-group/">March 10, 2020 05:54 PM</a></em>
</p>









<hr><h3 class="post"><a href="http://www.petecorey.com/" title="Pete Corey">Pete Corey (petecorey)</a></h3>


<h4><a href="http://www.petecorey.com/blog/2020/03/10/querying-for-mongodb-documents-where-every-subdocument-matches-a-pattern/">Querying for MongoDB Documents Where Every Sub-document Matches a Pattern</a></h4>
<p>
Recently I found myself tasked with removing documents from a MongoDB collection that had an array of sub-documents entirely matching a pattern. The final solution required I flip my perspective on the problem entirely.</p>
<p>
<em><a href="http://www.petecorey.com/blog/2020/03/10/querying-for-mongodb-documents-where-every-subdocument-matches-a-pattern/">March 10, 2020 12:00 AM</a></em>
</p>





<h2>March 09, 2020</h2>




<hr><h3 class="post"><a href="https://venam.nixers.net/blog/" title="Venam's Blog">Patrick Louis (venam)</a></h3>


<h4><a href="https://venam.nixers.net/blog/programming/2020/03/10/march-2020-projects.html">March 2020 Projects</a></h4>
<p>
<p>Here comes another life update.<br />
My biological clock seems to have chosen to remind me to post these
updates once every 6 months, with seasonal changes.</p>

<p>Since the previous post, everything has been hectic. The country I’m
living in, Lebanon, has plunged into an economic, financial, social,
political, and more recently, health crisis. As I’m writing these words,
it has defaulted on its debt payment.<br />
While the focus of these posts is usually not my surroundings, the gravity
of the situation is coloring whatever I’ve been up to recently. Thus,
it’s imperative to start with a summary.</p>

<h3 id="the-past-few-months-in-lebanon">The past few months in Lebanon</h3>

<p><img src="https://venam.nixers.net/blog/assets/Beirut_1913.jpg" alt="Beirut 1913" /></p>

<p><em>Language: fire</em><br />
<em>Explanation</em>:</p>

<p>My last post was on the 14th of September 2019, soon after publishing
it a lot of events unfolded.<br />
For already a year, the Lebanese government had been in a dire
economical situation and clumsily tried to argue over which austerity
measures they would implement as a remediation. One culprit was the
currency itself. Having the Lebanese Lira as a pegged currency has
advantages and disadvantages. At this point in time, it was apparent
that keeping the peg was costly, it required the central bank to perform
juggling of financial instruments, buying debts from the governments
with its reserve, that would be paid back from the yearly revenue
of the country. Debts that could be given in both Lebanese pounds
and Eurobonds in US Dollars. However, the price of this maneuver
grew quite a lot. The debt to gdp ratio had become ~150% and debt
servicing made up 25 to 30 percent of the government expenditures (<a href="http://backend.institutdesfinances.gov.lb/wp-content/uploads/2019/12/2019-Citizen-Budget-launching-PPT-english-sept19_compressed.pdf">2019
budget</a>,
<a href="http://www.institutdesfinances.gov.lb/wp-content/uploads/2020/03/Budget-flyer-A5-En-2020-web.pdf">2020
budget</a>).
Adding insult to injury, the majority of those debts used
to be bought by <a href="http://erf.org.eg/publications/ive-got-the-power-mapping-connections-between-lebanons-banking-sector-and-the-ruling-class/">local banks owned directly or indirectly by
politicians</a>.<br />
The lack of growth in the economy, which relied heavily on tourism
and a generous diaspora, can’t forever balance the peg. And the
financial moves cover the fact that people are literally paying for
it from their own pockets by giving up on basic public goods and
instead investing in their currency keeping its value. Additionally,
the almost non-existence of an industrial sector, or any export
sectors for that matter, means that all products are imported and
paid for in foreign currency, creating a vicious rampant <a href="http://cas.gov.lb/index.php/economic-statistics-en?layout=edit&id=185">inflation
cycle</a>.
This lead to a rapid increase in the price of living in Lebanon, in
power-distance, and in inequalities the past years.</p>

<p>In sum, there were a lot of talks about new taxes, fees, cutting
wages, increasing the retirement age in the public sector and
a freeze in hiring of government workers, but not a lot of talk
related to the stimulation of the job market other than telling
people to buy local goods and products regardless of their higher
prices. Even though <a href="https://www.doingbusiness.org/content/dam/doingBusiness/country/l/lebanon/LBN.pdf">starting a business in Lebanon is a lot of a
hassle</a>
and could be made easier. <a href="https://youtu.be/vgHBWiHh9YM?t=1819">There has been a lot of sweet talk about this but
rather delayed</a>. Who would want to
give up their current lifestyle, who would bear the burden. Should we
play the blame game?</p>

<p>Consequentially, there were a lot of small protests but the first
milestone, one that put the country on a standstill by having the highways
arteries blocked, was by retired veterans of the security forces that
disagreed and feared a bill that would reduce their retirement pensions
and privileges. There was no actual decision at this point, only rumors,
but the officials made it clear, to appease the crowd, that they wouldn’t
touch retirees pensions.<br />
The security sector is a sensible zone to wander in legislatively. There’s
too much feelings involved as the army is the core of any country. Any
form of disrespect would mean spitting on their service. This is the
old adage from Ancient Rome.</p>

<p><a href="https://www.reuters.com/article/us-lebanon-economy-budget-idUSKCN1S61NS">An article on
reuters</a>
quotes it best:</p>

<blockquote>
  <p>“This is our right, our sweat and blood,” former sergeant major Khodr
Noureddine said. “Our salaries can’t even feed us for a day, there’s
no school funding, no good healthcare.”</p>
</blockquote>

<p>Yet, the collective memory forgets that this exact
same scenario happened just two years earlier, <a href="https://monthlymagazine.com/article-desc_4506_">in
2017</a>, and that as a
result many civil servants had gotten a raise of ~40%. What a conundrum
for the dwindling budget.</p>

<p>The government was running out of options, options that wouldn’t put in
peril their political future and their personal pockets.</p>

<p>We absolutely have to mention that the Lebanese
army is heavily sponsored, not only by the Lebanese
government where it makes around <a href="https://en.wikipedia.org/wiki/List_of_countries_by_military_expenditures">~15% of the government
expenditure</a>,
but by foreign benefactors such as the
<a href="https://yalibnan.com/2018/05/16/pentagon-oks-90-million-for-lebanese-army/">USA</a>,
Canada, Russia, the Netherlands, the UK, Italy, France, and more, which
give billions in aid, donations, training, and equipment. Actually,
the Lebanese government spends almost nothing on equipment and everything
on personnel.</p>

<p>There was a time, before the civil war, where the military service used to
be obligatory in Lebanon. The army it composed used to be the smallest one
in the Middle East. After the civil war, in 1989, most of the militias
merged their arms together, other than Hezbollah, forming a new army
and officially taking over the country with the sectarian Taif agreement.<br />
As a consequence, some politicians still use the army as their own
militia, or to sway public opinions. They use it as a bargaining tool,
offering jobs to the poorest while making their families pledge allegiance
to the political movement. The army has become a sort of universal basic
income in Lebanon, which means that everyone is related to someone with
a link in the army. The army is engrained in everything.</p>

<p>Meanwhile, <a href="https://www.aljazeera.com/news/2019/09/israeli-army-fires-lebanon-hezbollah-missile-attack-190901134806880.html">Hezbollah was playing tug of war with
Israel</a>,
as it usually do, showing it doesn’t care for Lebanese issues but more
about its own interests, its brand of resistance™. If there was nothing
to resist against they would have no raison d’être.</p>

<p>While security is extremely important, political elites play the sentiment
card to siphon foreign aids and bribe higher ups.<br />
The entirety of the Lebanese political system works like this, factions
taking care of their turfs, appropriating themselves positions in the
parliaments that are related to projects where they can cook the books,
redirect funds, or take gigantic commissions. Each party has a cartel
of its own, even the non-official ones. It’s a system were hiring is
done on “wasta”, greed, bribe, and nepotism. A system where someone do
you favors so that you are forced to pay them back, mafia-style.<br />
The ongoing internationally funded projects in Lebanon are countless,
but the huge discrepancies between what’s on paper and what’s on the
ground is astonishing. Lebanon receives an insane amount of funding
from: the UN, the EU, the World Bank, the Islamic development bank,
Commonwealth Bank, Arab Fund for Economic and Social Development, OPEC
Fund for International Development, Italy, French development agency,
Japan, Saudi Arabia, UAE, Kuwait, Qatar, Germany, USA/USAID, China,
Turkey, Oman, Spain, etc.. Yet, money always seems to be a problem, and
projects almost never get finished. This <a href="https://www.trtworld.com/magazine/exclusive-mogherini-under-fire-over-stink-in-lebanon-from-eu-cash-33136">example from the European union
funds</a>
shows how rotten the public sector is.<br />
Clientelism reigns and companies that don’t accept the status-quo never
get contracts.</p>

<p>There’s no real long term planning, no real urban planning. Why
is that? No organization in Lebanon has the right to sign big
contracts other than the CDR, the Commission for Development and
Reconstruction. A defunct branch of government used after the civil
war that was brought back from its grave by the late Rafik Hariri to
bypass regulation and legislation, to make the projects he wanted
to do quicker. The CDR is under direct supervision from the prime
minister, which was still Saad Hariri until recently. The projects and
their fundings are listed on the cdr.gov.lb site, <a href="https://venam.nixers.net/blog/www.cdr.gov.lb/eng/progress_reports/pr102018/PReng.pdf">here is the 2018
report</a>, and
as you can see, a big share of the funding doesn’t come from Lebanon,
most of the infrastructure in Lebanon was built by foreign entities.</p>

<p>A scandal was reported at the start of October: The PM, Hariri, had given
<a href="https://www.nytimes.com/2019/09/30/world/middleeast/lebanon-hariri-model.html">$16M to a South African bikini model named Candice Van Der Merwe as a
“gift”</a>
and her government was suing her for not paying taxes on it. And
while the public took it only from the shock value perspective,
what was going on under the table was even more appalling. A nugget
of information that was lost was that Candice is the daughter
of a real estate tycoon and money launderer named Gary Van Der
Merwe, that resides and stores his money in the Seychelles tax
haven. The same Gary that <a href="https://www.iol.co.za/business-report/opinion/opinion-between-your-side-the-other-side-and-the-truth-12846951">appeared 350 times in court for shady
businesses</a>.<br />
What a way to stir up a population fearing economic collapse and already
sick of everything!</p>

<p>Soon after an environmental catastrophe shook the country, one where the
inefficacy of the decision makers was apparent: The forest of Lebanon
<a href="https://en.wikipedia.org/wiki/2019_Lebanon_forest_fires">were on fire</a>
and it couldn’t be stopped. Everyone soon learned that the government had
no equipment to deal with the situation other than using their anti-riot
vehicles mounted with water cannons. The firefighter helicopters
weren’t maintained and aid from the neighbors Cyprus, Turkey, Greece,
and Jordan was required.<br />
The population got even more stirred up, sentiments were at their
highest, even though some politicians tried to move the discussion to
their advantage by blaming and using sectarianism.</p>

<p>A week or so after the wildfires, rumors got out that part of the
austerity measures would include new taxes on cigarettes and VoIP
calls. People got the word and went to the streets. What used to
be small protests until that point, soon erupted into humongous
ones.<br />
Disapprovement was on everyone’s tongue.</p>

<p>Folks still wonder to this day what could’ve went into the mind of the
person that proposed the idea, in reality it was a proposal based on
deprecated Lebanese telecommunication laws, old man’s thinking per say. To
understand this decision we have to read the telecom sector history.<br />
It may sound surprising to hear this in 2020, but VoIP is still
technically illegal in Lebanon even though anyone with a computing
device can open an app and call anyone anywhere else on the planet and
only pay for the internet data consumption. The ban is only enforced on
the telecom level to not loose profit from calls, this is why we don’t
have VoIP with LTE.<br />
Back in the days, before 2004-2005, two private companies used to manage
and build the telecom sector, Cellis and Libancell. Each had very long
term contracts with the government with a maximum quota of subscribers
and a specific percentage it would pay the government from its profit
(from 20-40%). Their pricing used to be exorbitant compared to anywhere
else. However, those companies got greedy, they went above the quota
of subscribers and hid their profits. So, the government sued them for
breach of contract and required them to pay a fine. The contract was void,
the issue was settled, and Lebanon had in its hands telecom equipment
but nobody to run them.<br />
A government agency called the TRA, Telecom Regulation Authority, got
created to set the national standards and regulations, set the pricing
of telecom related activities, meanwhile a bidding war got announced
for who would manage the network and at which price. The contract would
work like this: the government would pay for the telecom equipment and
the expansion, the companies winning the bids would manage the network
and get paid a fixed fee on a 3-4 year contract basis, and any profit
from it would go in its entirety to the government. (for more info see
<a href="http://www.databank.com.lb/docs/Lebanon%20Telecoms%20Market%20Overview%202007.pdf">2007</a>
and
<a href="https://www.executive-magazine.com/economics-policy/telecom-reforms-get-jammed-in-the-system">2005</a>)<br />
This is the situation we have today and the reason why someone thought
it was a novel idea to tax VoIP but in reality it was an archaic one.</p>

<p>While the price for mobile related activities has radically changed with
the creation of the TRA, old perceptions are hard to move. The price on
mobile is like a tax that cancels itself to pay back the energy sector
debt. Plus, mobiles are an inherent part of Lebanese society and its
business related activities, especially WhatsApp. Everyone is on their
phones all the time.</p>

<p>Hence, the nation got on the streets and showed its discontentment,
more so than when it did in <a href="https://en.wikipedia.org/wiki/2015%E2%80%9316_Lebanese_protests">2015-2016 with the YouStink!
movement</a>
that I indirectly hinted at <a href="https://venam.nixers.net/blog/philosophy/2016/04/26/lebanese-mentality.html">in this
post</a>.<br />
It was surprising to see the awakening of a population that had been
trained to stay away from politics, to not have its own opinion and
leave the field for the big players to enjoy. Lebanese have been numbed,
apathetic, and sickened of this from years of civil war, they have
been tortured by fear transmitted through sectarianism propaganda and
tribalism. The majority being completely disconnected from their own
country, acting as if they weren’t living in it, dreaming of fleeing
and always thinking of the worst.<br />
Political discussions in the country are still immature, based solely
on emotions, personal benefits, turf and religious zeal. Moreover, the
social contract is missing, there’s a lack of social responsibilities
when it concerns the country as a whole. In sum, there’s no unity,
everyone has to live in their own bubbles and that means a full on
disrespect of anything that doesn’t profit single individuals.<br />
<em>Impatient opportunistic exploiters</em> has been the way I used to describe
the daily social interactions in Lebanon.</p>

<p>For these reasons, I thought the protests wouldn’t stick but they did,
one after the other, day after day, it erupted on the street. Enormous
groups gathered, dancing and chanting “revolution”, “everyone means
everyone”, wanting the fall of the current political elites, not sparring
anyone. Overall, the protests were non-violent.</p>

<p>That led the PM giving himself an ultimatum to adjust his austerity plan
to please the populace, otherwise he’d resign. Although we all know that
a crowd isn’t a beast that can be appeased with words and reasons. Thus,
the PM Hariri resigned along with his cabinet, leaving the country in
a chaotic state, on the 29th of October 2019.</p>

<p>This event engender yet another slip in the Lebanese bonds, one more
dive for the economy to handle: The lack of a functioning government.</p>

<p>The banks, which had closed on and off since the protests started for
security reasons, instituted restrictions on customers’ accounts. From
now on, no exchange from Lebanese Lira to US Dollar would be allowed,
which used to be the norm as Lebanon has a pegged currency. Additionally,
customers would be rationed their amount of hard cash currency per
week and per month, locally and internationally. The ration went
from $400/week to now $200/week in cash. That had the aftereffect of
causing a slow run on banks and giving rise to many parallel markets
for dollars which the central bank has tried
to thwart but couldn’t because it lacked the reserves to inject money
into the system.<br />
This created an increase in prices in any imported products as
money exchangers were taking a higher conversion rate from LBP to
USD. The country experienced protests from shortages in gas stations,
bakeries, hospitals, etc.. Currently, Lebanese have lost around 40% of
their purchasing power. The biggest loss is on people that don’t deal
internationally, the ones that are paid exclusively in Lebanese Lira,
the people working for the government for instance.</p>

<p>Then a new government was formed, so called politico-technocrat, led
by Hassan Diab as PM, a PhD professor of Engineering at the American
University of Beirut that published over 150 scientific articles and
that previously ran as minister of education from 2011 till 2014.<br />
He was torn apart between having to face both the anger of the street,
the previous political cartel of sectarian civil war veterans, the
elephant in the room, Hezbollah, and a monstrous economical and financial
situation. Not an easy feat to tackle, a political suicide one might say.<br />
His <a href="https://en.wikipedia.org/wiki/Lebanese_government_of_January_2020">small cabinet of
20</a>,
defunct of Hezbollah opposition parties which boycotted the formation,
had the difficult task to balance public trust, local and international,
along with austerity measures, a crumbling money with a population losing
their livelihood, and the financial sector on a locked down.</p>

<p>Naturally, the anger on the street couldn’t be rationalized
with. Emotions create rise to hatred and blame. The train couldn’t
be stopped. Indirectly, the people made a choice because they had no
trust in the system, a system they were disconnected from. They refused
austerity measures because they didn’t believe they would work. They
felt disrespected, they felt a lack of true leadership.<br />
Lebanese made a choice, a self-imposed reset, whatever the cost.</p>

<p>So on the 9th of March 2020, Lebanon’s first-ever debt default happened.</p>

<p>Amidst all this, the covid-19 cases in the country are increasing day
by day, currently sitting at around 50 cases, the first patients coming
from Iran and Egypt.</p>

<p>And.. The global stock market is in a whirlwind of a mess too.</p>

<p>Is it a
<a href="https://venam.nixers.net/blog/psychology/2020/01/10/what-is-a-collapse.html">collapse</a>,
I’ll let you judge.</p>

<p>This is what’s been happening the past few months. If
you want to read more about this, check <a href="https://en.wikipedia.org/wiki/2019%E2%80%9320_Lebanese_protests">this wikipedia
article</a>.</p>

<h3 id="psychology-philosophy--books">Psychology, Philosophy &amp; Books</h3>

<p><em>Language: brains</em><br />
<em>Explanation</em>:</p>

<p><img src="https://venam.nixers.net/blog/assets/collapse.jpg" alt="Collapse" /></p>

<p>I’ve read quite a lot, on average 2 to 3 books a months.</p>

<p>Here’s a list of the technical books:</p>

<ul>
  <li>Software Architecture in Practice 3rd edition - Finished it since last time</li>
  <li>Building evolutionary architectures - Neal Ford</li>
  <li>The clean coder: A code of conduct for professional programmers - Robert Martin</li>
  <li>Domain-Driven Design - Eric Evans - Currently reading, almost done</li>
</ul>

<p>I’ve also embarked on the first technical podcast that I enjoyed:</p>

<ul>
  <li><a href="https://onthemetal.fm/">On the metal</a></li>
</ul>

<p>The non-technical books are:</p>

<ul>
  <li>Artemis - Andy Weir</li>
  <li>Station Eleven - St.John Mandel Emily</li>
  <li>The institute - Stephen King</li>
  <li>Maybe you should talk to someone - Lori Gottlieb</li>
  <li>Howto - Randall Munroe</li>
  <li>Whatif - Randall Munroe</li>
  <li>The handmaid’s Tale - Margaret Atwood</li>
  <li>The design of everyday things - Don Norman</li>
  <li>The Art of loving - Erich Fromm</li>
  <li>Thinking, Fast and slow - Kahneman</li>
  <li>Collapse, how societies choose to fail or survice - Jared Diamond’s</li>
  <li>Capitalism without capital: The rise of the intangible economy - Jonathan Haskel</li>
  <li>Alchemy &amp; Mysticism (Bibliotheca Universalis) - Taschen - Currently reading</li>
  <li>Factfulness - Rossling - Currently devouring</li>
</ul>

<p>Other podcasts I’ve added to my long subscription list are:</p>

<ul>
  <li>The motley fool money</li>
  <li>Freakonomics radio</li>
  <li>The Lebanese politics podcast</li>
  <li>Mythical monsters</li>
</ul>

<p>Usually I avoid getting books before I’m done reading what I have but
considering the current situation I’ve added the following never-old
classics to my collection:</p>

<ul>
  <li>The better angels of our nature: Why violence declined - Stephen Pinker</li>
  <li>The book of M - Peng Shepherd</li>
  <li>The gene - Siddhartha mukherjee</li>
  <li>Beyond software architecture: Hohmann</li>
  <li>Algorithms: Sedgewick</li>
  <li>Computer Architecture: A Quantitative approach - Hennesy Patterson</li>
  <li>Operating system concepts - Silberschatz</li>
  <li>Compilers - Aho Lam Seth Ullman</li>
</ul>

<p>My book collection is stacking up and I’m really thinking I should build
a library.</p>

<h3 id="learning-growth">Learning, Growth</h3>

<p><em>Language:growth</em><br />
<em>Explanation</em>:</p>

<p><img src="https://venam.nixers.net/blog/assets/Roman_blacksmith.jpg" alt="Roman blacksmith" /></p>

<p>I’ve grown quite fond of the domain of software architecture. So far I’m
on a roll, reading and watching videos every day on the topic.</p>

<p>In total:</p>

<ul>
  <li>335 articles</li>
  <li>95 videos</li>
  <li>10 research papers</li>
  <li>5 books</li>
</ul>

<p>My Anki decks are full of knowledge that I review to not let it spill
out after I’m done with consuming the content.</p>

<p>I’ve attempted Kata programming exercises, which is something anyone
should try once to get out of their routine coding techniques.</p>

<p>I’ve published my first <a href="https://venam.nixers.net/blog/programming/2020/01/09/se-practices.html">blog post related to software engineering
practices</a>.</p>

<p>Eventually, I want to pass the Carnegie Mellon University software
architecture certification program. But, as you’ve probably noticed,
it’s not the best moment to spend money online with all the banking
restrictions.<br />
So instead I’ll continue writing articles whenever I can, sharing
knowledge.</p>

<h3 id="ascii-art--art">Ascii Art &amp; Art</h3>

<p><em>Language: ASCII</em><br />
<em>Explanation</em>:</p>

<p><img src="https://venam.nixers.net/blog/assets/ascii/as66.png" alt="Lebanon 2020" /><br />
<img src="https://venam.nixers.net/blog/assets/ascii/as65.png" alt="Building a Universe" /></p>

<p>I haven’t published many ASCII art pieces. The one you see above and
the ones in <a href="https://16colo.rs/pack/impure74/">Impure 74</a> and <a href="https://16colo.rs/pack/impure75/">Impure
75</a> packs.</p>

<h3 id="other-learning">Other Learning</h3>

<p><em>Language: gray matter</em><br />
<em>Explanation</em>:</p>

<p><img src="https://venam.nixers.net/blog/assets/elevate_app.png" alt="Elevate App" /></p>

<p>It’s been almost two months since I’ve done my last singing
session. Instead, I’ve learned to juggle, at least with 3 balls.</p>

<p>As far as the brainteaser, Elevate, goes, I’ve used it religiously and
am on a 318 days streak.</p>

<p>Apart from those I’ve been reading on emotional intelligence on <a href="http://emotionalgranularity.com">Emotional
Granurality</a> and been watching ton of
documentaries on Curiosity Stream along with some movies about the 2008
crisis and the Enron company.</p>

<p>On the other side, food wise, I’ve been gifted a fantastic apron for my
birthday and it has reinvigorated my love for cooking.</p>

<p>Finally, it’s noticeable that I’ve developed a huge interest in Urban
planning, management, leadership view, decision making, and been digging
into RFPs, big projects, history, sociology, deals, primarily I’ve been
interested in politics.</p>

<h3 id="life-and-other-hobbies">Life and other hobbies</h3>

<p><em>Language: life</em><br />
<em>Explanation</em>:</p>

<p><img src="https://venam.nixers.net/blog/assets/brussels_2020.jpg" alt="brussels" /></p>

<p>I spent a week in Brussels at the beginning of February to attend FOSDEM
and do some sightseeing.</p>

<p>At FOSDEM I’ve finally met face to face with some nice fellows from
nixers.net, namely eyenx, joshua, and pyratebeard. The conference itself
has so many talks that it was a hassle to plan properly which one to
attend. In the end it was a success and I didn’t miss any of my favorite
speakers or topics.</p>

<p>In Belgium I had a blast at the museum of art and history, I’m a big
fan of museums.</p>

<h2 id="now">Now</h2>

<p>I would end with “Which all leads to what’s in store for tomorrow.
More of the same but upgraded.” but today I need a bit of change.</p>

<p>I’ll still put all my efforts on software architecture but I’ll also
try to open new opportunities. Freshness is really needed right now.<br />
Plus whatever I’m already doing but more of it!</p>

<p>This is it!</p>

<p>As usual… If you want something done, no one’s gonna do it for you, use your own hands.<br />
And let’s go for a beer together sometime, or just chill.</p></p>
<p>
<em><a href="https://venam.nixers.net/blog/programming/2020/03/10/march-2020-projects.html">March 09, 2020 10:00 PM</a></em>
</p>





<h2>March 06, 2020</h2>




<hr><h3 class="post"><a href="https://www.jeffcarp.com/" title="jeffcarp">Jeff Carpenter (jeffcarp)</a></h3>


<h4><a href="https://www.jeffcarp.com/posts/2020/no-bookmarks/">Stop Using Bookmarks</a></h4>
<p>
The bookmark. A small, flimsy piece of paper or plastic wedged into the latest book you&rsquo;re reading (unless you deface your books by dog-earing them&mdash;but hear me out dog-earers: this essay is still for you). Bookmarks are a convenience I&rsquo;m guessing you take for granted and to which you don&rsquo;t give a second thought. In this essay I will attempt to pursuade you to stop using them altogether.
Why?? You ask, would you ever want to eliminate such a simple convenience?</p>
<p>
<em><a href="https://www.jeffcarp.com/posts/2020/no-bookmarks/">March 06, 2020 05:42 PM</a></em>
</p>









<hr><h3 class="post"><a href="https://pragtob.wordpress.com" title="Journeys of a not so young anymore Software Engineer">Tobias Pfeiffer (PragTob)</a></h3>


<h4><a href="">Slides: Stories in Open Source</a></h4>
<p>
Yesterday at RUG::B I tried something I&#8217;d never done before: a more personal, story driven talk. And in order to adequately illustrate it and how different Open Source feel to me I also opted paint some very special drawings. Open Source is something I&#8217;ve been doing for longer than people pay me to do programming. [&#8230;]</p>
<p>
<em><a href="">March 06, 2020 09:23 AM</a></em>
</p>





<h2>March 03, 2020</h2>




<hr><h3 class="post"><a href="http://gerikson.com/blog" title="The occasional scrivener">Gustaf Erikson (gerikson)</a></h3>


<h4><a href="http://gerikson.com/blog/books/read/Armageddon.html"><em>Armageddon: The Battle for Germany, 1944-1945</em> by Max Hastings</a></h4>
<p>
</p>
<p>
<em><a href="http://gerikson.com/blog/books/read/Armageddon.html">March 03, 2020 07:10 PM</a></em>
</p>









<hr><h3 class="post"><a href="https://danluu.com/atom/index.xml" title="Dan Luu">Dan Luu (dl)</a></h3>


<h4><a href="https://danluu.com/cli-complexity/">The growth of command line options, 1979-Present</a></h4>
<p>
<p><a href="https://www.xkcd.com/1795/">My hobby</a>: opening up <a href="http://danluu.com/mcilroy-unix/">McIlroy’s UNIX philosophy</a> on one monitor while reading manpages on the other.</p>

<p>The first of McIlroy's dicta is often paraphrased as &quot;do one thing and do it well&quot;, which is <a href="http://danluu.com/mcilroy-unix/">shortened from</a> &quot;Make each program do one thing well. To do a new job, build afresh rather than complicate old programs by adding new 'features.'&quot;</p>

<p>McIlroy's example of this dictum is:</p>

<blockquote>
<p>Surprising to outsiders is the fact that UNIX compilers produce no listings: printing can be done better and more flexibly by a separate program.</p>
</blockquote>

<p>If you open up a manpage for <code>ls</code> on mac, you’ll see that it starts with</p>

<pre><code>ls [-ABCFGHLOPRSTUW@abcdefghiklmnopqrstuwx1] [file ...]
</code></pre>

<p>That is, the one-letter flags to <code>ls</code> include every lowercase letter except for <code>{jvyz}</code>, 14 uppercase letters, plus <code>@</code> and <code>1</code>. That’s 22 + 14 + 2 = 38 single-character options alone.</p>

<p>On ubuntu 17, if you read the manpage for coreutils <code>ls</code>, you don’t get a nice summary of options, but you’ll see that <code>ls</code> has 58 options (including <code>--help</code> and <code>--version</code>).</p>

<p>To see if <code>ls</code> is an aberration or if it's normal to have commands that do this much stuff, we can look at some common commands, sorted by frequency of use.</p>

<p>table {border-collapse:collapse;margin:0px auto;}table,th,td {border: 1px solid black;}td {text-align:center;}
<table>
<tr>
<th>command</th><th>1979</th><th>1996</th><th>2015</th><th>2017</th></tr>
<tr>
<td>ls</td><td>11</td><td><font color="white">42</font></td><td><font color="white">58</font></td><td><font color="white">58</font></td></tr>
<tr>
<td>rm</td><td>3</td><td>7</td><td>11</td><td>12</td></tr>
<tr>
<td>mkdir</td><td>0</td><td>4</td><td>6</td><td>7</td></tr>
<tr>
<td>mv</td><td>0</td><td>9</td><td>13</td><td>14</td></tr>
<tr>
<td>cp</td><td>0</td><td>18</td><td><font color="white">30</font></td><td><font color="white">32</font></td></tr>
<tr>
<td>cat</td><td>1</td><td>12</td><td>12</td><td>12</td></tr>
<tr>
<td>pwd</td><td>0</td><td>2</td><td>4</td><td>4</td></tr>
<tr>
<td>chmod</td><td>0</td><td>6</td><td>9</td><td>9</td></tr>
<tr>
<td>echo</td><td>1</td><td>4</td><td>5</td><td>5</td></tr>
<tr>
<td>man</td><td>5</td><td>16</td><td><font color="white">39</font></td><td><font color="white">40</font></td></tr>
<tr>
<td>which</td><td></td><td>0</td><td>1</td><td>1</td></tr>
<tr>
<td>sudo</td><td></td><td>0</td><td>23</td><td>25</td></tr>
<tr>
<td>tar</td><td>12</td><td><font color="white">53</font></td><td><font color="white">134</font></td><td><font color="white">139</font></td></tr>
<tr>
<td>touch</td><td>1</td><td>9</td><td>11</td><td>11</td></tr>
<tr>
<td>clear</td><td></td><td>0</td><td>0</td><td>0</td></tr>
<tr>
<td>find</td><td>14</td><td><font color="white">57</font></td><td><font color="white">82</font></td><td><font color="white">82</font></td></tr>
<tr>
<td>ln</td><td>0</td><td>11</td><td>15</td><td>16</td></tr>
<tr>
<td>ps</td><td>4</td><td>22</td><td><font color="white">85</font></td><td><font color="white">85</font></td></tr>
<tr>
<td>ping</td><td></td><td>12</td><td>12</td><td><font color="white">29</font></td></tr>
<tr>
<td>kill</td><td>1</td><td>3</td><td>3</td><td>3</td></tr>
<tr>
<td>ifconfig</td><td></td><td>16</td><td>25</td><td>25</td></tr>
<tr>
<td>chown</td><td>0</td><td>6</td><td>15</td><td>15</td></tr>
<tr>
<td>grep</td><td>11</td><td>22</td><td><font color="white">45</font></td><td><font color="white">45</font></td></tr>
<tr>
<td>tail</td><td>1</td><td>7</td><td>12</td><td>13</td></tr>
<tr>
<td>df</td><td>0</td><td>10</td><td>17</td><td>18</td></tr>
<tr>
<td>top</td><td></td><td>6</td><td>12</td><td>14</td></tr>
</table></p>

<p>This table has the number of command line options for various commands for v7 Unix (1979), slackware 3.1 (1996), ubuntu 12 (2015), and ubuntu 17 (2017). Cells are darker and blue-er when they have more options (log scale) and are greyed out if no command was found.</p>

<p>We can see that the number of command line options has dramatically increased over time; entries tend to get darker going to the right (more options) and there are no cases where entries get lighter (fewer options). </p>

<p><a href="https://archive.org/details/DougMcIlroy_AncestryOfLinux_DLSLUG">McIlroy has long decried the increase in the number of options, size, and general functionality of commands</a><sup class="footnote-ref" id="fnref:M"><a rel="footnote" href="http://danluu.com/atom.xml#fn:M">1</a></sup>:</p>

<blockquote>
<p>Everything was small and my heart sinks for Linux when I see the size [inaudible]. The same utilities that used to fit in eight k[ilobytes] are a meg now. And the manual page, which used to really fit on, which used to really be a manual <em>page</em>, is now a small volume with a thousand options... We used to sit around in the UNIX room saying &quot;what can we throw out? Why is there this option?&quot; It's usually, it's often because there's some deficiency in the basic design -- you didn't really hit the right design point. Instead of putting in an option, figure out why, what was forcing you to add that option. This viewpoint, which was imposed partly because there was very small hardware ... has been lost and we're not better off for it.</p>
</blockquote>

<p>Ironically, one of the reasons for the rise in the number of command line options is another McIlroy dictum, &quot;Write programs to handle text streams, because that is a universal interface&quot; (see <code>ls</code> for one example of this).</p>

<p>If structured data or objects were passed around, formatting could be left to a final formatting pass. But, with plain text, the formatting and the content are intermingled; because formatting can only be done by parsing the content out, it's common for commands to add formatting options for convenience. Alternately, formatting can be done when the user leverages their knowledge of the structure of the data and encodes that knowledge into arguments to <code>cut</code>, <code>awk</code>, <code>sed</code>, etc. (also using their knowledge of how those programs handle formatting; it's different for different programs and the user is expected to, for example, <a href="https://unix.stackexchange.com/a/132322/261842">know how <code>cut -f4</code> is different from <code>awk '{ print $4 }'</code></a><sup class="footnote-ref" id="fnref:T"><a rel="footnote" href="http://danluu.com/atom.xml#fn:T">2</a></sup>). That's a lot more hassle than passing in one or two arguments to the last command in a sequence and it pushes the complexity from the tool to the user.</p>

<p>People sometimes say that they don't want to support structured data because they'd have to support multiple formats to make a universal tool, but they already have to support multiple formats to make a universal tool. Some standard commands can't read output from other commands because they use different formats, <code>wc -w</code> doesn't handle Unicode correctly, etc. Saying that &quot;text&quot; is a universal format is like saying that &quot;binary&quot; is a universal format.</p>

<p>I've heard people say that there isn't really any alternative to this kind of complexity for command line tools, but people who say that have never really tried the alternative, something like PowerShell. I have plenty of complaints about PowerShell, but passing structured data around and easily being able to operate on structured data without having to hold metadata information in my head so that I can pass the appropriate metadata to the right command line tools at that right places the pipeline isn't among my complaints<sup class="footnote-ref" id="fnref:W"><a rel="footnote" href="http://danluu.com/atom.xml#fn:W">3</a></sup>.</p>

<p>The sleight of hand that's happening when someone says that we can keep software simple and compatible by making everything handle text is the pretense that text data doesn't have a structure that needs to be parsed<sup class="footnote-ref" id="fnref:C"><a rel="footnote" href="http://danluu.com/atom.xml#fn:C">4</a></sup>. In some cases, we can just think of everything as a single space separated line, or maybe a table with some row and column separators that we specify (<a href="https://unix.stackexchange.com/a/132322/261842">with some behavior that isn't consistent across tools, of course</a>). That adds some hassle when it works, and then there are the cases where serializing data to a flat text format adds considerable complexity since the structure of data means that simple flattening requires significant parsing work to re-ingest the data in a meaningful way.</p>

<p>Another reason commands now have more options is that people have added convenience flags for functionality that could have been done by cobbling together a series of commands. These go all the way back to v7 unix, where <code>ls</code> has an option to reverse the sort order (which could have been done by passing the output to something like <code>tac</code> had they written <code>tac</code> instead of adding a special-case reverse option).</p>

<p>Over time, more convenience options have been added. For example, to pick a command that originally has zero options, <code>mv</code> can move <em>and</em> create a backup (three options; two are different ways to specify a backup, one of which takes an argument and the other of which takes zero explicit arguments and reads an implicit argument from the <code>VERSION_CONTROL</code> environment variable; one option allows overriding the default backup suffix). <code>mv</code> now also has options to never overwrite and to only overwrite if the file is newer.</p>

<p><code>mkdir</code> is another program that used to have no options where, excluding security things for SELinux or SMACK as well as help and version options, the added options are convenience flags: setting the permissions of the new directory and making parent directories if they don't exist.</p>

<p>If we look at <code>tail</code>, which originally had one option (<code>-number</code>, telling <code>tail</code> where to start), it's added both formatting and convenience options For formatting, it has <code>-z</code>, which makes the line delimiter <code>null</code> instead of a newline. Some examples of convenience options are <code>-f</code> to print when there are new changes, <code>-s</code> to set the sleep interval between checking for <code>-f</code> changes, <code>--retry</code> to retry if the file isn't accessible.</p>

<p>McIlroy says &quot;we're not better off&quot; for having added all of these options but I'm better off. I've never used some of the options we've discussed and only rarely use others, but that's the beauty of command line options -- unlike with a GUI, adding these options doesn't clutter up the interface. The manpage can get cluttered, but in the age of google and stackoverflow, I suspect many people just search for a solution to what they're trying to do without reading the manpage anyway.</p>

<p>This isn't to say there's no cost to adding options -- more options means more maintenance burden, but that's a cost that maintainers pay to benefit users, which isn't obviously unreasonable considering the ratio of maintainers to users. This is analogous to Gary Bernhardt's comment that it's reasonable to practice a talk fifty times since, if there's a three hundred person audience, the ratio of time spent watching to the talk to time spent practicing will still only be 1:6. In general, this ratio will be even more extreme with commonly used command line tools.</p>

<p>Someone might argue that all these extra options create a burden for users. That's not exactly wrong, but that complexity burden was always going to be there, it's just a question of where the burden was going to lie. If you think of the set of command line tools along with a shell as forming a language, a language where anyone can write a new method and it effectively gets added to the standard library if it becomes popular, where standards are defined by dicta like &quot;write programs to handle text streams, because that is a universal interface&quot;, the language was always going to turn into a write-only incoherent mess when taken as a whole. At least with tools that bundle up more functionality and options than is UNIX-y users can replace a gigantic set of wildly inconsistent tools with a merely large set of tools that, while inconsistent with each other, may have some internal consistency.</p>

<p>McIlroy implies that the problem is that people didn't think hard enough, the old school UNIX mavens would have sat down in the same room and thought longer and harder until they came up with a set of consistent tools that has &quot;unusual simplicity&quot;. But that was never going to scale, the philosophy made the mess we're in inevitable. It's not a matter of not thinking longer or harder; it's a matter of having a philosophy that cannot scale unless you have a relatively small team with a shared cultural understanding, able to to sit down in the same room.</p>

<p>If anyone can write a tool and the main instruction comes from &quot;the unix philosophy&quot;, people will have different opinions about what &quot;<a href="https://twitter.com/hillelogram/status/1174714902151421952">simplicity</a>&quot; or &quot;doing one thing&quot;<sup class="footnote-ref" id="fnref:P"><a rel="footnote" href="http://danluu.com/atom.xml#fn:P">5</a></sup> means, what the right way to do things is, and inconsistency will bloom, resulting in the kind of complexity you get when dealing with a wildly inconsistent language, like PHP. People make fun of PHP and javascript for having all sorts of warts and weird inconsistencies, but as a language and a standard library, any commonly used shell plus the collection of widely used *nix tools taken together is much worse and contains much more accidental complexity due to inconsistency even within a single Linux distro and there's no other way it could have turned out. If you compare across Linux distros, BSDs, Solaris, AIX, etc.,  the amount of accidental complexity that users have to hold in their heads when switching systems dwarfs PHP or javascript's incoherence. The most widely mocked programming languages are paragons of great design by comparison.</p>

<p>To be clear, I'm not saying that I or anyone else could have done better with the knowledge available in the 70s in terms of making a system that was practically useful at the time that would be elegant today. It's easy to look back and find issues with the benefit of hindsight. What I disagree with are comments from Unix mavens speaking today; comments like McIlroy's, which imply that we just forgot or don't understand the value of simplicity, or <a href="https://twitter.com/danluu/status/885214004649615360">Ken Thompson saying that C is as safe a language as any and if we don't want bugs we should just write bug-free code</a>. These kinds of comments imply that there's not much to learn from hindsight; in the 70s, we were building systems as effectively as anyone can today; five decades of collective experience, tens of millions of person-years, have taught us nothing; if we just go back to building systems like the original Unix mavens did, all will be well. I respectfully disagree.</p>

<h3 id="appendix-memory">Appendix: memory</h3>

<p>Although addressing McIlroy's complaints about binary size bloat is a bit out of scope for this, I will note that, in 2017, I bought a Chromebook that had 16GB of RAM for $300. A 1 meg binary might have been a serious problem in 1979, when a standard Apple II had 4KB. An Apple II cost $1298 in 1979 dollars, or $4612 in 2020 dollars. You can get a low end Chromebook that costs less than 1/15th as much which has four million times more memory. Complaining that memory usage grew by a factor of one thousand when a (portable!) machine that's more than an order of magnitude cheaper has four million times more memory seems a bit ridiculous.</p>

<p>I prefer slimmer software, which is why I optimized my home page down to two packets (it would be a single packet if my CDN served high-level brotli), but that's purely an aesthetic preference, something I do for fun. The bottleneck for command line tools isn't memory usage and spending time optimizing the memory footprint of a tool that takes one meg is like getting a homepage down to a single packet. Perhaps a fun hobby, but not something that anyone should prescribe.</p>

<h3 id="methodology-for-table">Methodology for table</h3>

<p>Command frequencies were sourced from public command history files on github, not necessarily representative of your personal usage. Only &quot;simple&quot; commands were kept, which ruled out things like curl, git, gcc (which has &gt; 1000 options), and wget. What's considered simple is arbitrary. <a href="https://en.wikipedia.org/wiki/Shell_builtin">Shell builtins</a>, like <code>cd</code> weren't included.</p>

<p>Repeated options aren't counted as separate options. For example, <code>git blame -C</code>, <code>git blame -C -C</code>, and <code>git blame -C -C -C</code> have different behavior, but these would all be counted as a single argument even though <code>-C -C</code> is effectively a different argument from <code>-C</code>.</p>

<p>The table counts sub-options as a single option. For example, <code>ls</code> has the following:</p>

<blockquote>
<p>--format=WORD
across -x, commas -m,  horizontal  -x,  long  -l,  single-column  -1,  verbose  -l, vertical -C</p>
</blockquote>

<p>Even though there are seven format options, this is considered to be only one option.</p>

<p>Options that are explicitly listed as not doing anything are still counted as options, e.g., <code>ls -g</code>, which reads <code>Ignored; for Unix compatibility.</code> is counted as an option.</p>

<p>Multiple versions of the same option are also considered to be one option. For example, with <code>ls</code>, <code>-A</code> and <code>--almost-all</code> are counted as a single option.</p>

<p>In cases where the manpage says an option is supposed to exist, but doesn't, the option isn't counted. For example, the v7 <code>mv</code> manpage says</p>

<blockquote>
<p>BUGS</p>

<p>If file1 and file2 lie on different file systems, mv must copy the file and delete the original.  In this case the owner name becomes that of the copying process and any linking relationship with other files is lost.</p>

<p>Mv should take <strong>-f</strong> flag, like rm, to suppress the question if the target exists and is not writable.</p>
</blockquote>

<p><code>-f</code> isn't counted as a flag in the table because the option doesn't actually exist.</p>

<p>The latest year in the table is 2017 because I wrote the first draft for this post in 2017 and didn't get around to cleaning it up until 2020.</p>

<h3 id="related">Related</h3>

<p><a href="https://blog.plover.com/Unix/tools.html">mjd on the Unix philosophy, with an aside into the mess of /usr/bin/time vs. built-in time</a>.</p>

<p><a href="https://groups.google.com/forum/m/#!topic/rec.humor.funny/Q-HG4LpW564">mjd making a joke about the proliferation of command line options in 1991</a>.</p>

<p>On HN:</p>

<blockquote>
<blockquote>
<p>p1mrx:</p>

<p><a href="https://unix.stackexchange.com/q/112125/261842">It's strange that ls has grown to 58 options, but still can't output \0-terminated filenames</a></p>

<p>As an exercise, try to sort a directory by size or date, and pass the result to xargs, while supporting any valid filename. I eventually just gave up and made my script ignore any filenames containing \n.</p>
</blockquote>

<p>whelming_wave:</p>

<p>Here you go: sort all files in the current directory by modification time, whitespace-in-filenames-safe.
The <code>printf (od -&gt; sed)' construction converts back out of null-separated characters into newline-separated, though feel free to replace that with anything accepting null-separated input. Granted,</code>sort --zero-terminated' is a GNU extension and kinda cheating, but it's even available on macOS so it's probably fine.</p>
</blockquote>

<pre><code>      printf '%b' $(
        find . -maxdepth 1 -exec sh -c '
          printf '\''%s %s\0'\'' &quot;$(stat -f '\''%m'\'' &quot;$1&quot;)&quot; &quot;$1&quot;
        ' sh {} \; | \
        sort --zero-terminated | \
        od -v -b | \
        sed 's/^[^ ]*//
      s/ *$//
      s/  */ \\/g
      s/\\000/\\012/g')
</code></pre>

<blockquote>
<p>If you're running this under zsh, you'll need to prefix it with `command' to use the system executable: zsh's builtin printf doesn't support printing octal escape codes for normally printable characters, and you may have to assign the output to a variable and explicitly word-split it.</p>

<p>This is all POSIX as far as I know, except for the sort.</p>
</blockquote>

<p><a href="https://en.wikipedia.org/wiki/The_Unix-Haters_Handbook">The Unix haters handbook</a>.</p>

<p><a href="http://www.oilshell.org/blog/2018/01/28.html">Why create a new shell</a>?</p>

<p><small>
Thanks to Leah Hanson, Hillel Wayne, Wesley Aptekar-Cassels, Mark Jason Dominus, Travis Downs, and Yuri Vishnevsky for comments/corrections/discussion.
</small></p>

<p>


</p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:M">This quote is slightly different than the version I've seen everywhere because I watched <a href="https://archive.org/details/DougMcIlroy_AncestryOfLinux_DLSLUG">the source video</a>. AFAICT, every copy of this quote that's on the internet (indexed by Bing, DuckDuckGo, or Google) is a copy of one person's transcription of the quote. There's some ambiguity because the audio is low quality and I hear something a bit different than whoever transcribed that quote heard.
 <a class="footnote-return" href="http://danluu.com/atom.xml#fnref:M"><sup>[return]</sup></a></li>
<li id="fn:T">Another example of something where the user absorbs the complexity because different commands handle formatting differently is <a href="https://blog.plover.com/Unix/tools.html">time formatting</a> -- the shell builtin <code>time</code> is, of course, inconsistent with <code>/usr/bin/time</code> and the user is expected to know this and know how to handle it.
 <a class="footnote-return" href="http://danluu.com/atom.xml#fnref:T"><sup>[return]</sup></a></li>

<li id="fn:W"><p>Just for example, you can use <code>ConvertTo-Json</code> or <code>ConvertTo-CSV</code> on any object, you <a href="https://docs.microsoft.com/en-us/powershell/scripting/samples/using-format-commands-to-change-output-view">can use cmdlets to change how properties are displayed for objects</a>, and you can write formatting configuration files that define how you prefer things to be formatted.</p>

<p>Another way to look at this is through the lens of <a href="https://en.wikipedia.org/wiki/Conway's_law">Conway's law</a>. If we have a set of command line tools that are built by different people, often not organizationally connected, the tools are going to be wildly inconsistent unless someone can define a standard and get people to adopt it. This actually works relatively well on Windows, and not just in PowerShell.</p>

<p>A common complaint about Microsoft is that they've created massive API churn, often for non-technical organizational reasons (e.g., a Sinofsky power play, like the one described in the replies to the now-deleted Tweet at <a href="https://twitter.com/stevesi/status/733654590034300929">https://twitter.com/stevesi/status/733654590034300929</a>). It's true. Even so, from the standpoint of a naive user, off-the-shelf Windows software is generally a lot better at passing non-textual data around than *nix. One thing this falls out of is Windows's embracing of non-textual data, which goes back at least to <a href="https://en.wikipedia.org/wiki/Component_Object_Model">COM</a> in 1999 (and arguably OLE and DDE, released in 1990 and 1987, respectively).</p>

<p>For example, if you copy from Foo, which supports binary formats <code>A</code> and <code>B</code>, into Bar, which supports formats <code>B</code> and <code>C</code> and you then copy from Bar into Baz, which supports <code>C</code> and <code>D</code>, this will work even though Foo and Baz have no commonly supported formats. </p>

<p>When you cut/copy something, the application basically &quot;tells&quot; the clipboard what formats it could provide data in. When you paste into the application, the destination application can request the data in any of the formats in which it's available. If the data is already in the clipboard, &quot;Windows&quot; provides it. If it isn't, Windows gets the data from the source application and then gives to the destination application and a copy is saved for some length of time in Windows. If you &quot;cut&quot; from Excel it will tell &quot;you&quot; that it has the data available in many tens of formats. This kind of system is pretty good for compatibility, although it definitely isn't simple or minimal.</p>

<p>In addition to nicely supporting many different formats and doing so for long enough that a lot of software plays nicely with this, Windows also generally has nicer clipboard support out of the box.</p>

<p>Let's say you copy and then paste a small amount of text. Most of the time, this will work like you'd expect on both Windows and Linux. But now let's say you copy some text, close the program you copied from, and then paste it. A mental model that a lot of people have is that when they copy, the data is stored in the clipboard, not in the program being copied from. On Windows, software is typically written to conform to this expectation (although, technically, users of the clipboard API don't have to do this). This is less common on Linux with X, where the correct mental model for most software is that copying stores a pointer to the data, which is still owned by the program the data was copied from, which means that paste won't work if the program is closed. When I've (informally) surveyed programmers, they're usually surprised by this if they haven't actually done copy+paste related work for an application. When I've surveyed non-programmers, they tend to find the behavior to be confusing as well as surprising.</p>

<p>The downside of having the OS effectively own the contents of the clipboard is that it's expensive to copy large amounts of data. Let's say you copy a really large amount of text, many gigabytes, or some complex object and then never paste it. You don't really want to copy that data from your program into the OS so that it can be available. Windows also handles this reasonably: applications can <a href="https://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-rdpeclip/fa309d1b-8034-44bf-b927-adfc753e69c1">provide data only on request</a> when that's deemed advantageous. In the case mentioned above, when someone closes the program, the program can decide whether or not it should push that data into the clipboard or discard it. In that circumstance, a lot of software (e.g., Excel) will prompt to &quot;keep&quot; the data in the clipboard or discard it, which is pretty reasonable.</p>

<p>It's not impossible to support some of this on Linux. For example, <a href="https://freedesktop.org/wiki/ClipboardManager/">the ClipboardManager spec</a> describes a persistence mechanism and GNOME applications generally kind of sort of support it (although <a href="https://bugzilla.gnome.org/show_bug.cgi?id=510204#c8">there are some bugs</a>) but the situation on *nix is really different from the more pervasive support Windows applications tend to have for nice clipboard behavior.</p>
 <a class="footnote-return" href="http://danluu.com/atom.xml#fnref:W"><sup>[return]</sup></a></li>

<li id="fn:C"><p>Another example of this are tools that are available on top of modern compilers. If we go back and look at McIlroy's canonical example, how proper UNIX compilers are so specialized that listings are a separate tool, we can see that this has changed even if there's still a separate tool you can use for listings. Some commonly used Linux compilers have literally thousands of options and do many things. For example, one of the many things <code>clang</code> now does is static analysis. As of this writing, <a href="https://clang.llvm.org/docs/analyzer/checkers.html#default-checkers">there are 79 normal static analysis checks and 44 experimental checks</a>. If these were separate commands (perhaps individual commands or perhaps a <code>static_analysis</code> command, they'd still rely on the same underlying compiler infrastructure and impose the same maintenance burden -- it's not really reasonable to have these static analysis tools operate on plain text and reimplement the entire compiler toolchain necessary to get the point where they can do static analysis. They could be separate commands instead of bundled into <code>clang</code>, but they'd still take a dependency on the same machinery that's used for the compiler and either impose a maintenance and complexity burden on the compiler (which has to support non-breaking interfaces for the tools built on top) or they'd break all the time.</p>

<p>Just make everything text so that it's simple makes for a nice soundbite, but in reality the textual representation of the data is often not what you want if you want to do actually useful work.</p>

<p>And on clang in particular, whether you make it a monolithic command or thousands of smaller commands, clang simply does more than any compiler that existed in 1979 or even all compilers that existed in 1979 combined. It's easy to say that things were simpler in 1979 and that us modern programmers have lost our way. It's harder to actually propose a design that's actually much simpler and could really get adopted. It's impossible that such a design could maintain all of the existing functionality and configurability and be as simple as something from 1979.</p>
 <a class="footnote-return" href="http://danluu.com/atom.xml#fnref:C"><sup>[return]</sup></a></li>
<li id="fn:P">Since its inception, curl has gone from supporting 3 protocols to 40. Does that mean it does 40 things and it would be more &quot;UNIX-y&quot; to split it up into 40 separate commands? Depends on who you ask. If each protocol were its own command, created and maintained by a different person, we'd be in the same situation we are with other commands. Inconsistent command line options, inconsistent output formats despite it all being text streams, etc. Would that be closer to the simplicity McIlroy advocates for? Depends on who you ask.
 <a class="footnote-return" href="http://danluu.com/atom.xml#fnref:P"><sup>[return]</sup></a></li>
</ol>
</div></p>
<p>
<em><a href="https://danluu.com/cli-complexity/">March 03, 2020 12:00 AM</a></em>
</p>





<h2>March 01, 2020</h2>




<hr><h3 class="post"><a href="https://blog.separateconcerns.com" title="Separate Concerns">Pierre Chapuis (catwell)</a></h3>


<h4><a href="https://blog.separateconcerns.com/2020-03-01-tools.html">Tools</a></h4>
<p>
</p>
<p>
<em><a href="https://blog.separateconcerns.com/2020-03-01-tools.html">March 01, 2020 06:00 PM</a></em>
</p>





<h2>February 29, 2020</h2>




<hr><h3 class="post"><a href="http://shape-of-code.coding-guidelines.com" title="The Shape of Code">Derek Jones (derek-jones)</a></h3>


<h4><a href="http://shape-of-code.coding-guidelines.com/2020/02/29/source-code-chapter-of-evidence-based-software-engineering-reworked/">Source code chapter of ‘evidence-based software engineering’ reworked</a></h4>
<p>
The Source code chapter of my evidence-based software engineering book has been reworked (draft pdf). When writing the first version of this chapter, I was not certain whether source code was a topic warranting a chapter to itself, in an evidence-based software engineering book. Now I am certain. Source code is the primary product delivery, [&#8230;]</p>
<p>
<em><a href="http://shape-of-code.coding-guidelines.com/2020/02/29/source-code-chapter-of-evidence-based-software-engineering-reworked/">February 29, 2020 10:33 PM</a></em>
</p>









<hr><h3 class="post"><a href="https://j11g.com" title="Jan van den Berg">Jan van den Berg (j11g)</a></h3>


<h4><a href="https://j11g.com/2020/02/29/surely-youre-joking-mr-feynman-ralph-leighton-and-richard-feynman/">Surely You’re Joking, Mr. Feynman! – Ralph Leighton and Richard Feynman</a></h4>
<p>
<p>The next day I rolled up my picture, put it in the back of my station wagon, and my wife Gweneth wished me good luck as I set out to visit the brothels of Pasadena to sell my drawing. Richard Feynman Well, I definitely wasn&#8217;t expecting such sentences in this collection of anecdotes from famous [&#8230;]</p>
<p>The post <a rel="nofollow" href="https://j11g.com/2020/02/29/surely-youre-joking-mr-feynman-ralph-leighton-and-richard-feynman/">Surely You&#8217;re Joking, Mr. Feynman! &#8211; Ralph Leighton and Richard Feynman</a> appeared first on <a rel="nofollow" href="https://j11g.com">Jan van den Berg</a>.</p></p>
<p>
<em><a href="https://j11g.com/2020/02/29/surely-youre-joking-mr-feynman-ralph-leighton-and-richard-feynman/">February 29, 2020 02:09 PM</a></em>
</p>





<h2>February 26, 2020</h2>




<hr><h3 class="post"><a href="https://www.geeklan.co.uk" title="GeekLAN">Sevan Janiyan (sevan)</a></h3>


<h4><a href="https://www.geeklan.co.uk/?p=2457">Full name of root account in BSD</a></h4>
<p>
NetBSD now has a users(7) and groups(7) manual. Looking into what entries existed in the passwdand groupfiles I wondered about root&#8217;s full name who we now know as Charlie Root in the BSDs. Root was called Ernie Co-vax in 3BSD. An Ernie Kovacs also shows up in adduser(8). The 4.4BSD System Manager&#8217;s Manual mentions &#8220;at Berkeley we have &#8230; <p class="link-more"><a href="https://www.geeklan.co.uk/?p=2457" class="more-link">Continue reading<span class="screen-reader-text"> "Full name of root account in BSD"</span></a></p></p>
<p>
<em><a href="https://www.geeklan.co.uk/?p=2457">February 26, 2020 10:44 PM</a></em>
</p>









<hr><h3 class="post"><a href="https://atilaoncode.blog" title="Átila on Code">Átila on Code (atilaneves)</a></h3>


<h4><a href="">Seriously, just use D to call C from Python</a></h4>
<p>
Last week I suggested that if you want to call C code from Python that you should use D. I still think that 4 lines of code (two of which are header includes) and a build system is hard to beat if that indeed is your goal. The internet, of course, had different ideas. I [&#8230;]</p>
<p>
<em><a href="">February 26, 2020 02:49 PM</a></em>
</p>





<h2>February 23, 2020</h2>




<hr><h3 class="post"><a href="http://shape-of-code.coding-guidelines.com" title="The Shape of Code">Derek Jones (derek-jones)</a></h3>


<h4><a href="http://shape-of-code.coding-guidelines.com/2020/02/23/the-wisdom-of-the-ancients/">The wisdom of the ancients</a></h4>
<p>
The software engineering ancients are people like Halstead and McCabe, along with less well known ancients (because they don&#8217;t name anything after them) such as Boehm for cost estimation, Lehman for software evolution, and Brooks because of a book; these ancients date from before 1980. Why is the wisdom of these ancients still venerated (i.e., [&#8230;]</p>
<p>
<em><a href="http://shape-of-code.coding-guidelines.com/2020/02/23/the-wisdom-of-the-ancients/">February 23, 2020 08:51 PM</a></em>
</p>





<h2>February 22, 2020</h2>




<hr><h3 class="post"><a href="https://www.jeremymorgan.com/tags/programming/" title="programming on Jeremy Morgan :: Tech Blog">Jeremy Morgan (JeremyMorgan)</a></h3>


<h4><a href="http://feedproxy.google.com/~r/JeremyMorganProgramming/~3/C4_2JP1Bj3M/">Stop Fearing the Whiteboard. Conquer It.</a></h4>
<p>
It&rsquo;s time we stopped fearing, complaining, and arguing about whiteboard coding interviews.
With a solid plan, a little skilling up, and some practice, you can master the whiteboard interview. We can argue for days about the validity of this type of interview, but the fact is many organizations require it. So are you going to let this obstacle stop you from getting the job you want? Of course not. Let&rsquo;s tackle the whiteboard interview, and defeat it.</p>
<p>
<em><a href="http://feedproxy.google.com/~r/JeremyMorganProgramming/~3/C4_2JP1Bj3M/">February 22, 2020 12:00 AM</a></em>
</p>





<h2>February 21, 2020</h2>




<hr><h3 class="post"><a href="https://j11g.com" title="Jan van den Berg">Jan van den Berg (j11g)</a></h3>


<h4><a href="https://j11g.com/2020/02/21/infinite-jest-david-foster-wallace/">Infinite Jest – David Foster Wallace</a></h4>
<p>
<p>Today is February 21st, David Foster Wallace&#8216;s birthday. So it&#8217;s rather fitting that today I finished reading his magnum opus: Infinite Jest. The notoriously long and difficult book from 1996 with visionary insights on modern life. Infinite Jest is one of the biggest books ever written, and it certainly is the biggest book I have [&#8230;]</p>
<p>The post <a rel="nofollow" href="https://j11g.com/2020/02/21/infinite-jest-david-foster-wallace/">Infinite Jest &#8211; David Foster Wallace</a> appeared first on <a rel="nofollow" href="https://j11g.com">Jan van den Berg</a>.</p></p>
<p>
<em><a href="https://j11g.com/2020/02/21/infinite-jest-david-foster-wallace/">February 21, 2020 03:38 PM</a></em>
</p>





<h2>February 20, 2020</h2>




<hr><h3 class="post"><a href="https://spacetime.dev/" title="spacetime.dev">Awn Umar (awn)</a></h3>


<h4><a href="https://spacetime.dev/plausibly-deniable-encryption">plausibly deniable encryption</a></h4>
<p>
</p>
<p>
<em><a href="https://spacetime.dev/plausibly-deniable-encryption">February 20, 2020 12:00 AM</a></em>
</p>





<h2>February 19, 2020</h2>




<hr><h3 class="post"><a href="http://brooker.co.za/blog/" title="Marc Brooker's Blog">Marc Brooker (mjb)</a></h3>


<h4><a href="http://brooker.co.za/blog/2020/02/19/firecracker.html">Firecracker: Lightweight Virtualization for Serverless Applications</a></h4>
<p>
<h1>Firecracker: Lightweight Virtualization for Serverless Applications</h1>

<p class="meta">Our second paper for NSDI'20.</p>


<p>In 2018, we announced <a href="https://firecracker-microvm.github.io/">Firecracker</a>, an <a href="https://github.com/firecracker-microvm/firecracker">open source</a> VMM optimized for multi-tenant serverless and container workloads. We heard some interest from the research community, and in response wrote up our reasoning behind building Firecracker, and how its used inside AWS Lambda.</p>

<p>That paper was accepted to NSDI'20, and is <a href="https://www.amazon.science/publications/firecracker-lightweight-virtualization-for-serverless-applications">available here</a>. Here's the abstract:</p>

<blockquote><p>Serverless containers and functions are widely used for deploying and managing software in the cloud. Their popularity is due to reduced cost of operations, improved utilization of hardware, and faster scaling than traditional deployment methods. The economics and scale of serverless applications demand that workloads from multiple customers run on the same hardware with minimal overhead, while preserving strong security and performance isolation. The traditional view is that there is a choice between virtualization with strong security and high overhead, and container technologies with weaker security and minimal overhead. This tradeoff is unacceptable to public infrastructure providers, who need both strong security and minimal overhead. To meet this need, we developed Fire-cracker, a new open source Virtual Machine Monitor (VMM)specialized for serverless workloads, but generally useful for containers, functions and other compute workloads within a reasonable set of constraints. We have deployed Firecracker in two publically available serverless compute services at Amazon Web Services (Lambda and Fargate), where it supports millions of production workloads, and trillions of requests per month. We describe how specializing for serverless in-formed the design of Firecracker, and what we learned from seamlessly migrating Lambda customers to Firecracker.</p></blockquote>

<p>Like any project the size of Firecracker, it was developed by a team of people from vision to execution. I played only a small role in that, but it's been great to work with the team (and the community) on getting Firecracker out, adding features, and using it in production at pretty huge scale.</p>

<p>Firecracker is a little bit unusual among software projects of having an explicit goal of being simple and well-suited for a relatively small number of tasks. That doesn't mean it's simplistic. Choosing what to do, and what not to do, was some of the most interesting decisions to be made in it's development. I'm particularly proud of how well the team made those decisions, and continues to make them.</p></p>
<p>
<em><a href="http://brooker.co.za/blog/2020/02/19/firecracker.html">February 19, 2020 12:00 AM</a></em>
</p>





<h2>February 18, 2020</h2>




<hr><h3 class="post"><a href="https://danluu.com/atom/index.xml" title="Dan Luu">Dan Luu (dl)</a></h3>


<h4><a href="https://danluu.com/discontinuities/">Suspicious discontinuities</a></h4>
<p>
<p>If you read any personal finance forums late last year, there's a decent chance you ran across a question from someone who was desperately trying to lose money before the end of the year. There are a number of ways someone could do this; one commonly suggested scheme was to buy <a href="https://en.wikipedia.org/wiki/Put_option">put options that were expected to expire worthless</a>, allowing the buyer to (probably) take a loss.</p>

<p>One reason people were looking for ways to lose money was that, in the U.S., there's <a href="https://en.wikipedia.org/wiki/Patient_Protection_and_Affordable_Care_Act#Subsidy_Cliff_at_400%_FPL">a hard income cutoff for a health insurance subsidy</a> at $48,560 for individuals (higher for larger households; $100,400 for a family of four). There are a number of factors that can cause the details to vary (age, location, household size, type of plan), but across all circumstances, it wouldn't have been uncommon for an individual going from one side of the cut-off to the other to have their health insurance cost increase by roughly $7200/yr. That means if an individual buying ACA insurance was going to earn $55k, they'd be better off reducing their income by $6440 and getting under the $48,560 subsidy ceiling than they are earning $55k.</p>

<p>Although that's an unusually severe example, <a href="http://www.cbo.gov/sites/default/files/cbofiles/attachments/11-15-2012-MarginalTaxRates.pdf">U.S. tax policy is full of discontinuities that disincentivize increasing earnings and, in some cases, actually incentivize decreasing earnings</a>. Some other discontinuities are the <a href="https://en.wikipedia.org/wiki/Temporary_Assistance_for_Needy_Families">TANF</a> income limit, the <a href="https://en.wikipedia.org/wiki/Medicaid">Medicaid</a> income limit, the <a href="https://en.wikipedia.org/wiki/Children%27s_Health_Insurance_Program">CHIP</a> income limit for free coverage, and the CHIP income limit for reduced-cost coverage. These vary by location and circumstance; the TANF and Medicaid income limits fall into ranges generally considered to be &quot;low income&quot; and the CHIP limits fall into ranges generally considered to be &quot;middle class&quot;. These subsidy discontinuities have the same impact as the ACA subsidy discontinuity -- at certain income levels, people are incentivized to lose money.</p>

<blockquote>
<p>Anyone may arrange his affairs so that his taxes shall be as low as possible; he is not bound to choose that pattern which best pays the treasury. There is not even a patriotic duty to increase one's taxes. Over and over again the Courts have said that there is nothing sinister in so arranging affairs as to keep taxes as low as possible. Everyone does it, rich and poor alike and all do right, for nobody owes any public duty to pay more than the law demands.</p>
</blockquote>

<p>If you agree with the famous <a href="https://en.wikipedia.org/wiki/Learned_Hand">Learned Hand</a> quote then losing money in order to reduce effective tax rate, increasing disposable income, is completely legitimate behavior at the individual level. However, a tax system that encourages people to lose money, perhaps by funneling it to (on average) much wealthier options traders by buying put options, seems sub-optimal.</p>

<p>A simple fix for the problems mentioned above would be to have slow phase-outs instead of sharp thresholds. Slow phase-outs are actually done for some subsidies and, while that can also have problems, they are typically less problematic than introducing a sharp discontinuity in tax/subsidy policy.</p>

<p>In this post, we'll look at a variety of discontinuities.</p>

<h3 id="hardware-or-software-queues">Hardware or software queues</h3>

<p>A naive queue has discontinuous behavior. If the queue is full, new entries are dropped. If the queue isn't full, new entries are not dropped. Depending on your goals, this can often have impacts that are non-ideal. For example, in networking, a naive queue might be considered &quot;unfair&quot; to bursty workloads that have low overall bandwidth utilization because workloads that have low bandwidth utilization &quot;shouldn't&quot; suffer more drops than workloads that are less bursty but use more bandwidth (this is also arguably not unfair, depending on what your goals are).</p>

<p>A class of solutions to this problem are <a href="https://en.wikipedia.org/wiki/Random_early_detection">random early drop</a> and its variants, which gives incoming items a probability of being dropped which can be determined by queue fullness (and possibly other factors), smoothing out the discontinuity and mitigating issues caused by having a discontinuous probability of queue drops.</p>

<p><a href="http://danluu.com/randomize-hn/">This post on voting in link aggregators</a> is fundamentally the same idea although, in some sense, the polarity is reversed. There's a very sharp discontinuity in how much traffic something gets based on whether or not it's on the front page. You could view this as a link getting dropped from a queue if it only receives N-1 votes and not getting dropped if it receives N votes.</p>

<h3 id="college-admissions-and-pell-grant-recipients-https-www-insidehighered-com-admissions-article-2019-01-28-study-pressure-enroll-more-pell-eligible-students-has-skewed-colleges"><a href="https://www.insidehighered.com/admissions/article/2019/01/28/study-pressure-enroll-more-pell-eligible-students-has-skewed-colleges">College admissions and Pell Grant recipients</a></h3>

<p><a href="https://en.wikipedia.org/wiki/Pell_Grant">Pell Grants</a> started getting used as a proxy for how serious schools are about helping/admitting low-income students. The first order impact is that students above the Pell Grant threshold had a significantly reduced probability of being admitted while students below the Pell Grant threshold had a significantly higher chance of being admitted. Phrased that way, it sounds like things are working as intended.</p>

<p>However, when we look at what happens within each group, we see outcomes that are the opposite of what we'd want if the goal is to benefit students from low income families. Among people who don't qualify for a Pell Grant, it's those with the lowest income who are the most severely impacted and have the most severely reduced probability of admission. Among people who do qualify, it's those with the highest income who are mostly likely to benefit, again the opposite of what you'd probably want if your goal is to benefit students from low income families.</p>

<p>We can see these in the graphs below, which are histograms of parental income among students at two universities in 2008 (first graph) and 2016 (second graph), where the red line indicates the Pell Grant threshold.</p>

<p><img src="http://danluu.com/images/discontinuities/pell-2008.jpg" alt="Histogram of income distribution of students at two universities in 2008; high incomes are highly overrepresented relative to the general population, but the distribution is smooth" height="816" width="1056" /></p>

<p><img src="http://danluu.com/images/discontinuities/pell-2016.jpg" alt="Histogram of income distribution of students at two universities in 2016; high incomes are still highly overrepresented, there's also a sharp discontinuity at the Pell grant threshold; plot looks roughly two upwards sloping piecewise linear functions, with a drop back to nearly 0 at the discontinuity at the Pell grant threshold" height="816" width="1056" /></p>

<p>A second order effect of universities optimizing for Pell Grant recipients is that savvy parents can do the same thing that some people do to cut their taxable income at the last minute. Someone might put money into a traditional IRA instead of a Roth IRA and, if they're at their IRA contribution limit, they can try to lose money on options, effectively transferring money to options traders who are likely to be wealthier than them, in order to bring their income below the Pell Grant threshold, increasing the probability that their children will be admitted to a selective school.</p>

<h3 id="election-statistics-https-arxiv-org-pdf-1410-6059-pdf"><a href="https://arxiv.org/pdf/1410.6059.pdf">Election statistics</a></h3>

<p>The following histograms of Russian elections across polling stations shows curious spikes in turnout and results at nice, round, numbers (e.g., 95%) starting around 2004. This appears to indicate that there's election fraud via fabricated results and that at least some of the people fabricating results don't bother with fabricating results that have a smooth distribution.</p>

<p><img src="http://danluu.com/images/discontinuities/russian-elections.png" height="1418" width="1822" /></p>

<p>For finding fraudulent numbers, also see, <a href="https://en.wikipedia.org/wiki/Benford%27s_law">Benford's law</a>.</p>

<h3 id="p-values-https-en-wikipedia-org-wiki-p-value"><a href="https://en.wikipedia.org/wiki/P-value">p-values</a></h3>

<p>Authors of psychology papers are incentivized to produce papers with <a href="https://en.wikipedia.org/wiki/P-value">p values</a> below some threshold, usually 0.05, but sometimes 0.1 or 0.01. <a href="https://www.ncbi.nlm.nih.gov/pubmed/22853650">Masicampo et al. plotted p values from papers published in three psychology journals</a> and found a curiously high number of papers with p values just below 0.05.</p>

<p><img src="http://danluu.com/images/discontinuities/p-value.png" alt="Histogram of published p-values; spike at p=0.05" height="1000" width="1874" /></p>

<p>The spike at p = 0.05 consistent with a number of hypothesis that aren't great, such as:</p>

<ul>
<li>Authors are fudging results to get p = 0.05</li>
<li>Journals are much more likely to accept a paper with p = 0.05 than if p = 0.055</li>
<li>Authors are much less likely to submit results if p = 0.055 than if p = 0.05</li>
</ul>

<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4359000/">Head et al. (2015)</a> surveys the evidence across a number of fields.</p>

<p>Andrew Gelman and others have been campaigning to get rid of the idea of statistical significance and p-value thresholds for years, <a href="https://stat.columbia.edu/~gelman/research/unpublished/abandon.pdf">see this paper for a short summary of why</a>. Not only would this reduce the incentive for authors to cheat on p values, there are other reasons to not want a bright-line rule to determine if something is &quot;significant&quot; or not.</p>

<h3 id="drug-charges-http-econweb-umd-edu-tuttle-files-tuttle-mandatory-minimums-pdf"><a href="http://econweb.umd.edu/~tuttle/files/tuttle_mandatory_minimums.pdf">Drug charges</a></h3>

<p>The top two graphs in this set of four show histograms of the amount of cocaine people were charged with possessing before and after the passing of the Fair Sentencing Act in 2010, which raised the amount of cocaine necessary to trigger the 10-year mandatory minimum prison sentence for possession from 50g to 280g. There's a relatively smooth distribution before 2010 and a sharp discontinuity after 2010.</p>

<p>The bottom-left graph shows the sharp spike in prosecutions at 280 grams followed by what might be a drop in 2013 after evidentiary standards were changed<sup class="footnote-ref" id="fnref:R"><a rel="footnote" href="http://danluu.com/atom.xml#fn:R">1</a></sup>.</p>

<p><img src="http://danluu.com/images/discontinuities/cocaine-280.png" height="1118" width="1408" /></p>

<h3 id="birth-month-and-sports">Birth month and sports</h3>

<p>These are scatterplots of football (soccer) players in the <a href="https://en.wikipedia.org/wiki/UEFA_Youth_League">UEFA Youth League</a>. The x-axis on both of these plots is how old players are modulo the year, i.e., their birth month normalized from 0 to 1.</p>

<p>The graph on the left is a histogram, which shows that there is a very strong relationship between where a person's birth falls within the year and their odds of making a club at the UEFA Youth League (U19) level. The graph on the right purports to show that birth time is only weakly correlated with actual value provided on the field. The authors use playing time as a proxy for value, presumably because it's easy to measure. That's not a great measure, but the result they find (younger-within-the-year players have higher value, conditional on making the U19 league) is consistent with other studies on sports and discrimination, which ind (for example) that <a href="https://danluu.com/tech-discrimination/">black baseball players were significantly better than white baseball players for decades after desegregation in baseball, French-Canadian defensemen are also better than average (French-Canadians are stereotypically afraid to fight, don't work hard enough, and are too focused on offense)</a>.</p>

<p>The discontinuity isn't directly shown in the graphs above because the graphs only show birth date for one year. If we were to plot birth date by cohort across multiple years, we'd expect to see a sawtooth pattern in the probability that a player makes it into the UEFA youth league with a 10x difference between someone born one day before vs. after the threshold.</p>

<p><img src="http://danluu.com/images/discontinuities/u19-age.png" height="1030" width="1758" /></p>

<p>This phenomenon, that birth day or month is a good predictor of participation in higher-level youth sports as well as pro sports, has been studied across a variety of sports.</p>

<p>It's generally believed that this is caused by a discontinuity in youth sports:</p>

<ol>
<li>Kids are bucketed into groups by age in years and compete against people in the same year</li>
<li>Within a given year, older kids are stronger, faster, etc., and perform better</li>
<li>This causes older-within-year kids to outcompete younger kids, which later results in older-within-year kids having higher levels of participation for a variety of reasons</li>
</ol>

<p>This is arguably a &quot;bug&quot; in how youth sports works. But <a href="http://danluu.com/bad-decisions/">as we've seen in baseball</a> <a href="http://danluu.com/tech-discrimination/">as well as a survey of multiple sports</a>, obviously bad decision making that costs individual teams tens or even hundreds of millions of dollars can persist for decades in the face of people pubicly discussing how bad the decisions are. In this case, the youth sports teams aren't feeder teams to pro teams, so they don't have a financial incentive to select players who are skilled for their age (as opposed to just taller and faster because they're slightly older) so this system-wide non-optimal even more difficult to fix than pro sports teams making locally non-optimal decisions that are completely under their control.</p>

<h3 id="high-school-exit-exam-scores-danluu-com-matura-2013-pdf"><a href="http://danluu.com/matura-2013.pdf">High school exit exam scores</a></h3>

<p>This is a histogram of high school exit exam scores from the Polish language exam. We can see that a curiously high number of students score 30 or just above thirty while curiously low number of students score from 23-29. This is from 2013; other years I've looked at (2010-2012) show a similar discontinuity.</p>

<p>Math exit exam scores don't exhibit any unusual discontinuities in the years I've examined (2010-2013).</p>

<p><img src="http://danluu.com/images/discontinuities/matura-polish-2013.png" height="772" width="1416" /></p>

<p><a href="https://www.reddit.com/r/dataisbeautiful/comments/1bqf9r/unusual_distributions_of_scores_on_final/c994zxt/">An anonymous reddit commenter explains this</a>:</p>

<blockquote>
<p>When a teacher is grading matura (final HS exam), he/she doesn't know whose test it is. The only things that are known are: the number (code) of the student and the district which matura comes from (it is usually from completely different part of Poland). The system is made to prevent any kind of manipulation, for example from time to time teachers supervisor will come to check if test are graded correctly. I don't wanna talk much about system flaws (and advantages), it is well known in every education system in the world where final tests are made, but you have to keep in mind that there is a key, which teachers follow very strictly when grading.</p>

<p>So, when a score of the test is below 30%, exam is failed. However, before making final statement in protocol, a commision of 3 (I don't remember exact number) is checking test again. This is the moment, where difference between humanities and math is shown: teachers often try to find a one (or a few) missing points, so the test won't be failed, because it's a tragedy to this person, his school and somewhat fuss for the grading team. Finding a &quot;missing&quot; point is not that hard when you are grading writing or open questions, which is a case in polish language, but nearly impossible in math. So that's the reason why distribution of scores is so different.</p>
</blockquote>

<p>As with p values, having a bright-line threshold, causes curious behavior. In this case, scoring below 30 on any subject (a 30 or above is required in every subject) and failing the exam has arbitrary negative effects for people, so teachers usually try to prevent people from failing if there's an easy way to do it, but a deeper root of the problem is the idea that it's necessary to produce a certification that's the discretization of a continuous score.</p>

<h3 id="procurement-auctions-http-www-keikawai-com-full-0804-pdf"><a href="http://www.keikawai.com/Full_0804.pdf">Procurement auctions</a></h3>

<p>Kawai et al. looked at Japanese government procurement, in order to find suspicious pattern of bids like the ones described in <a href="https://www.nber.org/papers/w4013">Porter et al. (1993)</a>, which looked at collusion in procurement auctions on Long Island (in New York in the United States). One example that's given is:</p>

<blockquote>
<p>In February 1983, the New York State Department of Transportation (DoT) held a pro- curement auction for resurfacing 0.8 miles of road. The lowest bid in the auction was $4 million, and the DoT decided not to award the contract because the bid was deemed too high relative to its own cost estimates. The project was put up for a reauction in May 1983 in which all the bidders from the initial auction participated. The lowest bid in the reauction was 20% higher than in the initial auction, submitted by the previous low bidder. Again, the contract was not awarded. The DoT held a third auction in February 1984, with the same set of bidders as in the initial auction. The lowest bid in the third auction was 10% higher than the second time, again submitted by the same bidder. The DoT apparently thought this was suspicious: “It is notable that the same firm submitted the low bid in each of the auctions. Because of the unusual bidding patterns, the contract was not awarded through 1987.”</p>
</blockquote>

<p>It could be argued that this is expected because different firms have different cost structures, so the lowest bidder in an auction for one particular project should be expected to be the lowest bidder in subsequent auctions for the same project. In order to distinguish between collusion and real structural cost differences between firms, Kawai et al. (2015) looked at auctions where the difference in bid between the first and second place firms was very small, making the winner effectively random.</p>

<p>In the auction structure studied, bidders submit a secret bid. If the secret bid is above a secret minimum, then the lowest bidder wins the auction and gets the contract. If not, the lowest bid is revealed to all bidders and another round of bidding is done. Kawai et al. found that, in about 97% of auctions, the bidder who submitted the lowest bid in the first round also submitted the lowest bid in the second round (the probability that the second lowest bidder remains second lowest was 26%).</p>

<p>Below, is a histogram of the difference in first and second round bids between the first-lowest and second-lowest bidders (left column) and the second-lowest and third-lowest bidders (right column). Each row has a different filtering criteria for how close the auction has to be in order to be included. In the top row, all auctions that reached the third round were included; in second, and third rows, the normalized delta between the first and second biders was less than 0.05 and 0.01, respectively; in the last row, the normalized delta between the first and the third bidder was less than 0.03. All numbers are normalized because the absolute size of auctions can vary.</p>

<p><img src="http://danluu.com/images/discontinuities/jp-procurement-bidding.png" height="1446" width="1682" /></p>

<p>We can see that the distributions of deltas between the first and second round are roughly symmetrical when comparing second and third lowest bidders. But when comparing first and second lowest bidders, there's a sharp discontinuity at zero, indicating that second-lowest bidder almost never lowers their bid by more than the first-lower bidder did. If you read the paper, you can see that the same structure persists into auctions that go into a third round.</p>

<p>I don't mean to pick on Japanese procurement auctions in particular. There's an extensive literature on procurement auctions that's found collusion in many cases, often much more blatant than the case presented above (e.g., there are a few firms and they round-robin who wins across auctions, or there are a handful of firms and every firm except for the winner puts in the same losing bid).</p>

<h3 id="restaurant-inspection-https-iquantny-tumblr-com-post-76928412519-think-nyc-restaurant-grading-is-flawed-heres-scores-http-datafra-me-blog-calling-out-nyc-restaurant-violations"><a href="https://iquantny.tumblr.com/post/76928412519/think-nyc-restaurant-grading-is-flawed-heres">Restaurant inspection</a> <a href="http://datafra.me/blog/Calling-out-NYC-restaurant-violations">scores</a></h3>

<p>The histograms below show a sharp discontinuity between 13 and 14, which is the difference between an A grade and a B grade. It appears that some regions also have a discontinuity between 27 and 28, which is the difference between a B and a C and <a href="https://iquantny.tumblr.com/post/76928412519/think-nyc-restaurant-grading-is-flawed-heres">this older analysis from 2014</a> found what appears to be a similar discontinuity between B and C grades.</p>

<p><img src="http://danluu.com/images/discontinuities/nyc-restaurant-inspections.png" height="900" width="1260" /></p>

<p>Inspectors have discretion in what violations are tallied and it appears that there are cases where restaurant are nudged up to the next higher grade.</p>

<h3 id="marathon-finishing-times-https-faculty-chicagobooth-edu-devin-pope-research-pdf-website-marathons-pdf"><a href="https://faculty.chicagobooth.edu/devin.pope/research/pdf/Website_Marathons.pdf">Marathon finishing times</a></h3>

<p>A histogram of marathon finishing times (finish times on the x-axis, count on the y-axis) across 9,789,093 finishes shows noticeable discontinuities at every half hour, as well as at &quot;round&quot; times like :10, :15, and :20.</p>

<p><img src="http://danluu.com/images/discontinuities/marathon-times.png" height="1094" width="1530" /></p>

<p>An analysis of times within each race (<a href="http://danluu.com/faculty.chicagobooth.edu/devin.pope/research/pdf/Website_Marathons.pdf">see section 4.4, figures 7-9</a>) indicates that this is at least partially because people speed up (or slow down less than usual) towards the end of races if they're close to a &quot;round&quot; time<sup class="footnote-ref" id="fnref:M"><a rel="footnote" href="http://danluu.com/atom.xml#fn:M">2</a></sup>.</p>

<h3 id="notes">Notes</h3>

<p>This post doesn't really have a goal or a point, it's just a collection of discontinuities that I find fun.</p>

<p>One thing that's maybe worth noting is that I've gotten a lot of mileage out in my career both out of being suspicious of discontinuities and figuring out where they come from and also out of applying standard techniques to smooth out discontinuities.</p>

<p>For finding discontinuities, basic tools like &quot;drawing a scatterplot&quot;, &quot;<a href="http://danluu.com/perf-tracing/#histogram">drawing a histogram</a>&quot;, &quot;drawing the <a href="https://en.wikipedia.org/wiki/Cumulative_distribution_function">CDF</a>&quot; often come in handy. Other kinds of visualizations that add temporality, like <a href="https://github.com/Netflix/flamescope">flamescope</a>, can also come in handy.</p>

<p>We <a href="http://danluu.com/atom.xml#hardware-or-software-queues">noted above that queues create a kind of discontinuity that, in some circumstances, should be smoothed out</a>. We also noted that we see similar behavior for other kinds of thresholds and that randomization can be a useful tool to smooth out discontinuities in thresholds as well. Randomization can also be used to allow for reducing quantization error when reducing precision with ML and in other applications.</p>

<p><small>Thanks to Leah Hanson, Omar Rizwan, Dmitry Belenko, Kamal Marhubi, Danny Vilea, Nick Roberts, Lifan Zeng, Wesley Aptekar-Cassels, Thomas Hauk, @BaudDev, and Michael Sullivan for comments/corrections/discussion.</small></p>

<p>Also, please feel free to <a href="https://twitter.com/danluu/status/1230595642390564866">send me other interesting discontinuities</a>!
</p>

<p>

</p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:R"><p>Most online commentary I've seen about this paper is incorrect. I've seen this paper used as evidence of police malfeasance because the amount of cocaine seized jumped to 280g. This is the opposite of what's described in the paper, where the author notes that, based on drug seizure records, amounts seized do not appear to be the cause of this change. After noting that drug seizures are not the cause, the author notes that prosecutors can charge people for amounts that are not the same as the amount seized and then notes:</p>

<blockquote>
<p>I do find bunching at 280g after 2010 in case management data from the Executive Office of the US Attorney (EOUSA). I also find that approximately 30% of prosecutors are responsible for the rise in cases with 280g after 2010, and that there is variation in prosecutor-level bunching both within and between districts. Prosecutors who bunch cases at 280g also have a high share of cases right above 28g after 2010 (the 5-year threshold post-2010) and a high share of cases above 50g prior to 2010 (the 10-year threshold pre-2010). Also, bunching above a mandatory minimum threshold persists across districts for prosecutors who switch districts. Moreover, when a “bunching” prosecutor switches into a new district, all other attorneys in that district increase their own bunching at mandatory minimums. These results suggest that the observed bunching at sentencing is specifically due to prosecutorial discretion</p>
</blockquote>

<p>This is mentioned in the abstract and then expounded on in the introduction (the quoted passage is from the introduction), so I think that most people commenting on this paper can't have read it. I've done a few surveys of comments on papers on blog posts and I generally find that, in cases where it's possible to identify this (e.g., when the post is mistitled), the vast majority of commenters can't have read the paper or post they're commenting on, but that's a topic for another post.</p>

<p>There is some evidence that something fishy may be going on in seizures (e.g., see Fig. A8.(c)), but if the analysis in the paper is correct, that impact of that is much smaller than the impact of prosecutorial discretion.</p>
 <a class="footnote-return" href="http://danluu.com/atom.xml#fnref:R"><sup>[return]</sup></a></li>
<li id="fn:M">One of the most common comments I've seen online about this graph and/or this paper is that this is due to pace runners provided by the marathon. Section 4.4 of the paper gives multiple explanations for why this cannot be the case, once again indicating that people tend to comment without reading the paper.
 <a class="footnote-return" href="http://danluu.com/atom.xml#fnref:M"><sup>[return]</sup></a></li>
</ol>
</div></p>
<p>
<em><a href="https://danluu.com/discontinuities/">February 18, 2020 12:00 AM</a></em>
</p>





<h2>February 17, 2020</h2>




<hr><h3 class="post"><a href="http://brooker.co.za/blog/" title="Marc Brooker's Blog">Marc Brooker (mjb)</a></h3>


<h4><a href="http://brooker.co.za/blog/2020/02/17/physalia.html">Physalia: Millions of Tiny Databases</a></h4>
<p>
<h1>Physalia: Millions of Tiny Databases</h1>

<p class="meta">Avoiding Hard CAP Tradeoffs</p>


<p>A few years ago, when I was still working on EBS, we started building a system called Physalia. Physalia is a custom transactional key-value store, designed to play the role of <em>configuration master</em> in the EBS architecture. Last year, we wrote a paper about Physalia, and were thrilled that it was accepted to NSDI'20.</p>

<p><a href="https://assets.amazon.science/c4/11/de2606884b63bf4d95190a3c2390/millions-of-tiny-databases.pdf">Millions of Tiny Databases</a> describes our problem and solution in detail. Here's the abstract:</p>

<blockquote><p>Starting in 2013, we set out to build a new database to act as the configuration store for a high-performance cloud block storage system Amazon EBS.
This database needs to be not only highly available, durable, and scalable but also strongly consistent. We quickly realized that the constraints on availability imposed by the CAP theorem, and the realities of operating distributed systems, meant that we didn't want one database. We wanted millions. Physalia is a transactional key-value store, optimized for use in large-scale cloud control planes, which takes advantage of knowledge of transaction patterns and infrastructure design to offer both high availability and strong consistency to millions of clients.
Physalia uses its knowledge of datacenter topology to place data where it is most likely to be available. Instead of being highly available for all keys to all clients, Physalia focuses on being extremely available for only the keys it knows each client needs, from the perspective of that client.
This paper describes Physalia in context of \amazon \ebs, and some other uses within \awsFull. We believe that the same patterns, and approach to design, are widely applicable to distributed systems problems like control planes, configuration management, and service discovery.</p></blockquote>

<p>I also wrote a post about Physalia <a href="https://www.amazon.science/blog/amazon-ebs-addresses-the-challenge-of-the-cap-theorem-at-scale">for the Amazon Science blog</a>.</p>

<p>One aspect of Physalia that I'm particular proud of is the work that we put in to correctness. We used TLA+ extensively throughout the design, and as documentation during implementation. As <a href="http://brooker.co.za/blog/2014/08/09/formal-methods.html">we've published about before</a>, TLA+ is really well suited to these kinds of systems. We also automatically generated unit tests, an approach I haven't seen used elsewhere:</p>

<blockquote><p>In addition to unit testing, we adopted a number of other testing approaches. One of those approaches was a suite of automatically-generated tests which run the Paxos implementation through every combination of packet loss and re-ordering that a node can experience. This testing approach was inspired by the TLC model checker, and helped usbuild confidence that our implementation matched the formal specification.</p></blockquote>

<p>Check out <a href="https://assets.amazon.science/c4/11/de2606884b63bf4d95190a3c2390/millions-of-tiny-databases.pdf">our paper</a> if you'd like to learn more.</p></p>
<p>
<em><a href="http://brooker.co.za/blog/2020/02/17/physalia.html">February 17, 2020 12:00 AM</a></em>
</p>





<h2>February 16, 2020</h2>




<hr><h3 class="post"><a href="http://shape-of-code.coding-guidelines.com" title="The Shape of Code">Derek Jones (derek-jones)</a></h3>


<h4><a href="http://shape-of-code.coding-guidelines.com/2020/02/16/patterns-of-regular-expression-usage-duplicate-regexs/">Patterns of regular expression usage: duplicate regexs</a></h4>
<p>
Regular expressions are widely used, but until recently they were rarely studied empirically (i.e., just theory research). This week I discovered two groups studying regular expression usage in source code. The VTLeeLab has various papers analysing 500K distinct regular expressions, from programs written in eight languages and StackOverflow; Carl Chapman and Peipei Wang have been [&#8230;]</p>
<p>
<em><a href="http://shape-of-code.coding-guidelines.com/2020/02/16/patterns-of-regular-expression-usage-duplicate-regexs/">February 16, 2020 06:41 PM</a></em>
</p>





<h2>February 15, 2020</h2>




<hr><h3 class="post"><a href="https://j11g.com" title="Jan van den Berg">Jan van den Berg (j11g)</a></h3>


<h4><a href="https://j11g.com/2020/02/15/gung-ho-turn-on-the-people-in-any-organization-ken-blanchard-sheldon-bowles/">Gung Ho! Turn On the People in Any Organization – Ken Blanchard &amp; Sheldon Bowles</a></h4>
<p>
<p>Gung Ho! is a management book written by well-know author Ken Blanchard. It was somehow never on my radar, so because of the strange title and my unfamiliarity I wasn&#8217;t expecting too much, and I only picked it up because I know Blanchard&#8217;s other famous theory. But it turned out to be a delightful, short [&#8230;]</p>
<p>The post <a rel="nofollow" href="https://j11g.com/2020/02/15/gung-ho-turn-on-the-people-in-any-organization-ken-blanchard-sheldon-bowles/">Gung Ho! Turn On the People in Any Organization &#8211; Ken Blanchard &#038; Sheldon Bowles</a> appeared first on <a rel="nofollow" href="https://j11g.com">Jan van den Berg</a>.</p></p>
<p>
<em><a href="https://j11g.com/2020/02/15/gung-ho-turn-on-the-people-in-any-organization-ken-blanchard-sheldon-bowles/">February 15, 2020 10:46 PM</a></em>
</p>









<hr><h3 class="post"><a href="http://gerikson.com/blog" title="The occasional scrivener">Gustaf Erikson (gerikson)</a></h3>


<h4><a href="http://gerikson.com/blog/books/read/Goodbye-Darkness.html"><em>Goodbye, Darkness</em> by William Manchester</a></h4>
<p>
</p>
<p>
<em><a href="http://gerikson.com/blog/books/read/Goodbye-Darkness.html">February 15, 2020 10:47 AM</a></em>
</p>











<h4><a href="http://gerikson.com/blog/books/read/Englands-Last-War.html"><em>England&#8217;s Last War Against France: Fighting Vichy 1940-42</em> by Colin Smith</a></h4>
<p>
</p>
<p>
<em><a href="http://gerikson.com/blog/books/read/Englands-Last-War.html">February 15, 2020 10:47 AM</a></em>
</p>











<h4><a href="http://gerikson.com/blog/books/read/D-Day.html"><em>D-Day</em> by Antony Beevor</a></h4>
<p>
</p>
<p>
<em><a href="http://gerikson.com/blog/books/read/D-Day.html">February 15, 2020 10:39 AM</a></em>
</p>





<h2>February 12, 2020</h2>




<hr><h3 class="post"><a href="https://defn.io/" title="defn.io">Bogdan Popa (bogdan)</a></h3>


<h4><a href="https://defn.io/2020/02/12/racket-web-server-guide/">The Missing Guide to Racket's Web Server</a></h4>
<p>
Racket&rsquo;s built-in web-server package is great, but parts of it are low-level enough that it can be confusing to people who are new to the language. In this post, I&rsquo;m going to try to clear up some of that confusion by providing some definitions and examples for things beginners might wonder about.
Servlets A servlet is a function from a request to a response. It has the contract:
1  (-&gt; request?</p>
<p>
<em><a href="https://defn.io/2020/02/12/racket-web-server-guide/">February 12, 2020 10:00 AM</a></em>
</p>





<h2>February 09, 2020</h2>




<hr><h3 class="post"><a href="https://www.ponylang.io/blog/" title="Blog on Pony">Ponylang (SeanTAllen)</a></h3>


<h4><a href="https://www.ponylang.io/blog/2020/02/last-week-in-pony---february-9-2020/">Last Week in Pony - February 9, 2020</a></h4>
<p>
<p>Pony 0.33.2 has been released! The core team is no longer maintaining the ponyc Homebrew formula, since <a href="https://github.com/ponylang/ponyup">ponyup</a> is now the officially supported installation method.</p>

<p></p></p>
<p>
<em><a href="https://www.ponylang.io/blog/2020/02/last-week-in-pony---february-9-2020/">February 09, 2020 04:29 PM</a></em>
</p>





<h2>February 08, 2020</h2>




<hr><h3 class="post"><a href="http://cfenollosa.com/blog/index.html" title="Carlos Fenollosa — Blog">Carlos Fenollosa (carlesfe)</a></h3>


<h4><a href="http://feedproxy.google.com/~r/WaitingForTheJobsToFinish/~3/HTkAR1Wz3AA/links-for-2020-02-09.html">Links for 2020-02-09</a></h4>
<p>
<h4>🐲 For Tolkien fans <a href="http://feeds.feedburner.com/WaitingForTheJobsToFinish#tolkien_faq" name="tolkien_faq" class="permalink">&#128279;</a></h4>

<p><a href="http://tolkien.slimy.com">The Tolkien Meta-FAQ</a>
(RH,
<a href="https://groups.google.com/forum/#!topic/rec.arts.books.tolkien/g3rgettx5IY">via usenet</a>)</p>

<p>Usenet FAQs used to be a great source of information. I recently found the Tolkien Meta-FAQ and it is
absolutely amazing.</p>

<h4>🎨 Mario Paint tunes <a href="http://feeds.feedburner.com/WaitingForTheJobsToFinish#mario_midis" name="mario_midis" class="permalink">&#128279;</a></h4>

<p><a href="https://www.theverge.com/2020/2/6/21122335/nintendo-mario-paint-music-composers-snes">Meet the musicians who compose in Mario Paint</a>
(5 min,
<a href="https://waxy.org/category/links/">via waxy</a>)</p>

<p>Delightfully retro.</p>

<p>PS: There is a <a href="https://www.reddit.com/r/MarioPaint/">Mario Paint subreddit</a>!</p>

<p></p>

<h4>💣 Android remote code execution via Bluetooth <a href="http://feeds.feedburner.com/WaitingForTheJobsToFinish#android_bluetooth" name="android_bluetooth" class="permalink">&#128279;</a></h4>

<p><a href="https://insinuator.net/2020/02/critical-bluetooth-vulnerability-in-android-cve-2020-0022/">Critical Bluetooth Vulnerability in Android (CVE-2020-0022)</a>
(1 min,
<a href="https://s.ovalerio.net/@dethos/103617131293927766">via @dethos@s.ovalerio.net</a>)</p>

<blockquote>
  <p>On Android 8.0 to 9.0, a remote attacker within proximity can silently execute arbitrary code [...] as long as Bluetooth is enabled.
No user interaction is required.</p>
</blockquote>

<p>I wonder if there are exploits in the wild already. Walking around a big city infecting all phones in a 10-foot radius.</p>

<h4>🤯 40 concepts for understanding the world <a href="http://feeds.feedburner.com/WaitingForTheJobsToFinish#40_concepts" name="40_concepts" class="permalink">&#128279;</a></h4>

<p><a href="https://twitter.com/G_S_Bhogal/status/1225561131122597896">In 40 tweets I will describe 40 powerful concepts for understanding the world</a>
(5 min,
<a href="https://twitter.com/paulg/status/1225770925104205826">via @paulg</a>)</p>

<blockquote>
  <p>This thread is worth reading. It's better than most popular books about ideas, and much shorter.</p>
</blockquote>

<h4>📒 What they don't teach you in CS classes  <a href="http://feeds.feedburner.com/WaitingForTheJobsToFinish#cs_missing" name="cs_missing" class="permalink">&#128279;</a></h4>

<p><a href="https://missing.csail.mit.edu">The Missing Semester of Your CS Education</a>
(RH,
<a href="https://lobste.rs/s/ti1k98/missing_semester_your_cs_education_mit">via lobste.rs</a>)</p>

<blockquote>
  <p>Over the years, we have seen that many students have limited knowledge of the tools available to them. </p>

<p>Common examples include holding the down arrow key for 30 seconds to scroll to the bottom of a large file in Vim, or using the nuclear approach to fix a Git repository (https://xkcd.com/1597/)</p>
</blockquote>

<p>This is one of the best resources I have ever linked to.</p>

<p>You <strong>must</strong> learn these skills.</p>

<p>(Self plug: my own <a href="https://cfenollosa.com/misc/workshop_unix.pdf">UNIX tools workshop slides</a>)</p>

<h4>🚂 Upscaling a 1896 film with AI  <a href="http://feeds.feedburner.com/WaitingForTheJobsToFinish#video_ai" name="video_ai" class="permalink">&#128279;</a></h4>

<p><a href="https://arstechnica.com/science/2020/02/someone-used-neural-networks-to-upscale-a-famous-1896-video-to-4k-quality/">Someone used neural networks to upscale a famous 1896 video to 4k quality</a>
(5 min,
<a href="https://news.ycombinator.com/item?id=22242478">via HN</a>)</p>

<p>We already had this capability. Only that it required an enormous effort by experienced video editors.</p>

<p>In a few years movies will be created just by feeding a script to an AI.</p>

<h4>🚗 Fake GMaps traffic jam <a href="http://feeds.feedburner.com/WaitingForTheJobsToFinish#gmaps_jam" name="gmaps_jam" class="permalink">&#128279;</a></h4>

<p><a href="http://www.simonweckert.com/googlemapshacks.html">Google Maps Hacks</a>
(5 min,
<a href="https://twitter.com/simon_deliver/status/1223569659645112320">via @simon_deliver</a>)</p>

<blockquote>
  <p>99 smartphones are transported in a handcart to generate virtual traffic jam in Google Maps.
Through this activity, it is possible to turn a green street red which has an impact in the physical world by navigating cars on another route! </p>
</blockquote>

<p>Devilishly genius!</p>

<p><img src="http://feeds.feedburner.com/img/gmaps_hacks.jpeg" /></p>

<p>Tags: <a href="http://feeds.feedburner.com/tag_roundup.html">roundup</a></p>

<!-- text end -->
<p id="twitter"><a href="http://twitter.com/intent/tweet?url=http://cfenollosa.com/blog/links-for-2020-02-09.html&text=<Type your comment here but please leave the URL so that other people can follow the comments>&via=cfenollosa">&amp;via=cfenollosa">&amp;via=cfenollosa">Comments? Tweet</a> 
<a href="https://twitter.com/search?q=http://cfenollosa.com/blog/links-for-2020-02-09.html"><span id="count-8320"></span></a>&nbsp;</p><img src="http://feeds.feedburner.com/~r/WaitingForTheJobsToFinish/~4/HTkAR1Wz3AA" height="1" width="1" alt="" /></p>
<p>
<em><a href="http://feedproxy.google.com/~r/WaitingForTheJobsToFinish/~3/HTkAR1Wz3AA/links-for-2020-02-09.html">February 08, 2020 11:48 AM</a></em>
</p>





<h2>February 07, 2020</h2>




<hr><h3 class="post"><a href="http://shape-of-code.coding-guidelines.com" title="The Shape of Code">Derek Jones (derek-jones)</a></h3>


<h4><a href="http://shape-of-code.coding-guidelines.com/2020/02/07/source-code-has-a-brief-and-lonely-existence/">Source code has a brief and lonely existence</a></h4>
<p>
The majority of source code has a short lifespan (i.e., a few years), and is only ever modified by one person (i.e., 60%). Literate programming is all well and good for code written to appear in a book that the author hopes will be read for many years, but this is a tiny sliver of [&#8230;]</p>
<p>
<em><a href="http://shape-of-code.coding-guidelines.com/2020/02/07/source-code-has-a-brief-and-lonely-existence/">February 07, 2020 01:16 PM</a></em>
</p>









<hr><h3 class="post"><a href="https://www.jeremymorgan.com/tags/programming/" title="programming on Jeremy Morgan :: Tech Blog">Jeremy Morgan (JeremyMorgan)</a></h3>


<h4><a href="http://feedproxy.google.com/~r/JeremyMorganProgramming/~3/tlAlHnkfKpc/">Become a React Developer in a Weekend</a></h4>
<p>
If you want to be a React Developer, there&rsquo;s a lot to learn. You can get started in a weekend. Yes, in a single weekend, you can learn React and start developing some cool applications!
Here&rsquo;s how I would approach it.
Friday Night Ok, instead of binge-watching some TV show Friday night (no judgment, I&rsquo;ve been there), you could spend the time learning the basics of React. If you&rsquo;ve never touched React or done anything with it, The Big Picture is the place to start.</p>
<p>
<em><a href="http://feedproxy.google.com/~r/JeremyMorganProgramming/~3/tlAlHnkfKpc/">February 07, 2020 12:00 AM</a></em>
</p>









<hr><h3 class="post"><a href="https://danluu.com/atom/index.xml" title="Dan Luu">Dan Luu (dl)</a></h3>


<h4><a href="https://danluu.com/p95-skill/">95%-ile isn't that good</a></h4>
<p>
<p>Reaching 95%-ile isn't very impressive because it's not that hard to do. I think this is one of my most ridiculable ideas. It doesn't help that, when stated nakedly, that sounds elitist. But I think it's just the opposite: most people can become (relatively) good at most things.</p>

<p>Note that when I say 95%-ile, I mean 95%-ile among people who participate, not all people (for many activities, just doing it at all makes you 99%-ile or above across all people). I'm also not referring to 95%-ile among people who practice regularly. The &quot;<a href="https://en.wikipedia.org/wiki/One_weird_trick_advertisements">one weird trick</a>&quot; is that, for a lot of activities, being something like 10%-ile among people who practice can make you something like 90%-ile or 99%-ile among people who participate.</p>

<p>This post is going to refer to specifics since <a href="https://twitter.com/danluu/status/926493613097439232">the discussions I've seen about this are all in the abstract</a>, which turns them into Rorschach tests. For example, Scott Adams has a widely cited post claiming that it's better to be a generalist than a specialist because, to become &quot;extraordinary&quot;, you have to either be &quot;the best&quot; at one thing or 75%-ile at two things. If that were strictly true, it would surely be better to be a generalist, but that's of course exaggeration and it's possible to get a lot of value out of a specialized skill without being &quot;the best&quot;; since the precise claim, as written, is obviously silly and the rest of the post is vague handwaving, discussions will inevitably devolve into people stating their prior beliefs and basically ignoring the content of the post.</p>

<p>Personally, in every activity I've participated in where it's possible to get a rough percentile ranking, people who are 95%-ile constantly make mistakes that seem like they should be easy to observe and correct. &quot;Real world&quot; activities typically can't be reduced to a percentile rating, but achieving what appears to be a similar level of proficiency seems similarly easy.</p>

<p>We'll start by looking at Overwatch (a video game) in detail because it's an activity I'm familiar with where it's easy to get ranking information and observe what's happening, and then we'll look at some &quot;real world&quot; examples where we can observe the same phenomena, although we won't be able to get ranking information for real world examples<sup class="footnote-ref" id="fnref:S"><a rel="footnote" href="http://danluu.com/atom.xml#fn:S">1</a></sup>.</p>

<h3 id="overwatch">Overwatch</h3>

<p>At 90%-ile and 95%-ile ranks in Overwatch, the vast majority of players will pretty much constantly make basic game losing mistakes. These are simple mistakes like standing next to the objective instead of on top of the objective while the match timer runs out, turning a probable victory into a certain defeat. See the attached footnote if you want enough detail about specific mistakes that you can decide for yourself if a mistake is &quot;basic&quot; or not<sup class="footnote-ref" id="fnref:O"><a rel="footnote" href="http://danluu.com/atom.xml#fn:O">2</a></sup>.</p>

<p>Some reasons we might expect this to happen are:</p>

<ol>
<li>People don't want to win or don't care about winning</li>
<li>People understand their mistakes but haven't put in enough time to fix them</li>
<li>People are untalented</li>
<li>People don't understand how to spot their mistakes and fix them</li>
</ol>

<p>In Overwatch, you may see a lot of (1), people who don’t seem to care about winning, at lower ranks, but by the time you get to 30%-ile, it's common to see people indicate their desire to win in various ways, such as yelling at players who are perceived as uncaring about victory or unskilled, complaining about people who they perceive to make mistakes that prevented their team from winning, etc.<sup class="footnote-ref" id="fnref:A"><a rel="footnote" href="http://danluu.com/atom.xml#fn:A">3</a></sup>. Other than the occasional troll, it's not unreasonable to think that people are generally trying to win when they're severely angered by losing.</p>

<p>(2), not having put in time enough to fix their mistakes will, at some point, apply to all players who are improving, but if you look at the median time played at 50%-ile, people who are stably ranked there have put in hundreds of hours (and the median time played at higher ranks is higher). Given how simple the mistakes we're discussing are, not having put in enough time cannot be the case for most players.</p>

<p>A common complaint among low-ranked Overwatch players in Overwatch forums is that they're just not talented and can never get better. Most people probably don't have the talent to play in a professional league regardless of their practice regimen, but when you can get to 95%-ile by fixing mistakes like &quot;not realizing that you should stand on the objective&quot;, you don't really need a lot of talent to get to 95%-ile.</p>

<p>While (4), people not understanding how to spot and fix their mistakes, isn't the only other possible explanation<sup class="footnote-ref" id="fnref:D"><a rel="footnote" href="http://danluu.com/atom.xml#fn:D">4</a></sup>, I believe it's the most likely explanation for most players. Most players who express frustration that they're stuck at a rank up to maybe 95%-ile or 99%-ile don't seem to realize that they could drastically improve by observing their own gameplay or having someone else look at their gameplay.</p>

<p>One thing that's curious about this is that Overwatch makes it easy to spot basic mistakes (compared to most other activities). After you're killed, the game shows you how you died from the viewpoint of the player who killed you, allowing you to see what led to your death. Overwatch also records the entire game and lets you watch a replay of the game, allowing you to figure out what happened and why the game was won or lost. In many other games, you'd have to set up recording software to be able to view a replay.</p>

<p>If you read Overwatch forums, you'll see a regular stream of posts that are basically &quot;I'm SOOOOOO FRUSTRATED! I've played this game for 1200 hours and I'm still ranked 10%-ile, [some Overwatch specific stuff that will vary from player to player]&quot;. Another user will inevitably respond with something like &quot;we can't tell what's wrong from your text, please post a video of your gameplay&quot;. In the cases where the original poster responds with a recording of their play, people will post helpful feedback that will immediately make the player much better if they take it seriously. If you follow these people who ask for help, you'll often see them ask for feedback at a much higher rank (e.g., moving from 10%-ile to 40%-ile) shortly afterwards. It's nice to see that the advice works, but it's unfortunate that so many players don't realize that watching their own recordings or posting recordings for feedback could have saved 1198 hours of frustration.</p>

<p>It appears to be common for Overwatch players (well into 95%-ile and above) to:</p>

<ul>
<li>Want to improve</li>
<li>Not get feedback</li>
<li>Improve slowly when getting feedback would make improving quickly easy</li>
</ul>

<p>Overwatch provides the tools to make it relatively easy to get feedback, but people who very strongly express a desire to improve don't avail themselves of these tools.</p>

<h3 id="real-life">Real life</h3>

<p>My experience is that other games are similar and I think that &quot;real life&quot; activities aren't so different, although there are some complications.</p>

<p>One complication is that real life activities tend not to have a single, one-dimensional, objective to optimize for. Another is that what makes someone good at a real life activity tends to be poorly understood (by comparison to games and sports) even in relation to a specific, well defined, goal.</p>

<p>Games with rating systems are easy to optimize for: your meta-goal can be to get a high rating, which can typically be achieved by increasing your win rate by fixing the kinds of mistakes described above, like not realizing that you should step onto the objective. For any particular mistake, you can even make a reasonable guess at the impact on your win rate and therefore the impact on your rating.</p>

<p>In real life, if you want to be (for example) &quot;a good speaker&quot;, that might mean that you want to give informative talks that help people learn or that you want to give entertaining talks that people enjoy or that you want to give keynotes at prestigious conferences or that you want to be asked to give talks for $50k an appearance. Those are all different objectives, with different strategies for achieving them and for some particular mistake (e.g., spending 8 minutes on introducing yourself during a 20 minute talk), it's unclear what that means with respect to your goal.</p>

<p>Another thing that makes games, at least mainstream ones, easy to optimize for is that they tend to have a lot of aficionados who have obsessively tried to figure out what's effective. This means that if you want to improve, unless you're trying to be among the top in the world, you can simply figure out what resources have worked for other people, pick one up, read/watch it, and then practice. For example, if you want to be 99%-ile in a trick-taking card game like bridge or spades (among all players, not subgroups like &quot;ACBL players with masterpoints&quot; or &quot;people who regularly attend North American Bridge Championships&quot;), you can do this by:</p>

<ul>
<li>learning the basics of the game</li>
<li>reading <a href="https://amzn.to/2sUtmsk">a beginner book on cardplay</a></li>
<li>practicing applying the material</li>
</ul>

<p>If you want to become a good speaker and you have a specific definition of “a good speaker” in mind, there still isn't an obvious path forward. Great speakers will give directly contradictory advice (e.g., avoid focusing on presentation skills vs. practice presentation skills). Relatively few people obsessively try to improve and figure out what works, which results in a lack of rigorous curricula for improving. However, this also means that it's easy to improve in percentile terms since relatively few people are trying to improve at all.</p>

<p>Despite all of the caveats above, my belief is that it's easier to become relatively good at real life activities relative to games or sports because there's so little delibrate practice put into most real life activities. Just for example, if you're a local table tennis hotshot who can beat every rando at a local bar, when you challenge someone to a game and they say &quot;sure, what's your rating?&quot; you know you're in shellacking by someone who can probably beat you while playing with a shoe brush. You're probably 99%-ile, but someone with no talent who's put in the time to practice the basics is going to have a serve that you can't return as well as be able to kill any shot a local bar expert is able to consitently hit. In most real life activities, there's almost no one who puts in a level of delibrate practice equivalent to someone who goes down to their local table tennis club and practices two hours a week, let alone someone like a top pro, who might seriously train for four hours a day.</p>

<p>To give a couple of concrete examples, I helped <a href="http://blog.leahhanson.us/speaking.html">Leah</a> prepare for talks from 2013 to 2017. The first couple practice talks she gave were about the same as you'd expect if you walked into a random talk at a large tech conference. For the first couple years she was speaking, she did something like 30 or so practice runs for each public talk, of which I watched and gave feedback on half. Her first public talk was (IMO) well above average for a talk at a large, well regarded, tech conference and her talks got better from there until she stopped speaking in 2017.</p>

<p>As we discussed above, this is more subjective than game ratings and there's no way to really determine a percentile, but if you look at how most people prepare for talks, it's not too surprising that Leah was above average. At one of the first conferences she spoke at, the night before the conference, we talked to another speaker who mentioned that they hadn't finished their talk yet and only had fifteen minutes of material (for a forty minute talk). They were trying to figure out how to fill the rest of the time. That kind of preparation isn't unusual and the vast majority of talks prepared like that aren't great.</p>

<p>Most people consider doing 30 practice runs for a talk to be absurd, a totally obsessive amount of practice, but I think Gary Bernhardt has it right when he says that, if you're giving a 30-minute talk to a 300 person audience, that's 150 person-hours watching your talk, so it's not obviously unreasonable to spend 15 hours practicing (and 30 practice runs will probably be less than 15 hours since you can cut a number of the runs short and/or repeatedly practice problem sections). One thing to note that this level of practice, considered obessive when giving a talk, still pales in comparison to the amount of time a middling table tennis club player will spend practicing.</p>

<p>If you've studied pedagogy, you might say that the help I gave to Leah was incredibly lame. It's known that having laypeople try to figure out how to improve among themselves is among the worst possible ways to learn something, good instruction is more effective and having a skilled coach or teacher give one-on-one instruction is more effective still<sup class="footnote-ref" id="fnref:C"><a rel="footnote" href="http://danluu.com/atom.xml#fn:C">5</a></sup>. That's 100% true, my help was incredibly lame. However, most people aren't going to practice a talk more than a couple times and many won't even practice a single time (I don't have great data proving this, this is from informally polling speakers at conferences I've attended). This makes Leah's 30 practice runs an extraordinary amount of practice compared to most speakers, which resulted in a relatively good outcome even though we were using one of the worst possible techniques for improvement.</p>

<p>My writing is another example. I'm not going to compare myself to anyone else, but my writing improved dramatically the first couple of years I wrote this blog just because I spent a little bit of effort on getting and taking feedback.</p>

<p>Leah read one or two drafts of almost every post and gave me feedback. On the first posts, since neither one of us knew anything about writing, we had a hard time identifying what was wrong. If I had some awkward prose or confusing narrative structure, we'd be able to point at it and say &quot;that looks wrong&quot; without being able to describe what was wrong or suggest a fix. It was like, in the era before spellcheck, when you misspelled a word and could tell that something was wrong, but every permutation you came up with was just as wrong.</p>

<p>My fix for that was to hire a professional editor whose writing I respected with the instructions &quot;I don't care about spelling and grammar fixes, there are fundamental problems with my writing that I don't understand, please explain to me what they are&quot;<sup class="footnote-ref" id="fnref:F"><a rel="footnote" href="http://danluu.com/atom.xml#fn:F">6</a></sup>. I think this was more effective than my helping Leah with talks because we got someone who's basically a professional coach involved. An example of something my editor helped us with was giving us a vocabulary we could use to discuss structural problems, the way <a href="https://amzn.to/2GPPmYE">design patterns</a> gave people a vocabulary to talk about OO design.</p>

<h3 id="back-to-this-blog-s-regularly-scheduled-topic-programming">Back to this blog's regularly scheduled topic: programming</h3>

<p>Programming is similar to the real life examples above in that it's impossible to assign a rating or calculate percentiles or anything like that, but it is still possible to make significant improvements relative to your former self without too much effort by getting feedback on what you're doing.</p>

<p>For example, <a href="https://twitter.com/danluu/status/926492239081197569">here's one thing Michael Malis did</a>:</p>

<blockquote>
<p>One incredibly useful exercise I’ve found is to watch myself program. Throughout the week, I have a program running in the background that records my screen. At the end of the week, I’ll watch a few segments from the previous week. Usually I will watch the times that felt like it took a lot longer to complete some task than it should have. While watching them, I’ll pay attention to specifically where the time went and figure out what I could have done better. When I first did this, I was really surprised at where all of my time was going.</p>

<p>For example, previously when writing code, I would write all my code for a new feature up front and then test all of the code collectively. When testing code this way, I would have to isolate which function the bug was in and then debug that individual function. After watching a recording of myself writing code, I realized I was spending about a quarter of the total time implementing the feature tracking down which functions the bugs were in! This was completely non-obvious to me and I wouldn’t have found it out without recording myself. Now that I’m aware that I spent so much time isolating which function a bugs are in, I now test each function as I write it to make sure they work. This allows me to write code a lot faster as it dramatically reduces the amount of time it takes to debug my code.</p>
</blockquote>

<p>In the past, I've spent time figuring out where time is going when I code and basically saw the same thing as in Overwatch, except instead of constantly making game-losing mistakes, I was constantly doing pointlessly time-losing things. Just getting rid of some of those bad habits has probably been at least a 2x productivity increase for me, pretty easy to measure since fixing these is basically just clawing back wasted time. For example, I noticed how I'd get distracted for N minutes if I read something on the internet when I needed to wait for two minutes, so I made sure to keep a queue of useful work to fill dead time (and if I was working on something very latency sensitive where I didn't want to task switch, I'd do nothing until I was done waiting).</p>

<p>One thing to note here is that it's important to actually track what you're doing and not just guess at what you're doing. When I've recorded what people do and compare it to what they think they're doing, these are often quite different. It would generally be considered absurd to operate a complex software system without metrics or tracing, but it's normal to operate yourself without metrics or tracing, even though you're much more complex and harder to understand than the software you work on.</p>

<p><a href="http://danluu.com/hn-comments/#what-makes-engineers-productive-https-news-ycombinator-com-item-id-5496914">Jonathan Tang has noted that choosing the right problem dominates execution speed</a>. I don't disagree with that, but doubling execution speed is still decent win that's independent of selecting the right problem to work on and I don't think that discussing how to choose the right problem can be effectively described in the abstract and the context necessary to give examples would be much longer than the already too long Overwatch examples in this post, maybe I'll write another post that's just about that.</p>

<p>Anyway, this is sort of an odd post for me to write since I think that culturally, we care a bit too much about productivity in the U.S., especially in places I've lived recently (NYC &amp; SF). But at a personal level, higher productivity doing work or chores doesn't have to be converted into more work or chores, it can also be converted into more vacation time or more time doing whatever you value.</p>

<p>And for games like Overwatch, I don't think improving is a moral imperative; there's nothing wrong with having fun at 50%-ile or 10%-ile or any rank. But in every game I've played with a rating and/or league/tournament system, a lot of people get really upset and unhappy when they lose even when they haven't put much effort into improving. If that's the case, why not put a little bit of effort into improving and spend a little bit less time being upset?</p>

<h3 id="some-meta-techniques-for-improving">Some meta-techniques for improving</h3>

<ul>
<li>Get feedback and practice

<ul>
<li>Ideally from an expert coach but, if not, this can be from a layperson or even yourself (if you have some way of recording/tracing what you're doing)</li>
</ul></li>
<li>Guided exercises or exercises with solutions

<ul>
<li>This is very easy to find in books for &quot;old&quot; games, like chess or Bridge.</li>
<li>For particular areas, you can often find series of books that have these, e.g., in math, books in the Springer Undergraduate Mathematics Series (SUMS) tend to have problems with solutions</li>
</ul></li>
</ul>

<h3 id="appendix-other-most-ridiculable-ideas">Appendix: other most ridiculable ideas</h3>

<p>Here are the ideas I've posted about that were the most widely ridiculed at the time of the post:</p>

<ul>
<li><a href="http://danluu.com/startup-tradeoffs/">It's not uncommon for programmers at trendy tech companies to make $350k/yr or more</a> (2015, stated number was $250k/yr at the time)</li>
<li><a href="http://danluu.com/monorepo/">Monorepos can be reasonable</a> (2015)</li>
<li><a href="http://danluu.com/cpu-bugs/">We should expect to see a lot more CPU bugs</a> (2016)</li>
<li><a href="http://danluu.com/tech-discrimination/">Markets are not incompatible with discrimination</a> (2014)</li>
<li><a href="http://danluu.com/input-lag/">Computers are getting slower in some ways</a> (2017)</li>
<li><a href="http://danluu.com/empirical-pl/">Empirical evidence on the benefit of types is almost non-existent</a> (2014)</li>
<li>It's reasonable to write technical posts on a subject that avoid domain-specific terminology</li>
</ul>

<p>My posts on compensation have the dubious distinction of being the posts most frequently called out both for being so obvious that they're pointless as well as  for being laughably wrong. I suspect they're also the posts that have had the largest aggregate impact on people -- I've had a double digit number of people tell me one of the compensation posts changed their life and they now make $x00,000/yr more than they used to because they know it's possible to get a much higher paying job and I doubt that I even hear from 10% of the people who make a big change as a result of learning that it's possible to make a lot more money.</p>

<p>When I wrote my first post on compensation, in 2015, I got ridiculed more for writing something obviously wrong than for writing something obvious, but the last few years things have flipped around. I still get the occasional bit of ridicule for being wrong when some corner of Twitter or a web forum that's well outside the HN/reddit bubble runs across my post, but the ratio of “obviously wrong” to “obvious” has probably gone from 20:1 to 1:5.</p>

<p>Opinions on monorepos have also seen a similar change since 2015. Outside of some folks at big companies, monorepos used to be considered obviously stupid among people who keep up with trends, but this has really changed. Not as much as opinions on compensation, but enough that I'm now a little surprised when I meet a hardline anti-monorepo-er.</p>

<p>Although it's taken longer for opinions to come around on CPU bugs, that's probably the post that now gets the least ridicule from the list above.</p>

<p>That markets don't eliminate all discrimination is the one where opinions have come around the least. Hardline &quot;all markets are efficient&quot; folks aren't really convinced by academic work like <a href="https://amzn.to/2Or7Z9k">Becker's The Economics of Discrimination</a> or summaries like <a href="http://danluu.com/tech-discrimination/">the evidence laid out in the post</a>.</p>

<p>The posts on computers having higher latency and the lack of empirical evidence of the benefit of types are the posts I've seen pointed to the most often to defend a ridicuable opinion. I didn't know when I started doing the work for either post and they both happen to have turned up evidence that's the opposite of the most common loud claims (there's very good evidence that advanced type systems improve safety in practice and of course computers are faster in every way, people who think they're slower are just indulging in nostalgia). I don't know if this has changed many opinion. However, I haven't gotten much direct ridicule for either post even though both posts directly state a position I see commonly ridiculed online. I suspect that's partially because both posts are empirical, so there's not much to dispute (though the post on discrimnation is also empirical, but it still gets its share of ridicule).</p>

<p>The last idea in the list is more meta: no one directly tells me that I should use more obscure terminology. Instead, I get comments that I must not know much about X because I'm not using terms of art. Using terms of art is a common way to establish credibility or authority, but that's something I don't really believe in. Arguing from authority doesn't tell you anything; adding needless terminology just makes things more difficult for readers who aren't in the field and are reading because they're interested in the topic but don't want to actually get into the field.</p>

<p>This is a pretty fundamental disagreement that I have with a lot of people. Just for example, I recently got into a discussion with an authority who insisted that it wasn't possible for me to reasonably disagree with them (I suggested we agree to disagree) because they're an authority on the topic and I'm not. It happens that I worked on the formal verification of a system very similar to the system we were discussing, but I didn't mention that because I don't believe that my status as an authority on the topic matters. If someone has such a weak argument that they have to fall back on an infallible authority, that's usually a sign that they don't have a well-reasoned defense of their position. This goes double when they point to themselves as the infallible authority.</p>

<p>I have about 20 other posts on stupid sounding ideas queued up in my head, but I mostly try to avoid writing things that are controversial, so I don't know that I'll write many of those up. If I were to write one post a month (much more frequently than my recent rate) and limit myself to 10% posts on ridiculable ideas, it would take 16 years to write up all of the ridiculable ideas I currently have.</p>

<p><small>Thanks to Leah Hanson, Hillel Wayne, Robert Schuessler, Michael Malis, Kevin Burke, Jeremie Jost, Pierre-Yves Baccou, Veit Heller, Jeff Fowler, Malte Skarupe, David Turner, Akiva Leffert, Lifan Zeng, John Hergenroder, Wesley Aptekar-Cassels, Chris Lample, Julia Evans, Anja Boskovic, Vaibhav Sagar, Sean Talts, Valentin Hartmann, Sean Barrett, Kevin Shannon, and an anonymous commenter for comments/corrections/discussion.&gt;</small></p>

<p>





</p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:S"><p>The choice of Overwatch is arbitrary among activities I'm familiar with where:</p>

<ul>
<li>I know enough about the activity to comment on it</li>
<li>I've observed enough people trying to learn it that I can say if it's &quot;easy&quot; or not to fix some mistake or class of mistake</li>
<li>There's a large enough set of rated players is high enough to support the argument</li>
<li>Many readers will also be familiar with the activity</li>
</ul>

<p>99% of my gaming background comes from 90s video games, but I'm not going to use those as examples because relatively few readers will be familiar with those games. I could also use &quot;modern&quot; board games like Puerto Rico, Dominion, Terra Mystica, <a href="https://en.wikipedia.org/wiki/Advanced_Squad_Leader">ASL</a> etc., but the set of people who played in rated games is very low, which makes the argument less convincing (perhaps people who play in rated games are much worse than people who don't -- unlikely, but difficult to justify without comparing gameplay between rated and unrated games, which is pretty deep into weeds for this post).</p>

<p>There are numerous activities that would be better to use than Overwatch, but I'm not familiar enough with them to use them as examples. For example, on reading a draft of this post, Kevin Burke noted that he's observed the same thing while coaching youth basketball and multiple readers noted that they've observed the same thing in chess, but I'm not familiar enough with youth basketball or chess to confidently say much about either activity even they'd be better examples because it's likely that more readers are familiar with basketball or chess than with Overwatch.</p>
 <a class="footnote-return" href="http://danluu.com/atom.xml#fnref:S"><sup>[return]</sup></a></li>

<li id="fn:O"><p>When I first started playing Overwatch (which is when I did that experiment), I ended up getting rated slightly above 50%-ile (for Overwatch players, that was in Plat -- this post is going to use percentiles and not ranks to avoid making non-Overwatch players have to learn what the ranks mean). It's generally believed and probably true that people who play the main ranked game mode in Overwatch are, on average, better than people who only play unranked modes, so it's likely that my actual percentile was somewhat higher than 50%-ile and that all &quot;true&quot; percentiles listed in this post are higher than the nominal percentiles.</p>

<p>Some things you'll regularly see at slightly above 50%-ile are:</p>

<ul>
<li>Supports (healers) will heal someone who's at full health (which does nothing) while a teammate who's next to them is dying and then dies</li>
<li>Players will not notice someone who walks directly behind the team and kills people one at a time until the entire team is killed</li>
<li>Players will shoot an enemy until only one more shot is required to kill the enemy and then switch to a different target, letting the 1-health enemy heal back to full health before shooting at that enemy again</li>
<li>After dying, players will not wait for their team to respawn and will, instead, run directly into the enemy team to fight them 1v6. This will repeat for the entire game (the game is designed to be 6v6, but in ranks below 95%-ile, it's rare to see a 6v6 engagement after one person on one team dies)</li>
<li>Players will clearly have no idea what character abilities do, including for the character they're playing</li>
<li>Players go for very high risk but low reward plays (for Overwatch players, a classic example of this is Rein going for a meme pin when the game opens on 2CP defense, very common at 50%-ile, rare at 95%-ile since players who think this move is a good idea tend to have generally poor decision making).</li>
<li>People will have terrible aim and will miss four or five shots in a row when all they need to do is hit someone once to kill them</li>
<li>If a single flanking enemy threatens a healer who can't escape plus a non-healer with an escape ability, the non-healer will probably use their ability to run away, leaving the healer to die, even though they could easily kill the flanker and save their healer if they just attacked while being healed.</li>
</ul>

<p>Having just one aspect of your gameplay be merely bad instead of atrocious is enough to get to 50%-ile. For me, that was my teamwork, for others, it's other parts of their gameplay. The reason I'd say that my teamwork was bad and not good or even mediocre was that I basically didn't know how to play the game, didn't know what any of the characters’ strengths, weaknesses, and abilities are, so I couldn't possibly coordinate effectively with my team. I also didn't know how the game modes actually worked (e.g., under what circumstances the game will end in a tie vs. going into another round), so I was basically wandering around randomly with a preference towards staying near the largest group of teammates I could find. That's above average.</p>

<p>You could say that someone is pretty good at the game since they're above average. But in a non-relative sense, being slightly above average is quite bad -- it's hard to argue that someone who doesn't notice their entire team being killed from behind while two teammates are yelling &quot;[enemy] behind us!&quot; over voice comms isn't bad.</p>

<p>After playing a bit more, I ended up with what looks like a &quot;true&quot; rank of about 90%-ile when I'm using a character I know how to use. Due to volatility in ranking as well as matchmaking, I played in games as high as 98%-ile. My aim and dodging were still atrocious. Relative to my rank, my aim was actually worse than when I was playing in 50%-ile games since my opponents were much better and I was only a little bit better. In 90%-ile, two copies of myself would probably lose fighting against most people 2v1 in the open. I would also usually lose a fight if the opponent was in the open and I was behind cover such that only 10% of my character was exposed, so my aim was arguably more than 10x worse than median at my rank.</p>

<p>My &quot;trick&quot; for getting to 90%-ile despite being a 1/10th aimer was learning how the game worked and playing in a way that maximized the probability of winning (to the best of my ability), as opposed to playing the game like it's an <a href="https://en.wikipedia.org/wiki/Deathmatch">FFA</a> game where your goal is to get kills as quickly as possible. It takes a bit more context to describe what this means in 90%-ile, so I'll only provide a couple examples, but these are representative of mistakes the vast majority of 90%-ile players are making all of the time (with the exception of a few players who have grossly defective aim, like myself, who make up for their poor aim by playing better than average for the rank in other ways).</p>

<p>Within the game, the goal of the game is to win. There are different game modes, but for the mainline ranked game, they all will involve some kind of objective that you have to be on or near. It's very common to get into a situation where the round timer is ticking down to zero and your team is guaranteed to lose if no one on your team touches the objective but your team may win if someone can touch the objective and not die instantly (which will cause the game to go into overtime until shortly after both teams stop touching the objective). A concrete example of this that happens somewhat regularly is, the enemy team has four players on the objective while your team has two players near the objective, one tank and one support/healer. The other four players on your team died and are coming back from spawn. They're close enough that if you can touch the objective and not instantly die, they'll arrive and probably take the objective for the win, but they won't get there in time if you die immediately after taking the objective, in which case you'll lose.</p>

<p>If you're playing the support/healer at 90%-ile to 95%-ile, this game will almost always end as follows: the tank will move towards the objective, get shot, decide they don't want to take damage, and then back off from the objective. As a support, you have a small health pool and will die instantly if you touch the objective because the other team will shoot you. Since your team is guaranteed to lose if you don't move up to the objective, you're forced to do so to have any chance of winning. After you're killed, the tank will either move onto the objective and die or walk towards the objective but not get there before time runs out. Either way, you'll probably lose.</p>

<p>If the tank did their job and moved onto the objective before you died, you could heal the tank for long enough that the rest of your team will arrive and you'll probably win. The enemy team, if they were coordinated, could walk around or through the tank to kill you, but they won't do that -- anyone who knows that will cause them to win the game and can aim well enough to successfully follow through can't help but end up in a higher rank). And the hypothetical tank on your team  who knows that it's their job to absorb damage for their support in that situation and not vice versa won't stay at 95%-ile very long because they'll win too many games and move up to a higher rank.</p>

<p>Another basic situation that the vast majority of 90%-ile to 95%-ile players will get wrong is when you're on offense, waiting for your team to respawn so you can attack as a group. Even at 90%-ile, maybe 1/4 to 1/3 of players won't do this and will just run directly at the enemy team, but enough players will realize that 1v6 isn't a good idea that you'll often 5v6 or 6v6 fights instead of the constant 1v6 and 2v6 fights you see at 50%-ile. Anyway, while waiting for the team to respawn in order to get a 5v6, it's very likely one player who realizes that they shouldn't just run into the middle of the enemy team 1v6 will decide they should try to hit the enemy team with long-ranged attacks 1v6. People will do this instead of hiding in safety behind a wall even when the enemy has multiple snipers with instant-kill long range attacks. People will even do this against multiple snipers when they're playing a character that isn't a sniper and needs to hit the enemy 2-3 times to get a kill, making it overwhelmingly likely that they won't get a kill while taking a significant risk of dying themselves. For Overwatch players, people will also do this when they have full ult charge and the other team doesn't, turning a situation that should be to your advantage (your team has ults ready and the other team has used ults), into a neutral situation (both teams have ults) <em>at best</em>, and instantly losing the fight at worst.</p>

<p>If you ever read an Overwatch forum, whether that's one of the reddit forums or the official Blizzard forums, a common complaint is &quot;why are my teammates so bad? I'm at [90%-ile to 95%-ile rank], but all my teammates are doing obviously stupid game-losing things all the time, like [an example above]&quot;. The answer is, of course, that the person asking the questiiton is also doing obviously stupid game-losing things all the time because anyone who doesn't wins too much to stay at 95%-ile. This also applies to me.</p>

<p>People will argue that players at this rank <em>should</em> be good because they're better than 95% of other players, which makes them relatively good. But non-relatively, it's hard to argue that someone who doesn't realize that you should step on the objective to probably win the game instead of not touching the objective for a sure loss is good. One of the most basic things about Overwatch is that it's an objective-based game, but the majority of players at 90%-ile to 95%-ile don't play that way.</p>

<p>For anyone who isn't well into the 99%-ile, reviewing recorded games will reveal game-losing mistakes all the time. For myself, usually ranked 90%-ile or so, watching a recorded game will reveal tens of game losing mistakes in a close game (which is maybe 30% of losses, the other 70% are blowouts where there isn't a single simple mistake that decides the game).</p>

<p>It's generally not too hard to fix these since the mistakes are like the example above: simple enough that once you see that you're making the mistake, the fix is straightforward because the mistake is straightforward.</p>
 <a class="footnote-return" href="http://danluu.com/atom.xml#fnref:O"><sup>[return]</sup></a></li>

<li id="fn:A"><p>There are probably some people who just want to be angry at their teammates. Due to how infrequently you get matched with the same players, it's hard to see this in the main rated game mode, but I think you can sometimes see this when Overwatch sometimes runs mini-rated modes.</p>

<p>Mini-rated modes have a much smaller playerbase than the main rated mode, which has two notable side effects: players with a much wider variety of skill levels will be thrown into the same game and you'll see the same players over and over again if you play multiple games.</p>

<p>Since you ended up matched with the same players repeatedly, you'll see players make the same mistakes and cause themselves to lose in the same way and then have the same tantrum and blame their teammates in the same way game after game.</p>

<p>You'll also see tantrums and teammate blaming in the normal rated game mode, but when you see it, you generally can't tell if the person who's having a tantrum is just having a bad day or if it's some other one-off occurrence since, unless you're ranked very high or very low (where there's a smaller pool of closely rated players), you don't run into the same players all that frequently. But when you see a set of players in 15-20 games over the course of a few weeks and you see them lose the game for the same reason a double digit number of times followed by the exact same tantrum, you might start to suspect that some fraction of those people really want to be angry and that the main thing they're getting out of playing the game is a source of anger. You might also wonder about this from how some people use social media, but that's a topic for another post.</p>
 <a class="footnote-return" href="http://danluu.com/atom.xml#fnref:A"><sup>[return]</sup></a></li>

<li id="fn:D"><p>For example, there will also be players who have some kind of disability that prevents them from improving, but at the levels we're talking about, 99%-ile or below, that will be relatively rare (certainly well under 50%, and I think it's not unreasonable to guess that it's well under 10% of people who choose to play the game). IIRC, there's at least one player who's in the top 500 who's deaf (this is severely disadvantageous since sound cues give a lot of fine-grained positional information that cannot be obtained in any other way), at least one legally blind player who's 99%-ile, and multiple players with physical impairments that prevent them from having fine-grained control of a mouse, i.e., who are basically incapable of aiming, who are 99%-ile.</p>

<p>There are also other kinds of reasons people might not improve. For example, Kevin Burke has noted that when he coaches youth basketball, some children don't want to do drills that they think make them look foolish (e.g., avoiding learning to dribble with their off hand even during drills where everyone is dribbling poorly because they're using their off hand). When I spent a lot of time in a climbing gym with a world class coach who would regularly send a bunch of kids to nationals and some to worlds, I'd observe the same thing in his classes -- kids, even ones who are nationally or internationally competitive, would sometimes avoid doing things because they were afraid it would make them look foolish to their peers. The coach's solution in those cases was to deliberately make the kid look extremely foolish and tell them that it's better to look stupid now than at nationals. Similarly, but I view these as basically independent of the issue discussed in the post.</p>
 <a class="footnote-return" href="http://danluu.com/atom.xml#fnref:D"><sup>[return]</sup></a></li>
<li id="fn:C">note that, here, a skilled coach is someone who is skilled at coaching, not necessarily someone who is skilled at the activity. People who are skilled at the activity but who haven't explicitly been taught how to teach or spent a lot of time working on teaching are generally poor coaches.
 <a class="footnote-return" href="http://danluu.com/atom.xml#fnref:C"><sup>[return]</sup></a></li>
<li id="fn:F">If you read the acknowledgements section of any of my posts, you can see that I get feedback from more than just two people on most posts (and I really appreciate the feedback), but I think that, by volume, well over 90% of the feedback I've gotten has come from Leah and a professional editor.
 <a class="footnote-return" href="http://danluu.com/atom.xml#fnref:F"><sup>[return]</sup></a></li>
</ol>
</div></p>
<p>
<em><a href="https://danluu.com/p95-skill/">February 07, 2020 12:00 AM</a></em>
</p>





<h2>February 04, 2020</h2>




<hr><h3 class="post"><a href="https://venam.nixers.net/blog/" title="Venam's Blog">Patrick Louis (venam)</a></h3>


<h4><a href="https://venam.nixers.net/blog/unix/2020/02/05/trash.html">Command Line Trash</a></h4>
<p>
<p><img src="https://venam.nixers.net/blog/assets/trash.png" alt="lock drawing" /></p>

<p><em>NB</em>: This is a repost on this blog of a post made on <a href="https://nixers.net/showthread.php?tid=2249">nixers.net</a></p>

<p>No this isn’t a post trashing shell scripting.</p>

<p>Handling files on the command line is most of the time a
non-reversable process, a dangerous one in some cases (<a href="https://nixers.net/showthread.php?tid=2055">Unix Horror
Stories</a>). There are tricks
to avoid the unnecessary loss and help in recovering files if need be.</p>

<blockquote>
  <p>Users do not expect that anything they delete is permanently
gone. Instead, they are used to a “Trash can” metaphor. A deleted
document ends up in a “Trash can”, and stays there at least for some
time — until the can is manually or automatically cleaned.</p>
</blockquote>

<p>In this thread we’ll list what ideas we have on this topic, novel or
not so novel.</p>

<hr />

<p>There’s the usual aliasing of rm to mv into a specific directory,
a trash can for the command line.<br />
This can be combined with a cron job or timer that cleans files in this
directory that are older than a certain time.</p>

<p>You can check the actual XDG trash documentation that goes into great
details about what needs to be taken into consideration:<br />
<a href="https://specifications.freedesktop.org/trash-spec/trashspec-1.0.html">https://specifications.freedesktop.org/trash-spec/trashspec-1.0.html</a></p>

<p>In <code class="highlighter-rouge">$HOME/.local/share/Trash</code> (<code class="highlighter-rouge">$XDG_DATA_HOME/Trash</code>) and usually at least
split into two directories:</p>

<ul>
  <li><strong>files</strong> for the actual exact copy of the files and directories
  (including their permission, and they should not override if two have
  the same names)</li>
  <li><strong>info</strong>, that contains the information about where and what name the
deleted file had, in case it needs to be restored. And also the date it
was deleted.</li>
</ul>

<p>Another way to avoid losing files is to keep backups of the file
system. This can be done via a logical volume management be it included
in the file system itself (ZFS, btrfs, etc..) or not.</p>

<p>So, what’s your command line trash, how do you deal with avoidable losses.</p></p>
<p>
<em><a href="https://venam.nixers.net/blog/unix/2020/02/05/trash.html">February 04, 2020 10:00 PM</a></em>
</p>





<h2>February 03, 2020</h2>




<hr><h3 class="post"><a href="https://www.ponylang.io/blog/" title="Blog on Pony">Ponylang (SeanTAllen)</a></h3>


<h4><a href="https://www.ponylang.io/blog/2020/02/0.33.2-released/">0.33.2 released</a></h4>
<p>
<p>Pony version 0.33.2 is now available. The release features no breaking changes for users&rsquo; Pony code. We recommend updating at your leisure.
</p></p>
<p>
<em><a href="https://www.ponylang.io/blog/2020/02/0.33.2-released/">February 03, 2020 10:37 PM</a></em>
</p>





<h2>February 02, 2020</h2>




<hr><h3 class="post"><a href="http://gerikson.com/blog" title="The occasional scrivener">Gustaf Erikson (gerikson)</a></h3>


<h4><a href="http://gerikson.com/blog/books/read/Deception-Well.html"><em>Deception Well</em> by Linda Nagata</a></h4>
<p>
</p>
<p>
<em><a href="http://gerikson.com/blog/books/read/Deception-Well.html">February 02, 2020 09:13 PM</a></em>
</p>









<hr><h3 class="post"><a href="https://www.ponylang.io/blog/" title="Blog on Pony">Ponylang (SeanTAllen)</a></h3>


<h4><a href="https://www.ponylang.io/blog/2020/02/last-week-in-pony---february-2-2020/">Last Week in Pony - February 2, 2020</a></h4>
<p>
<p>Our community Zulip has over 500 members! Ryan A. Hagenson introduces pony-bio, a bioinformatics library for the Pony ecosystem.</p>

<p></p></p>
<p>
<em><a href="https://www.ponylang.io/blog/2020/02/last-week-in-pony---february-2-2020/">February 02, 2020 05:13 PM</a></em>
</p>









<hr><h3 class="post"><a href="http://cfenollosa.com/blog/index.html" title="Carlos Fenollosa — Blog">Carlos Fenollosa (carlesfe)</a></h3>


<h4><a href="http://feedproxy.google.com/~r/WaitingForTheJobsToFinish/~3/I9J_A1uoBv4/links-for-2020-02-02.html">Links for 2020-02-02</a></h4>
<p>
<h4>💣 Remote exploit in OpenSMTPd  <a href="http://feeds.feedburner.com/WaitingForTheJobsToFinish#exploit_opensmtpd" name="exploit_opensmtpd" class="permalink">&#128279;</a></h4>

<p><a href="https://poolp.org/posts/2020-01-30/opensmtpd-advisory-dissected/">OpenSMTPD advisory dissected</a>
(5 min,
<a href="https://bsd.network/@brynet/103579748648371641">via</a>)</p>

<p>The author of OpenSMTPd does a good post-mortem of the catastrophic bug that has left a remote exploit
available for three years and a half.</p>

<blockquote>
  <p>We can’t prevent human mistakes, they will happen because tools won’t help spot that a human-described 
logic is flawed. What we need is to make changes so that OpenSMTPD becomes more resistant to human 
errors. In other words, we need safe-guards that are not dependant on sanity checks and input, we need 
safe-guards that will guarantee that even if OpenSMTPD lets completely untrusted input pass through, 
this will have the most limited consequences... then we ensure that it doesn’t let untrusted input pass through.</p>
</blockquote>

<p>Agreed. There is no such thing as bug-free code. </p>

<h4>🖥 CacheOut, another Intel CPU vulnerability <a href="http://feeds.feedburner.com/WaitingForTheJobsToFinish#intel_cacheout" name="intel_cacheout" class="permalink">&#128279;</a></h4>

<p><a href="https://cacheoutattack.com">CacheOut, Leaking Data on Intel CPUs via Cache Evictions</a>
(5 min,
<a href="https://news.ycombinator.com/item?id=22162762">via</a>)</p>

<p>Every single one of these would be a scandal. Now, we've gotten used to it. Shame on Intel.</p>

<h4>👴 UNIX lore <a href="http://feeds.feedburner.com/WaitingForTheJobsToFinish#unix_lore" name="unix_lore" class="permalink">&#128279;</a></h4>

<p><a href="https://www.tuhs.org/">The Unix Heritage Society</a>
(RH,
<a href="https://news.ycombinator.com/item?id=22195887">via</a>)</p>

<p>Great resource to learn more about UNIX history.</p>

<p>Make sure to <a href="https://wiki.tuhs.org/doku.php">browse their wiki</a></p>

<h4>💉 Antivirus selling user data <a href="http://feeds.feedburner.com/WaitingForTheJobsToFinish#antivirus_virus" name="antivirus_virus" class="permalink">&#128279;</a></h4>

<p><a href="https://www.vice.com/en_us/article/qjdkq7/avast-antivirus-sells-user-browsing-data-investigation">Leaked Documents Expose the Secretive Market for Your Web Browsing Data</a>
(1 min,
<a href="https://news.ycombinator.com/item?id=22159385">via</a>)</p>

<blockquote>
  <p>An Avast antivirus subsidiary sells 'Every search. Every click. Every buy. On every site.' 
Its clients have included Home Depot, Google, Microsoft, Pepsi, and McKinsey.</p>
</blockquote>

<p>How ironic.</p>

<h4>🎨 Oldschool web design trends <a href="http://feeds.feedburner.com/WaitingForTheJobsToFinish#oldschool_web" name="oldschool_web" class="permalink">&#128279;</a></h4>

<p><a href="https://pavellaptev.github.io/web-dark-ages/">Dark Ages of The Web</a>
(2 min,
<a href="https://www.dragonflydigest.com/2020/01/26/24073.html">via</a>)
is a visual trip through old web design trends.</p>

<p>It contains, of course:</p>

<ul>
<li>Tables</li>
<li>Animated gifs</li>
<li>The Web 2.0</li>
<li>Flash</li>
<li>The "Home Page"</li>
</ul>

<p>and more</p>

<p><img src="http://feeds.feedburner.com/img/oldschool_web.png" /></p>

<h4>🏴‍☠️ Whatsapp hack for Jeff Bezos <a href="http://feeds.feedburner.com/WaitingForTheJobsToFinish#whatsapp_bezos" name="whatsapp_bezos" class="permalink">&#128279;</a></h4>

<p><a href="https://assets.documentcloud.org/documents/6668313/FTI-Report-into-Jeff-Bezos-Phone-Hack.pdf">Technical Report of the Bezos Phone Hack</a>
(20 min, pdf,
<a href="https://die-partei.social/@hackernews/103548734926030567">via</a>)</p>

<p>Besides the actual forensics of the hack, which are not very in depth, this report provides
an interesting insight into the tools and environments that real security firms use to 
study malware. It seems that Cellebrite's software is very popular.</p>

<p>Be sure to read <a href="https://news.ycombinator.com/item?id=22151023">the HN discussion</a>, which seems to agree with my
point: the forensic analysis was not very good, but the between-lines content is insightful.</p>

<h4>🍎 Vintage Apple magazines <a href="http://feeds.feedburner.com/WaitingForTheJobsToFinish#vintage_apple" name="vintage_apple" class="permalink">&#128279;</a></h4>

<p><a href="https://vintageapple.org">VintageApple, Information from the early Apple era</a>
(RH,
<a href="https://www.dragonflydigest.com/2020/01/26/24073.html">via</a>)
is an archive of vintage Apple material, like magazines, books,
pictures, and more.</p>

<p>Make sure to check this one out if you're a retro Apple fan.</p>

<h4>👁 The Eye, another internet archive <a href="http://feeds.feedburner.com/WaitingForTheJobsToFinish#the_eye" name="the_eye" class="permalink">&#128279;</a></h4>

<p><a href="https://the-eye.eu">The Eye</a>
(RH,
<a href="https://old.reddit.com/r/DataHoarder/comments/ag8ce1/ive_made_a_collection_of_approx_11000_old_game/">via</a>)</p>

<p>I hope you already know about <a href="https://archive.org">The Internet Archive</a>, a non-profit effort to archive a lot 
of content on the Web. If you don't, contgratulations! Play with <a href="https://archive.org/details/softwarelibrary_msdos">MS-DOS software in your browser</a>, 
<a href="https://archive.org/details/texts">read free books</a> and watch <a href="https://archive.org/details/moviesandfilms">copyright-free movies</a></p>

<p>Then, check out <em>The Eye</em>. It's another non-profit project aimed at file archival, a bit more chaotic, which makes browsing
through its pages a real archeology dig.</p>

<blockquote>
  <p>The-Eye is a non-profit, community driven platform dedicated to the archiving and long-term 
preservation of any and all data including but by no means limited to... websites, books, games, 
software, video, audio, other digital-obscura and ideas.</p>
</blockquote>

<h4>🕹 Starfox into Zelda <a href="http://feeds.feedburner.com/WaitingForTheJobsToFinish#starfox_zelda" name="starfox_zelda" class="permalink">&#128279;</a></h4>

<p><a href="https://arstechnica.com/gaming/2020/01/how-to-get-star-fox-64-ships-into-ocarina-of-time-no-hacking-required/">This amazing glitch puts Star Fox 64 ships in an unmodified Zelda cartridge</a>
(15 min,
<a href="https://lobste.rs/s/y5sdtr/this_amazing_glitch_puts_star_fox_64_ships">via</a>)</p>

<p>The fact that these glitches can be run, and that there is people actively looking for them, makes me very happy.</p>

<p>Let's give due credit: <a href="https://www.twitch.tv/videos/540663120?t=2h11m15s">Zfg1 on Twitch</a></p>

<p>Related link: <a href="https://cfenollosa.com/blog/tag_roundup.html#oot_ace">Ocarina of Time glitches and code execution</a></p>

<p>Tags: <a href="http://feeds.feedburner.com/tag_roundup.html">roundup</a></p>

<!-- text end -->
<p id="twitter"><a href="http://twitter.com/intent/tweet?url=http://cfenollosa.com/blog/links-for-2020-02-02.html&text=<Type your comment here but please leave the URL so that other people can follow the comments>&via=cfenollosa">&amp;via=cfenollosa">&amp;via=cfenollosa">Comments? Tweet</a> 
<a href="https://twitter.com/search?q=http://cfenollosa.com/blog/links-for-2020-02-02.html"><span id="count-25008"></span></a>&nbsp;</p><img src="http://feeds.feedburner.com/~r/WaitingForTheJobsToFinish/~4/I9J_A1uoBv4" height="1" width="1" alt="" /></p>
<p>
<em><a href="http://feedproxy.google.com/~r/WaitingForTheJobsToFinish/~3/I9J_A1uoBv4/links-for-2020-02-02.html">February 02, 2020 12:09 PM</a></em>
</p>





<h2>February 01, 2020</h2>




<hr><h3 class="post"><a href="http://gerikson.com/blog" title="The occasional scrivener">Gustaf Erikson (gerikson)</a></h3>


<h4><a href="http://gerikson.com/blog/books/read/The-Secrets-of-Drearcliff.html"><em>The Secrets of Drearcliff Grange School</em> by Kim Newman</a></h4>
<p>
</p>
<p>
<em><a href="http://gerikson.com/blog/books/read/The-Secrets-of-Drearcliff.html">February 01, 2020 06:13 PM</a></em>
</p>





<h2>January 31, 2020</h2>




<hr><h3 class="post"><a href="http://gerikson.com/blog" title="The occasional scrivener">Gustaf Erikson (gerikson)</a></h3>


<h4><a href="http://gerikson.com/blog/books/read/The-Haunting-of-Drearcliff.html"><em>The Haunting of Drearcliff Grange School</em> by Kim Newman</a></h4>
<p>
</p>
<p>
<em><a href="http://gerikson.com/blog/books/read/The-Haunting-of-Drearcliff.html">January 31, 2020 01:50 PM</a></em>
</p>

    </div>
  </div>

  <div id="left-hand-navigation">
    <div id="menu">
      <ul class="level-one">
          <li>
          <ul class="level-two">
             <li><a href="index.html">Full content</a></li>
             <li><a href="rss20.xml">RSS feed</a></li>
             <li><a href="http://www.planetplanet.org/">Powered by Planet!</a></li>
	  </ul></li>
	  <li>Python Libraries
          <ul class="level-two">
  <li><a href="http://planet.laptop.org/">Planet OLPC</a></li>
  <li><a href="http://planet.pysoy.org/">Planet PySoy</a></li>
  <li><a href="http://planet.scipy.org/">Planet SciPy</a></li>
  <li><a href="http://planet.twistedmatrix.com/">Planet Twisted</a></li>
	  </ul></li>
	  <li>Python/Web Planets
          <ul class="level-two">
  <li><a href="http://planet.cherrypy.org/">Planet CherryPy</a></li>
  <li><a href="http://www.djangoproject.com/community/">Django Community</a></li>
  <li><a href="http://planet.plone.org/">Planet Plone</a></li>
  <li><a href="http://planet.turbogears.org/">Planet Turbogears</a></li>
	  </ul></li>
	  <li>Other Languages
          <ul class="level-two">
  <li><a href="http://planet.lisp.org/">Planet Lisp</a></li>
  <li><a href="http://planet.parrotcode.org/">Planet Parrot</a></li>
  <li><a href="http://planet.perl.org/">Planet Perl</a></li>
  <li><a href="http://planetruby.0x42.net/">Planet Ruby</a></li>
	  </ul></li>
	  <li>Subscriptions
          <ul class="level-two">
<li><a href="opml.xml">[OPML feed]</a></li>
<li><a href="https://deftly.net/" title="deftly.net - All posts">Aaron Bieber (qbit)</a></li>
<li><a href="https://blog.scriptingsysadmin.com/" title="Adnans Tech Links Blog">Adnans Tech Links (adnan)</a></li>
<li><a href="https://medium.com/@probablyfine?source=rss-e2a8548b9f4f------2" title="Stories by Alex Wilson on Medium">Alex Wilson (mrwilson)</a></li>
<li><a href="http://beza1e1.tuxen.de/" title="Andreas Writing">Andreas Zwinkau (qznc)</a></li>
<li><a href="https://blog.burntsushi.net/" title="Andrew Gallant's Blog on Andrew Gallant's Blog">Andrew Gallant (burntsushi)</a></li>
<li><a href="" title="">Andrew Gwozdziewycz (apg)</a></li>
<li><a href="https://amontalenti.com" title="Andrew Montalenti">Andrew Montalenti (amontalenti)</a></li>
<li><a href="https://www.junglecoder.com/blog/" title="Jungle Coder">Andrew Owen (yumaikas)</a></li>
<li><a href="http://www.andy-rambles.com/index.xml" title="Andy Rambles on Andy Rambles">Andy Rambles (yumaikas)</a></li>
<li><a href="https://www.anishathalye.com/" title="cat /var/log/life">Anish Athalye (anishathalye)</a></li>
<li><a href="" title="">Artemis (Artemix)</a></li>
<li><a href="http://assorted-experience.blogspot.com/" title="Assorted Experience">Assorted Experience (kghose)</a></li>
<li><a href="https://spacetime.dev/" title="spacetime.dev">Awn Umar (awn)</a></li>
<li><a href="http://benaiah.me" title="Benaiah Mischenko">Benaiah Mischenko (benaiah)</a></li>
<li><a href="https://www.bitquabit.com/" title="bitquabit">Benjamin Pollack (gecko)</a></li>
<li><a href="https://bitcannon.net/" title="Bit Cannon">Bit Cannon (wezm)</a></li>
<li><a href="https://defn.io/" title="defn.io">Bogdan Popa (bogdan)</a></li>
<li><a href="https://www.brianthicks.com/" title="Hey there! · Brian Hicks">Brian Hicks (brianhicks)</a></li>
<li><a href="http://waywardmonkeys.org/" title="Notes from a Wayward Monkey">Bruce Mitchener (BruceM)</a></li>
<li><a href="https://caiustheory.com/" title="Caius Theory">Caius Durling (caius)</a></li>
<li><a href="http://cfenollosa.com/blog/index.html" title="Carlos Fenollosa — Blog">Carlos Fenollosa (carlesfe)</a></li>
<li><a href="" title="">Chris (friendlysock)</a></li>
<li><a href="https://bitemyapp.com" title="">Chris Allen (bitemyapp)</a></li>
<li><a href="https://chr4.org/" title="chr4">Chris Aumann (chr4)</a></li>
<li><a href="http://bluishcoder.co.nz/&quot;" title="Bluishcoder">Chris Double (doublec)</a></li>
<li><a href="https://danluu.com/atom/index.xml" title="Dan Luu">Dan Luu (dl)</a></li>
<li><a href="https://journal.dedasys.com" title="DedaSys Journal">David N. Welton (davidw)</a></li>
<li><a href="https://sweetness.hmmz.org/" title="sweetness.hmmz.org">David Wilson (dw)</a></li>
<li><a href="http://shape-of-code.coding-guidelines.com" title="The Shape of Code">Derek Jones (derek-jones)</a></li>
<li><a href="http://faehnri.ch//" title="faehnri.ch">Eric Faehnrich (faehnrich)</a></li>
<li><a href="https://www.cambus.net/" title="Atom Feed - Cambus.net">Frederic Cambus (fcambus)</a></li>
<li><a href="https://frederik-braun.com/" title="Frederik Braun">Frederik Braun (freddyb)</a></li>
<li><a href="https://gabe.svbtle.com" title="gabriel guzman">Gabriel Guzman (gabe)</a></li>
<li><a href="https://wozniak.ca/" title="Curried lambda">Geoff Wozniak (GeoffWozniak)</a></li>
<li><a href="https://asylum.madhouse-project.org/blog/" title="Asylum Archives">Gergely Nagy (algernon)</a></li>
<li><a href="https://www.gkbrk.com/" title="Gokberk Yaltirakli">Gokberk Yaltirakli (gkbrk)</a></li>
<li><a href="https://blog.ovalerio.net" title="Gonçalo Valério">Gonçalo Valério (dethos)</a></li>
<li><a href="http://anadoxin.org/blog/" title="antek's tech blog">Grzegorz Antoniak (dark_grimoire)</a></li>
<li><a href="http://gerikson.com/blog" title="The occasional scrivener">Gustaf Erikson (gerikson)</a></li>
<li><a href="https://www.the-paper-trail.org/" title="The Paper Trail">Henry Robinson (henryr)</a></li>
<li><a href="https://medium.com/@wesharehoodies?source=rss-8853354c0e65------2" title="Stories by Ray Callahan on Medium">Indrek Lasn (indreklasn)</a></li>
<li><a href="" title="">Jakob (jakob)</a></li>
<li><a href="https://j11g.com" title="Jan van den Berg">Jan van den Berg (j11g)</a></li>
<li><a href="https://www.jeffcarp.com/" title="jeffcarp">Jeff Carpenter (jeffcarp)</a></li>
<li><a href="https://www.jeremymorgan.com/tags/programming/" title="programming on Jeremy Morgan :: Tech Blog">Jeremy Morgan (JeremyMorgan)</a></li>
<li><a href="https://begriffs.com" title="begriffs.com">Joe Nelson (begriffs)</a></li>
<li><a href="https://jonwillia.ms" title="Jon Williams">Jon Williams (wizardishungry)</a></li>
<li><a href="https://joshmanders.com" title="Thoughts, Stories &amp;amp; Ideas">Josh Manders (joshmanders)</a></li>
<li><a href="http://zduck.com" title="Joshua Poehls">Joshua Poehls (silent__thought)</a></li>
<li><a href="https://jpadilla.com" title="José Padilla">José Padilla (jpadilla)</a></li>
<li><a href="https://nerderati.com/" title="Nerderati">Joël Perras (jperras)</a></li>
<li><a href="http://cipht.net/" title="Julian Squires">Julian Squires (tokenrove)</a></li>
<li><a href="http://julienblanchard.com" title="Julien Blanchard">Julien Blanchard (julienXX)</a></li>
<li><a href="https://simplectic.com/blog/" title="simplectic">Kevin Beaty (kevinbeaty)</a></li>
<li><a href="https://kevin.burke.dev" title="Kevin Burke">Kevin Burke (kb)</a></li>
<li><a href="" title="">Leo Tindall (LeoLambda)</a></li>
<li><a href="http://codeplea.com/" title="CodePlea">Lewis Van Winkle (code)</a></li>
<li><a href="https://itscode.red/" title="It's Code Red">Luke Picciau (user545)</a></li>
<li><a href="http://brooker.co.za/blog/" title="Marc Brooker's Blog">Marc Brooker (mjb)</a></li>
<li><a href="https://markfischerjr.com//" title="Expositus">Mark Fischer (flyingfisch)</a></li>
<li><a href="http://www.kmjn.org/notes/" title="Mark's Notes">Mark J. Nelson (mjn)</a></li>
<li><a href="https://ideasandcode.xyz/" title="Ideas, and Code">Matthew Iselin (miselin)</a></li>
<li><a href="https://bernsteinbear.com" title="Max Bernstein's Blog">Maxwell Bernstein (tekknolagi)</a></li>
<li><a href="http://containerops.org/" title="Container Ops">Milos Gajdos (gyre007)</a></li>
<li><a href="https://www.monkeysnatchbanana.com/" title="Monkey Snatch Banana">Monkey Snatch Banana (SeanTAllen)</a></li>
<li><a href="http://theinternate.com/" title="The Internate">Nate Smith (nwjsmith)</a></li>
<li><a href="https://medium.com/@nikitavoloboev?source=rss-2a6397e4339e------2" title="Stories by Nikita Voloboev on Medium">Nikita Voloboev (nikivi)</a></li>
<li><a href="https://nikola.plejic.com/" title="Nikola Plejić">Nikola Plejić (nikola)</a></li>
<li><a href="https://silky.github.io" title="silky.github.io">Noon van der Silk (silky)</a></li>
<li><a href="https://medium.com/@olegkovalov?source=rss-c34448aa5bb9------2" title="Stories by Oleg Kovalov on Medium">Oleg Kovalov (olegkovalov)</a></li>
<li><a href="http://ocharles.org.uk/blog" title="Inside ocharles">Oliver Charles (ocharles)</a></li>
<li><a href="https://kaushikghose.wordpress.com" title="Pages from the fire">Pages From The Fire (kghose)</a></li>
<li><a href="https://venam.nixers.net/blog/" title="Venam's Blog">Patrick Louis (venam)</a></li>
<li><a href="" title="">Patrick Marchand (superpat)</a></li>
<li><a href="http://pepijndevos.nl/" title="Wishful Coding">Pepijn de Vos (pepijndevos)</a></li>
<li><a href="http://www.petecorey.com/" title="Pete Corey">Pete Corey (petecorey)</a></li>
<li><a href="https://push.cx" title="push.cx">Peter Bhat Harkins (pushcx)</a></li>
<li><a href="https://blog.functorial.com/feed.rss" title="Functorial Blog">Phil Freeman (paf31)</a></li>
<li><a href="https://technomancy.us/" title="Technomancy">Phil Hagelberg (technomancy)</a></li>
<li><a href="https://blog.separateconcerns.com" title="Separate Concerns">Pierre Chapuis (catwell)</a></li>
<li><a href="https://www.ponylang.io/blog/" title="Blog on Pony">Ponylang (SeanTAllen)</a></li>
<li><a href="https://www.rkallos.com/index.html" title="Richard Kallos: Richard Kallos">Richard Kallos (rkallos)</a></li>
<li><a href="https://sulami.github.io" title="sulami's blog">Robin Schroer (sulami)</a></li>
<li><a href="http://stsievert.com/" title="Scott Sievert">Scott Sievert (stsievert)</a></li>
<li><a href="" title="">Sevag Hanssian (sevagh)</a></li>
<li><a href="https://www.geeklan.co.uk" title="GeekLAN">Sevan Janiyan (sevan)</a></li>
<li><a href="" title="">Siddhant Goel (siddhantgoel)</a></li>
<li><a href="https://pzel.name" title="Simon Zelazny's Blog">Simon Zelazny (pzel)</a></li>
<li><a href="https://singpolyma.net" title="Tech – Singpolyma">Stephen Paul Weber (singpolyma)</a></li>
<li><a href="" title="">Stig Brautaset (stig)</a></li>
<li><a href="https://medium.com/@stjepan.golemac?source=rss-512a4050aac------2" title="Stories by Stjepan Golemac on Medium">Stjepan Golemac (stjepangolemac)</a></li>
<li><a href="http://timkellogg.me/" title="Tim Kellogg">Tim Kellogg (kellogh)</a></li>
<li><a href="https://pragtob.wordpress.com" title="Journeys of a not so young anymore Software Engineer">Tobias Pfeiffer (PragTob)</a></li>
<li><a href="https://unrelenting.technology/posts" title="User feed for Unknown">Unrelenting Technology (myfreeweb)</a></li>
<li><a href="https://vfoley.xyz/" title="Occasionally sane">Vincent (vfoley)</a></li>
<li><a href="https://blog.wallaroolabs.com/" title="Wallaroo Labs Engineering Blog">Wallaroo Labs (chuckblake)</a></li>
<li><a href="https://www.wezm.net/v2" title="Wesley Moore">Wesley Moore (wezm)</a></li>
<li><a href="http://yannesposito.com" title="yannesposito.com">Yann Esposito (yogsototh)</a></li>
<li><a href="" title="">Zac Brown (zacbrown)</a></li>
<li><a href="https://blog.asrpo.com" title="Asrp Blog">asrpo (asrp)</a></li>
<li><a href="https://theta.eu.org/" title="η (eta)">eta (eta)</a></li>
<li><a href="http://localhost/" title="Executive Orc House">jfb (jfb)</a></li>
<li><a href="https://blog.xero.nu" title="the website of xero harrison">xero (xero)</a></li>
<li><a href="https://atilaoncode.blog" title="Átila on Code">Átila on Code (atilaneves)</a></li>
          </ul></li>
      </ul>
    </div>
  </div>
</body>
</html>
